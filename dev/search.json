[{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://yu-group.github.io/simChef/dev/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://yu-group.github.io/simChef/dev/articles/parallel.html","id":"simulation-tasks","dir":"Articles","previous_headings":"","what":"Simulation tasks","title":"Computing experimental replicates in parallel","text":"future plan set user calls run_experiment, simChef distribute computation across resources specified plan. Consider n computational “tasks” distributed across p parallel workers. simChef, tasks correspond simulation replicates, generate data single DGP fit data using single Method, along associated parameters (either defaults varied Experiment). Assuming task takes approximately amount time complete regardless worker assigned task, n=100 p=4 worker complete around 25 tasks. ideal setting, total time complete 100 tasks around 4 times lower time takes one worker complete , average.","code":""},{"path":"https://yu-group.github.io/simChef/dev/articles/parallel.html","id":"dealing-with-task-heterogeneity","dir":"Articles","previous_headings":"Simulation tasks","what":"Dealing with task heterogeneity","title":"Computing experimental replicates in parallel","text":"realistic scenarios–especially simulation experiments often include heterogeneous methods compared diverse data-generated processes range sample sizes–tasks can much less uniform. Different groupings tasks can profound implications overall running time. Therefore, ’s important carefully decide arrange simulation separate experiments order take greatest advantage available parallelism. simChef distributes simulation’s replicates evenly across available future workers, partially answering question. remainder answer comes specific application, couple tips: general, one fewer tasks workers avoid n>>p small tasks overhead distributing computation workers may outweigh benefits parallelism. tasks unbalanced sizes, can helpful group tasks separate experiments, tasks roughly equal duration. spite extra overhead, may find using separate Experiment task group ends decreasing overall simulation running time workers small tasks spend less time idly waiting workers large tasks finish. Using clone_from argument create_experiment(), can copy existing experiment modify tasks similar sizes, repeating process group similarly-sized tasks. can use progressr package get updates experiment computation progresses. Use options(simChef.debug = TRUE) get helpful debugging output Experiment works ’s tasks, including info memory usage. may slow things quite bit, don’t use run full simulation.","code":""},{"path":"https://yu-group.github.io/simChef/dev/articles/parallel.html","id":"on-the-roadmap-nested-parallelism","dir":"Articles","previous_headings":"Simulation tasks","what":"On the roadmap: nested parallelism","title":"Computing experimental replicates in parallel","text":"future plan give control user splits computation across workers, nested parallelism cases , e.g., DGPs can split across nodes (e.g., using one plan package future.batchtools) node uses many cores process replicates parallel (e.g., using future::multicore plan). something ’re interested , please feel free contribute discussion https://github.com/Yu-Group/simChef/issues/54.","code":""},{"path":"https://yu-group.github.io/simChef/dev/articles/parallel.html","id":"example","dir":"Articles","previous_headings":"","what":"Example","title":"Computing experimental replicates in parallel","text":"Putting aside caveats now, parallelization simChef works without modification using future set parallel backend. example , choose multicore backend (available Windows) create forked R processes using available cores. example shows total replicates can quickly add varying across DGP Method parameters. varying across parameters one DGPs, effect 17 distinct data generating processes experiment (1 dgp1 16 combinations parameters dgp2), though actuality two DGP objects. Similarly, effectively 4 distinct methods, though 2 Method objects. n_reps = 2, results total 2 x 17 x 4 = 136 total rows results tibble. find lower computational resource utilization ’d like, simulation grows might consider breaking experiment separate experiments, e.g., DGP, method, parameters like sample size n number covariates d, depending factors greatest impact task duration.","code":"library(simChef) library(future) library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union  n_cores <- availableCores(methods = \"system\") n_cores #> system  #>      2  plan(multicore, workers = n_cores)  dgp_fun1 <- function(n=100, rho=0.5, noise_level=1) {   cov_mat <- diag(nrow = 5)   cov_mat[cov_mat == 0] <- rho   X <- MASS::mvrnorm(n = n, mu = rep(0, 5), Sigma = cov_mat)   y <- cbind(1, X) %*% c(-8, 3, -1, 0, 0, 0) + rnorm(n, sd = noise_level)   return(list(X = X, y = y)) }  dgp_fun2 <- function(n=100, d=100, rho=0.5, sparsity=0.5, noise_level=1,                      nonzero_coeff = c(-3, -1, 1, 3)) {   cov_mat <- diag(nrow = d)   cov_mat[cov_mat == 0] <- rho   X <- MASS::mvrnorm(n = n, mu = rep(0, d), Sigma = cov_mat)   coeff_prob <- c(sparsity, rep((1 - sparsity) / 4, times = 4))   coeff <- c(     -8, # intercept     sample(       c(0, nonzero_coeff), size = d, replace = TRUE,       prob = coeff_prob     )   )   y <- cbind(1, X) %*% coeff + rnorm(n, sd = noise_level)   return(list(X = X, y = y)) }  dgp1 <- create_dgp(dgp_fun1, .name = \"dense_dgp\") dgp2 <- create_dgp(dgp_fun2, .name = \"sparse_dgp\")  ols <- function(X, y) {   fit <- lm(y ~ X) %>% broom::tidy()   return(fit) }  elnet <- function(X, y, alpha=1) {   fit <- glmnet::glmnet(     x = X, y = y, family = \"gaussian\", alpha = alpha   ) %>% broom::tidy()   return(fit) }  method1 <- create_method(ols, .name = \"ols\") method2 <- create_method(elnet, .name = \"elnet\")  experiment <- create_experiment(   name = \"exper\", future.packages = \"dplyr\") %>%   add_dgp(dgp1) %>%   add_dgp(dgp2) %>%   add_method(method1) %>%   add_method(method2) %>%   add_vary_across(     .dgp = \"sparse_dgp\",     d = c(100, 1000),     rho = c(0.2, 0.9),     sparsity = c(0.5, 0.9),     nonzero_coeff = list(c(-3, -1, 1, 3), c(-0.3, -0.1, 0.1, 0.3))   ) %>%   add_vary_across(     .method = \"elnet\", alpha = c(0, 0.5, 1)   )  results <- experiment$fit(n_reps = 2) #> Fitting exper... #> 2 reps completed (totals: 2/2) | time taken: 0.839235 minutes #> ============================== results #> # A tibble: 136 × 16 #>    .rep  .dgp_…¹ .meth…²     d   rho spars…³ nonze…⁴ alpha term  estim…⁵ std.e…⁶ #>    <chr> <chr>   <chr>   <dbl> <dbl>   <dbl> <list>  <dbl> <lis> <list>  <list>  #>  1 1     dense_… elnet      NA  NA      NA   <NULL>    0   <chr> <dbl>   <NULL>  #>  2 1     dense_… elnet      NA  NA      NA   <NULL>    0.5 <chr> <dbl>   <NULL>  #>  3 1     dense_… elnet      NA  NA      NA   <NULL>    1   <chr> <dbl>   <NULL>  #>  4 1     dense_… ols        NA  NA      NA   <NULL>   NA   <chr> <dbl>   <dbl>   #>  5 1     sparse… elnet     100   0.2     0.5 <dbl>     0   <chr> <dbl>   <NULL>  #>  6 1     sparse… elnet     100   0.2     0.5 <dbl>     0.5 <chr> <dbl>   <NULL>  #>  7 1     sparse… elnet     100   0.2     0.5 <dbl>     1   <chr> <dbl>   <NULL>  #>  8 1     sparse… elnet    1000   0.2     0.5 <dbl>     0   <chr> <dbl>   <NULL>  #>  9 1     sparse… elnet    1000   0.2     0.5 <dbl>     0.5 <chr> <dbl>   <NULL>  #> 10 1     sparse… elnet    1000   0.2     0.5 <dbl>     1   <chr> <dbl>   <NULL>  #> # … with 126 more rows, 5 more variables: statistic <list>, p.value <list>, #> #   step <list>, lambda <list>, dev.ratio <list>, and abbreviated variable #> #   names ¹​.dgp_name, ²​.method_name, ³​sparsity, ⁴​nonzero_coeff, ⁵​estimate, #> #   ⁶​std.error"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Getting started with simChef","text":"goal simChef seamlessly efficiently run simulation experiments using simple grammar. results simulation experiments can also conveniently viewed organized interactive browser (html file) (e.g., ). basic usage simChef can summarized follows: Create individual parts simulation experiment recipe Create DGP(s) (data-generating processes) via create_dgp() Create Method(s) via create_method() Create Evaluator(s) via create_evaluator() Create Visualizer(s) via create_visualizer() Assemble recipe parts complete simulation experiment, e.g.: Document describe simulation experiment text Run experiment Visualize results via automated R Markdown report next go toy example simulation using linear regression.","code":"dgp <- create_dgp(     function(n = 100, p = 10, noise_max = 5) {     noise_level <- runif(1, max = noise_max)     X <- matrix(rnorm(n*p), nrow = n)     y <- X %*% rnorm(p, sd = 2) + rnorm(n, sd = noise_level)     # dgp's should return a named list     return(list(X = X, y = y, noise_level = noise_level))     } ) dgp #> DGP Name: NULL  #>    Function: function (n = 100, p = 10, noise_max = 5)   #>    Parameters:  list() method <- create_method(   # method function args include the names in the dgp output list (`X` and `y` here)   function(X, y, ...) {     # by concatenating ... with the list output, we can pass through other     # outputs from the dgp to later stages of the simulation (evaluation and     # visualization)     return(c(list(fit = lm(y ~ X)), ...))   } ) method #> Method Name: NULL  #>    Function: function (X, y, ...)   #>    Parameters:  list() evaluator <- create_evaluator(   # the main computational loop of the simulation will return a `tibble::tibble`   # which is passed as 'fit_results' to our evaluation functions   function(fit_results) {     # calculate R-squared     fit_results %>%       dplyr::mutate(         rsq = sapply(fit, function(.fit) summary(.fit)$r.squared)       )   } ) evaluator #> Evaluator Name: NULL  #>    Function: function (fit_results)   #>    Parameters:  list() #>    R Markdown Options: List of 3 #>      $ digits : num 2 #>      $ sigfig : logi FALSE #>      $ options:List of 2 #>       ..$ scrollX       : logi TRUE #>       ..$ scrollCollapse: logi TRUE #>    Show in R Markdown: TRUE visualizer <- create_visualizer(   # you can use 'fit_results' as well here by adding it as an argument   function(eval_results) {     require(ggplot2)     # return a plot r-squared vs noise level     ggplot(aes(x = noise_level, y = rsq), data = eval_results[[1]]) +       geom_point() +       geom_smooth()   } ) visualizer #> Visualizer Name: NULL  #>    Function: function (eval_results)   #>    Parameters:  list() #>    R Markdown Options: List of 2 #>      $ height: num 6 #>      $ width : num 10 #>    Show in R Markdown: TRUE experiment <- create_experiment(name = \"Experiment\") %>%   add_dgp(dgp, name = \"DGP1\") %>%   add_method(method, name = \"Method1\") %>%   add_evaluator(evaluator, name = \"Evaluator1\") %>%   add_visualizer(visualizer, name = \"Visualizer1\") experiment #> Experiment Name: Experiment  #>    Saved results at: results/Experiment  #>    DGPs: DGP1  #>    Methods: Method1  #>    Evaluators: Evaluator1  #>    Visualizers: Visualizer1  #>    Vary Across: None init_docs(experiment) results <- run_experiment(experiment, n_reps = 100, save = T) # or alternatively, `results <- experiment$run(n_reps = 100, save = T)` render_docs(experiment)"},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"create-individual-parts-of-the-simulation-experiment-recipe","dir":"Articles","previous_headings":"Basic usage","what":"Create individual parts of the simulation experiment recipe","title":"Getting started with simChef","text":"begin, first need create individual parts simulation experiment recipe. four main components/classes verbs simulation experiment: DGP (data-generating process): data-generating processes generate data Method: methods (models) fit experiment Evaluator: evaluation metrics used evaluate methods performance Visualizer: visualization functions used visualize outputs method fits evaluation results (can tables, plots, even R Markdown snippets display) create DGP(), Method(), Evaluator(), Visualizer(), can respectively use create_dgp(), create_method(), create_evaluator(), create_visualizer() functions. create_*() function follows syntax takes inputs: .*_fun: first input function simulate data, fit method, evaluate metrics, create visualization (depending *). .name: (optional) name component. Can specified either create_*() creating experiment see later. ...: additional arguments get passed *_fun .","code":""},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"create-data-generating-process-dgp","dir":"Articles","previous_headings":"Basic usage > Create individual parts of the simulation experiment recipe","what":"Create data-generating process (DGP)","title":"Getting started with simChef","text":"toy DGP example, let us create function simulate random Gaussian data matrix \\(\\mathbf{X}\\) size \\(n \\times 2\\) linear response vector \\(\\mathbf{y}\\) size \\(n \\times 1\\), \\[\\begin{gather*} \\mathbf{X} \\sim N\\left(\\mathbf{0}, \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix}\\right), \\\\ \\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\epsilon},\\\\ \\boldsymbol{\\epsilon} \\sim N(\\mathbf{0}, \\sigma^2 \\mathbf{}_n) \\end{gather*}\\] can create object class DGP() function via Note additional arguments create_dgp() must named arguments match dgp_fun().","code":"dgp_fun <- function(n, beta, rho, sigma) {   cov_mat <- matrix(c(1, rho, rho, 1), byrow = T, nrow = 2, ncol = 2)   X <- MASS::mvrnorm(n = n, mu = rep(0, 2), Sigma = cov_mat)   y <- X %*% beta + rnorm(n, sd = sigma)   return(list(X = X, y = y)) } dgp <- create_dgp(.dgp_fun = dgp_fun, .name = \"Linear Gaussian DGP\",                   # additional named parameters to pass to dgp_fun()                   n = 200, beta = c(1, 0), rho = 0, sigma = 1)"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"create-method","dir":"Articles","previous_headings":"Basic usage > Create individual parts of the simulation experiment recipe","what":"Create method","title":"Getting started with simChef","text":"Given DGP, suppose want investigate performance linear regression, specifically p-values outputted non-intercept coefficients summary.lm(). can create object class Method() function via couple notes : inputs method function lm_fun() include named outputs DGP function dgp_fun() (case, X y), data generated DGP automatically passed Method. Additional arguments can passed create_method() done previously create_dgp(). However, necessary case happy default argument cols lm_fun().","code":"lm_fun <- function(X, y, cols = c(\"X1\", \"X2\")) {   lm_fit <- lm(y ~ X)   pvals <- summary(lm_fit)$coefficients[cols, \"Pr(>|t|)\"] %>%     setNames(paste(names(.), \"p-value\"))   return(pvals) } lm_method <- create_method(.method_fun = lm_fun)"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"create-evaluator","dir":"Articles","previous_headings":"Basic usage > Create individual parts of the simulation experiment recipe","what":"Create evaluator","title":"Getting started with simChef","text":"evaluate performance linear regression, one metric (statistic) interest rejection probability level \\(\\alpha\\), compute following function. can create object class Evaluator() function via key points keep mind writing custom Evaluator function reject_prob_fun(). First, Evaluator function almost always take named argument fit_results. fit_results placeholder tibble outputted Experiment$fit() automatically passed experiment fitted. Note argument must exactly named fit_results else Evaluator function receive results Experiment$fit(). see Experiment$fit() action later, now, can think fit_results tibble containing results (replicate, DGP, method) combinations fitted experiment. Naturally, fit_results columns named .rep, .dgp_name, .method_name, named arguments outputted method function (.e., lm_fun). Many evaluation metrics naturally computed across replicates, common group fit_results .dgp_name .method_name seen reject_prob_fun() . , rejection probability (across replicates) computed (DGP, Method) combination separately. However, depending goal Evaluator function, grouping .dgp_name .method_name might necessary. , additional arguments can passed create_evaluator(), case, overwritten default value alpha alpha = 0.1.","code":"reject_prob_fun <- function(fit_results, alpha = 0.05) {   group_vars <- c(\".dgp_name\", \".method_name\")   eval_out <- fit_results %>%     dplyr::group_by(across({{group_vars}})) %>%     dplyr::summarise(       `X1 Reject Prob.` = mean(`X1 p-value` < alpha),       `X2 Reject Prob.` = mean(`X2 p-value` < alpha)     )   return(eval_out) } reject_prob_eval <- create_evaluator(.eval_fun = reject_prob_fun, alpha = 0.1)"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"create-visualizer","dir":"Articles","previous_headings":"Basic usage > Create individual parts of the simulation experiment recipe","what":"Create visualizer","title":"Getting started with simChef","text":"Lastly, may want plot results Method fits (stored fit_results) /outputs Evaluators (stored eval_results). example, plot power hypothesis test. can create object class Visualizer() function via Like custom Evaluator functions, custom Visualizer functions power_plot_fun() can take argument fit_results want construct plot method fit outputs. want construct visualization using output Evaluators (e.g., output reject_prob_fun()), Visualizer function can also take argument eval_results input. Note arguments must exactly named fit_results eval_results order work properly. Beyond creating plots, Visualizers can return tables generally, R Markdown snippet containing results. create_* functions, additional arguments need pass custom Visualizer function can passed create_visualizer().","code":"power_plot_fun <- function(fit_results, col = \"X1\") {   plt <- ggplot2::ggplot(fit_results) +     ggplot2::aes(x = .data[[paste(col, \"p-value\")]],                  color = as.factor(.method_name)) +     ggplot2::geom_abline(slope = 1, intercept = 0,                          color = \"darkgray\", linetype = \"solid\", size = 1) +     ggplot2::stat_ecdf(size = 1) +     ggplot2::scale_x_continuous(limits = c(0, 1)) +     ggplot2::labs(x = \"t\", y = \"P( p-value \\u2264 t )\",                   linetype = \"\", color = \"Method\")   return(plt) } power_plot <- create_visualizer(.viz_fun = power_plot_fun)"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"assemble-simulation-experiment-recipe","dir":"Articles","previous_headings":"Basic usage","what":"Assemble simulation experiment recipe","title":"Getting started with simChef","text":"point, created DGP (dgp), Method (lm_method), Evaluator (reject_prob_eval), Visualizer (power_plot). next step create simulation experiment recipe add component recipe via number DGPs, Methods, Evaluators, Visualizers can added simulation experiment recipe, added element experiment intelligible name used creating R Markdown results report. can easily see individual parts simulation experiment recipe printing experiment. DGP, Method, Evaluator, Visualizer added simulation experiment recipe, component can updated using update_dgp(), update_method(), update_evaluator(), update_visualizer() removed using remove_dgp(), remove_method(), remove_evaluator(), remove_visualizer().","code":"experiment <- create_experiment(name = \"Linear Regression Experiment\") %>%   add_dgp(dgp, name = \"Linear Gaussian DGP\") %>%   add_method(lm_method, name = \"OLS\") %>%   add_evaluator(reject_prob_eval, name = \"Rejection Prob. (alpha = 0.1)\") %>%   add_visualizer(power_plot, name = \"Power\") print(experiment) #> Experiment Name: Linear Regression Experiment  #>    Saved results at: results/Linear Regression Experiment  #>    DGPs: Linear Gaussian DGP  #>    Methods: OLS  #>    Evaluators: Rejection Prob. (alpha = 0.1)  #>    Visualizers: Power  #>    Vary Across: None"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"document-the-simulation-experiment","dir":"Articles","previous_headings":"Basic usage","what":"Document the simulation experiment","title":"Getting started with simChef","text":"crucial component running veridical simulations documentation. highly encourage practitioners document purpose objective simulation experiment, DGPs, Methods, Evaluators, Visualizers used, DGPs, Methods, Evaluators, Visualizers chosen. can done even running simulation experiment. facilitate tedious important process, can easily create documentation template fill using creates series blank .md files user fill descriptions simulation experiment recipe components. blank .md files can found experiment’s root results directory docs/. find experiment’s root results directory, use experiment$get_save_dir().","code":"init_docs(experiment)"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"run-the-simulation-experiment","dir":"Articles","previous_headings":"Basic usage","what":"Run the simulation experiment","title":"Getting started with simChef","text":"Thus far, created documented simulation experiment recipe, generated results experiment. , given simulation experiment instructions . run experiment, say 100 replicates, can via alternatively, output experiment$run() list length three: fit_results: output Method fits (see experiment$fit()) eval_results: output Evaluators (see experiment$evaluate()) viz_results: output Visualizers (see experiment$visualize())  default, results saved disk. However, generate R Markdown report, need save results disk hence set save = TRUE . experiment can also run parallel. detailed walkthrough parallelize experiment, please see vignette(\"parallel\").","code":"results <- experiment$run(n_reps = 100, save = TRUE) #> Fitting Linear Regression Experiment... #> Saving fit results... #> Fit results saved | time taken: 0.052464 seconds #> 100 reps completed (totals: 100/100) | time taken: 0.616703 minutes #> ============================== #> Evaluating Linear Regression Experiment... #> `summarise()` has grouped output by '.dgp_name'. You can override using the #> `.groups` argument. #> Evaluation completed | time taken: 0.000995 minutes #> Saving eval results... #> Eval results saved | time taken: 0.101644 seconds #> ============================== #> Visualizing Linear Regression Experiment... #> Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. #> ℹ Please use `linewidth` instead. #> Visualization completed | time taken: 0.003588 minutes #> Saving viz results... #> Viz results saved | time taken: 0.066790 seconds #> ============================== results <- experiment %>%   run_experiment(n_reps = 100, save = TRUE) str(results, max.level = 2) #> List of 3 #>  $ fit_results : tibble [100 × 5] (S3: tbl_df/tbl/data.frame) #>  $ eval_results:List of 1 #>   ..$ Rejection Prob. (alpha = 0.1): tibble [1 × 4] (S3: tbl_df/tbl/data.frame) #>  $ viz_results :List of 1 #>   ..$ Power:List of 9 #>   .. ..- attr(*, \"class\")= chr [1:2] \"gg\" \"ggplot\" results$fit_results #> # A tibble: 100 × 5 #>    .rep  .dgp_name           .method_name `X1 p-value` `X2 p-value` #>    <chr> <chr>               <chr>               <dbl>        <dbl> #>  1 1     Linear Gaussian DGP OLS              4.90e-29       0.704  #>  2 2     Linear Gaussian DGP OLS              4.28e-28       0.713  #>  3 3     Linear Gaussian DGP OLS              1.60e-38       0.680  #>  4 4     Linear Gaussian DGP OLS              2.31e-29       0.0115 #>  5 5     Linear Gaussian DGP OLS              8.08e-33       0.127  #>  6 6     Linear Gaussian DGP OLS              8.95e-29       0.980  #>  7 7     Linear Gaussian DGP OLS              6.84e-33       0.385  #>  8 8     Linear Gaussian DGP OLS              6.60e-29       0.116  #>  9 9     Linear Gaussian DGP OLS              4.16e-28       0.765  #> 10 10    Linear Gaussian DGP OLS              1.28e-21       0.530  #> # … with 90 more rows results$eval_results #> $`Rejection Prob. (alpha = 0.1)` #> # A tibble: 1 × 4 #>   .dgp_name           .method_name `X1 Reject Prob.` `X2 Reject Prob.` #>   <chr>               <chr>                    <dbl>             <dbl> #> 1 Linear Gaussian DGP OLS                          1              0.12 results$viz_results #> $Power"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"visualize-results","dir":"Articles","previous_headings":"Basic usage","what":"Visualize results","title":"Getting started with simChef","text":"Finally, can easily visualize results simulation experiment html file (generated using R Markdown) browser. results can found . Note documentation template yet created experiment (e.g., via init_docs(experiment)), render_docs() automatically create documentation template user fill . , highly encourage practitioners document simulation experiments spirit transparency reproducibility.","code":"render_docs(experiment, open = FALSE) #> Creating R Markdown report for Linear Regression Experiment..."},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"running-an-experiment-across-varying-parameters-in-the-dgpmethod","dir":"Articles","previous_headings":"Basic usage","what":"Running an experiment across varying parameters in the DGP/Method","title":"Getting started with simChef","text":"Now, going slightly beyond basic usage simChef, often helpful understand method’s performance affected vary single parameter DGP across different values. instance, happens power amount noise linear model increases? Using simple grammar simChef, can investigate question adding “vary across” component simulation experiment. add_vary_across(), dgp argument name DGP vary DGP object . subsequent arguments form [param_name] = [param_values], param_name name argument/parameter DGP function varied, param_values list atomic vector values param_name take vary across arguments kept constant base value (see dgp$dgp_params). , varying sigma parameter (.e., SD additive noise term) values 1, 2, 4, 8 within Linear Gaussian DGP. (Note: can also vary across parameters Method inputting method argument instead dgp argument add_vary_across().) However, run experiment, results quite expect. results summarized/aggregated across values sigma.  see different values sigma affect experiment results, need modify Evaluator Visualizer functions. Specifically, reject_prob_eval, want group fit_results sigma addition .dgp_name .method_name. , need add vary_params argument custom Evaluator function. run experiment, vary_params auto-filled vector parameter names varied (.e., added via add_vary_across()). case, vary_params auto-filled c(\"sigma\"). Similarly power_plot_fun, need add vary_params argument plot results across different values sigma. , also added pre-processing step deal potential case vary across list parameter values. pre-processing step uses helper function, list_col_to_chr(), convert list-type tibble column character-type tibble column amenable plotting (unlike list-type column). Now, ready update experiment run experiment via  Note need use update_* instead add_* since Evaluator named “Rejection Prob. (alpha = 0.1)” Visualizer named “Power” already exist Experiment. Using add_* throw error. fun, let’s add another plot (fact, interactive plot using plotly::ggplotly) Experiment run Experiment across various values coefficient \\(\\boldsymbol{\\beta}_2\\) correlation \\(\\rho\\) features \\(\\mathbf{X}\\). (Note: visualizer function (reject_prob_plot_fun) takes Evaluator results, stored eval_results, plots rejection probability \\(\\boldsymbol{\\beta}_1\\) \\(\\alpha = 0.1\\).) Now generating R Markdown report summary Experiment, R Markdown compile results (evaluation visualization results) saved Experiments root results directory experiment$get_save_dir(). Since results many vary_across runs saved original experiment’s results directory, following include results single document. Equivalently, can create R Markdown report summary directly specifying experiment’s root results directory. results can found . addition showing results root results directory, render_docs() automatically generate blank documentation template every DGP(), Method(), Evaluator(), Visualizer() found one Experiments root results directory. one like generate documentation template create R Markdown report, see init_docs().","code":"experiment <- experiment %>%   add_vary_across(.dgp = \"Linear Gaussian DGP\", sigma = c(1, 2, 4, 8)) print(experiment) #> Experiment Name: Linear Regression Experiment  #>    Saved results at: results/Linear Regression Experiment  #>    DGPs: Linear Gaussian DGP  #>    Methods: OLS  #>    Evaluators: Rejection Prob. (alpha = 0.1)  #>    Visualizers: Power  #>    Vary Across:  #>       DGP: Linear Gaussian DGP  #>          sigma:  num [1:4] 1 2 4 8 vary_results <- experiment$run(n_reps = 100, save = TRUE) #> Fitting Linear Regression Experiment... #> Saving fit results... #> Fit results saved | time taken: 0.044660 seconds #> 100 reps completed (totals: 100/100) | time taken: 2.641444 minutes #> ============================== #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000422 minutes #> Saving eval results... #> Eval results saved | time taken: 0.036636 seconds #> ============================== #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.001169 minutes #> Saving viz results... #> Viz results saved | time taken: 0.083531 seconds #> ============================== vary_results$eval_results #> $`Rejection Prob. (alpha = 0.1)` #> # A tibble: 1 × 4 #>   .dgp_name           .method_name `X1 Reject Prob.` `X2 Reject Prob.` #>   <chr>               <chr>                    <dbl>             <dbl> #> 1 Linear Gaussian DGP OLS                      0.875             0.112 vary_results$viz_results #> $Power reject_prob_fun <- function(fit_results, vary_params = NULL, alpha = 0.05) {   group_vars <- c(\".dgp_name\", \".method_name\", vary_params)   eval_out <- fit_results %>%     dplyr::group_by(across({{group_vars}})) %>%     dplyr::summarise(       `X1 Reject Prob.` = mean(`X1 p-value` < alpha),       `X2 Reject Prob.` = mean(`X2 p-value` < alpha)     )   return(eval_out) } reject_prob_eval <- create_evaluator(.eval_fun = reject_prob_fun, alpha = 0.1) power_plot_fun <- function(fit_results, vary_params = NULL, col = \"X1\") {    if (!is.null(vary_params)) {     # deal with the case when we vary across a parameter that is vector-valued     if (is.list(fit_results[[vary_params]])) {       fit_results[[vary_params]] <- list_col_to_chr(fit_results[[vary_params]],                                                     name = vary_params,                                                     verbatim = TRUE)     }   }    plt <- ggplot2::ggplot(fit_results) +     ggplot2::aes(x = .data[[paste(col, \"p-value\")]],                  color = as.factor(.method_name)) +     ggplot2::geom_abline(slope = 1, intercept = 0,                          color = \"darkgray\", linetype = \"solid\", size = 1) +     ggplot2::stat_ecdf(size = 1) +     ggplot2::scale_x_continuous(limits = c(0, 1)) +     ggplot2::labs(x = \"t\", y = \"P( p-value \\u2264 t )\",                   linetype = \"\", color = \"Method\")   if (!is.null(vary_params)) {     plt <- plt + ggplot2::facet_wrap(~ .data[[vary_params]])   }   return(plt) } power_plot <- create_visualizer(.viz_fun = power_plot_fun) vary_results <- experiment %>%   update_evaluator(reject_prob_eval, name = \"Rejection Prob. (alpha = 0.1)\") %>%   update_visualizer(power_plot, name = \"Power\") %>%   run_experiment(n_reps = 100, save = TRUE) #> Fitting Linear Regression Experiment... #> Saving fit results... #> Fit results saved | time taken: 0.061489 seconds #> 100 reps completed (totals: 100/100) | time taken: 2.639569 minutes #> ============================== #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000330 minutes #> Saving eval results... #> Eval results saved | time taken: 0.042223 seconds #> ============================== #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.001341 minutes #> Saving viz results... #> Viz results saved | time taken: 0.099180 seconds #> ============================== vary_results$eval_results #> $`Rejection Prob. (alpha = 0.1)` #> # A tibble: 4 × 5 #>   .dgp_name           .method_name sigma `X1 Reject Prob.` `X2 Reject Prob.` #>   <chr>               <chr>        <dbl>             <dbl>             <dbl> #> 1 Linear Gaussian DGP OLS              1              1                 0.08 #> 2 Linear Gaussian DGP OLS              2              1                 0.12 #> 3 Linear Gaussian DGP OLS              4              0.98              0.08 #> 4 Linear Gaussian DGP OLS              8              0.58              0.11 vary_results$viz_results #> $Power # create rejection probability plot reject_prob_plot_fun <- function(eval_results, vary_params = NULL,                                  alpha = 0.05) {   eval_results <- eval_results$`Rejection Prob. (alpha = 0.1)`   if (is.list(eval_results[[vary_params]])) {     # deal with the case when we vary across a parameter that is vector-valued     eval_results[[vary_params]] <- list_col_to_chr(eval_results[[vary_params]],                                                    name = vary_params,                                                    verbatim = TRUE)   }   plt <- ggplot2::ggplot(eval_results) +     ggplot2::aes(x = .data[[vary_params]], y = `X1 Reject Prob.`,                  color = as.factor(.method_name),                  fill = as.factor(.method_name)) +     ggplot2::labs(x = vary_params,                   y = sprintf(\"Rejection Probability (alpha = %s)\", alpha),                   color = \"Method\", fill = \"Method\") +     ggplot2::scale_y_continuous(limits = c(0, 1))   if (is.numeric(eval_results[[vary_params]])) {     plt <- plt +       ggplot2::geom_line() +       ggplot2::geom_point(size = 2)   } else {     plt <- plt +       ggplot2::geom_bar(stat = \"identity\")   }   return(plotly::ggplotly(plt)) } reject_prob_plot <- create_visualizer(.viz_fun = reject_prob_plot_fun, alpha = 0.1)  experiment <- experiment %>%   add_visualizer(reject_prob_plot, name = \"Rejection Prob. (alpha = 0.1) Plot\")  # run experiment across values of beta_2 vary_beta2_results <- experiment %>%   remove_vary_across(dgp = \"Linear Gaussian DGP\") %>%   add_vary_across(.dgp = \"Linear Gaussian DGP\",                   beta = list(c(1, 0),                               c(1, 0.5),                               c(1, 1),                               c(1, 1.5),                               c(1, 2))) %>%   run_experiment(n_reps = 100, save = TRUE) #> Fitting Linear Regression Experiment... #> Saving fit results... #> Fit results saved | time taken: 0.053134 seconds #> 100 reps completed (totals: 100/100) | time taken: 3.259015 minutes #> ============================== #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000424 minutes #> Saving eval results... #> Eval results saved | time taken: 0.044051 seconds #> ============================== #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.004585 minutes #> Saving viz results... #> Viz results saved | time taken: 0.141874 seconds #> ==============================  # run experiment across values of rho (correlation) vary_cor_results <- experiment %>%   remove_vary_across(dgp = \"Linear Gaussian DGP\") %>%   add_vary_across(.dgp = \"Linear Gaussian DGP\",                   rho = c(0, 0.2, 0.5, 0.9)) %>%   run_experiment(n_reps = 100, save = TRUE) #> Fitting Linear Regression Experiment... #> Saving fit results... #> Fit results saved | time taken: 0.053913 seconds #> 100 reps completed (totals: 100/100) | time taken: 2.771877 minutes #> ============================== #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000264 minutes #> Saving eval results... #> Eval results saved | time taken: 0.043002 seconds #> ============================== #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.003174 minutes #> Saving viz results... #> Viz results saved | time taken: 0.150805 seconds #> ============================== render_docs(experiment, open = FALSE) #> Creating R Markdown report for Linear Regression Experiment... #> *Linear Gaussian DGP #> **Varying beta #>    Rejection Prob. (alpha = 0.1) #>    Power #>    Rejection Prob. (alpha = 0.1) Plot #> **Varying rho #>    Rejection Prob. (alpha = 0.1) #>    Power #>    Rejection Prob. (alpha = 0.1) Plot #> **Varying sigma #>    Rejection Prob. (alpha = 0.1) #>    Power render_docs(save_dir = experiment$get_save_dir(), open = FALSE)"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"simulation-experiment-templates","dir":"Articles","previous_headings":"","what":"Simulation Experiment Templates","title":"Getting started with simChef","text":"also provided boilerplate code templates running common types simulation experiments, namely, focused prediction (regression classification), feature selection, inference. templates provide (1) quick starting point Evaluators Visualizers commonly used specified type simulation experiment (2) concrete example get started using functions simChef library. Currently, implemented following templates: use_prediction_template(type = \"regression\") use_prediction_template(type = \"classification\") use_feature_selection_template() use_inference_template() functions print code console can easily copied /run. example, guidance, can also include concrete examples DGP Method via:","code":"use_prediction_template(type = \"regression\") #> dgp <- create_dgp( #>   dgp_fun = stop('Add DGP function here.'), #>   name = stop('Add name of DGP here.'), #>   stop('Add additional arguments (if necessary) to pass to DGP here.') #> )  #>  #> method <- create_method( #>   method_fun = stop('Add Method function here.'), #>   name = stop('Add name of Method here.'), #>   stop('Add additional arguments (if necessary) to pass to Method here.') #> )  #>  #> nested_pred_data <- stop('(Optional) Add name of column in `fit_results` with prediction result columns to be unnested.') #> true_pred_col <- stop('Add name of column in `fit_results` with true responses here.') #> est_pred_col <- stop('Add name of column in `fit_results` with the predicted responses here.') #>  #>  #> pred_err <- create_evaluator( #>   eval_fun = summarize_pred_err, #>   name = 'Prediction Accuracy', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   estimate_col = est_pred_col #> )  #>  #> pred_err_plot <- create_visualizer( #>   viz_fun = plot_pred_err, #>   name = 'Prediction Accuracy Plot', #>   evaluator_name = 'Prediction Accuracy' #> )  #>  #> experiment <- create_experiment(name = 'Prediction Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(pred_err) %>%  #>   add_visualizer(pred_err_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment) use_prediction_template(type = \"regression\",                         include_dgp_example = TRUE,                         include_method_example = TRUE) #> dgp <- create_dgp( #>   dgp_fun = xy_dgp_constructor, #>   name = 'Example DGP (Uncorrelated Gaussian Linear DGP)', #>   X_fun = generate_X_gaussian, #>   y_fun = generate_y_linear, #>   err_fun = rnorm, #>   n = 200, #>   p = 10, #>   betas = c(rep(1, 5), rep(0, 5)), #>   .err_sd = 1, #>   data_split = TRUE, #>   train_prop = 0.5, #>   return_support = TRUE #> )  #>  #> rf_method <-function (X, y, Xtest, ytest, support, ...)  #> { #>     data <- as.data.frame(X) %>% cbind(.y = y) #>     if (is.factor(y)) { #>         mtry <- round(sqrt(ncol(X))) #>     } #>     else { #>         mtry <- round(ncol(X)/3) #>     } #>     fit <- ranger::ranger(data = data, dependent.variable.name = \".y\",  #>         importance = \"impurity\", mtry = mtry, num.threads = 1,  #>         ...) #>     preds <- stats::predict(fit, as.data.frame(Xtest))$predictions #>     if (is.factor(y)) { #>         k <- nlevels(y) #>         prob_preds <- stats::predict(fit, as.data.frame(Xtest),  #>             predict.all = TRUE, num.threads = 1)$predictions #>         prob_preds <- purrr::map_dfr(1:nrow(prob_preds), function(i) { #>             x <- factor(prob_preds[i, ], levels = 1:k) #>             c(prop.table(table(x))) #>         }) %>% stats::setNames(levels(y)) %>% dplyr::select(-1) #>     } #>     else { #>         prob_preds <- NULL #>     } #>     p <- ncol(X) #>     if (is.null(colnames(X))) { #>         features <- 1:p #>     } #>     else { #>         features <- colnames(X) #>     } #>     out <- list(y = y, predictions = preds, prob_predictions = prob_preds,  #>         support_df = data.frame(feature = features, true_support = 1:p %in%  #>             support, imp = fit$variable.importance, selected = fit$variable.importance >  #>             mean(fit$variable.importance))) #>     return(out) #> }  #>  #> method <- create_method( #>   method_fun = rf_method, #>   name = 'RF' #> )  #>  #> nested_pred_data <- c('y', 'predictions', 'prob_predictions')  # prediction results columns to be unnested #> true_pred_col <- 'y'  # true response column #> est_pred_col <- 'predictions'  # predicted response column #>  #>  #> pred_err <- create_evaluator( #>   eval_fun = summarize_pred_err, #>   name = 'Prediction Accuracy', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   estimate_col = est_pred_col #> )  #>  #> pred_err_plot <- create_visualizer( #>   viz_fun = plot_pred_err, #>   name = 'Prediction Accuracy Plot', #>   evaluator_name = 'Prediction Accuracy' #> )  #>  #> experiment <- create_experiment(name = 'Prediction Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(pred_err) %>%  #>   add_visualizer(pred_err_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment)"},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"the-experiment-r6-class","dir":"Articles","previous_headings":"Additional notes and usage","what":"The Experiment R6 Class","title":"Getting started with simChef","text":"important note Experiment() class R6. , need careful clones versus pointers. following, may look like vary_experiment object vary_across component experiment object vary_across component. However, experiment piped add_vary_across(), modifying experiment, vary_experiment simply pointing modified experiment.","code":"experiment <- experiment %>%   remove_vary_across(dgp = \"Linear Gaussian DGP\") experiment #> Experiment Name: Linear Regression Experiment  #>    Saved results at: results/Linear Regression Experiment  #>    DGPs: Linear Gaussian DGP  #>    Methods: OLS  #>    Evaluators: Rejection Prob. (alpha = 0.1)  #>    Visualizers: Power, Rejection Prob. (alpha = 0.1) Plot  #>    Vary Across: None vary_experiment <- experiment %>%   add_vary_across(.dgp = \"Linear Gaussian DGP\", sigma = c(1, 2, 4, 8)) all.equal(vary_experiment, experiment) #> [1] TRUE data.table::address(experiment) == data.table::address(vary_experiment) #> [1] TRUE experiment #> Experiment Name: Linear Regression Experiment  #>    Saved results at: results/Linear Regression Experiment  #>    DGPs: Linear Gaussian DGP  #>    Methods: OLS  #>    Evaluators: Rejection Prob. (alpha = 0.1)  #>    Visualizers: Power, Rejection Prob. (alpha = 0.1) Plot  #>    Vary Across:  #>       DGP: Linear Gaussian DGP  #>          sigma:  num [1:4] 1 2 4 8"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"creating-an-experiment-from-another-experiment","dir":"Articles","previous_headings":"Additional notes and usage","what":"Creating an experiment from another experiment","title":"Getting started with simChef","text":"modify vary_experiment without making changes experiment, need create vary_experiment new experiment explicitly cloning old experiment experiment. creating Experiment clone, making deep clone parent experiment’s DGPs, Methods, Evaluators, Visualizers, vary_across component. thus need add vary_across component vary_experiment using add_vary_across(). can also add/update DGPs, Methods, Evaluators, Visualizers cloned experiment without modifying parent experiment.","code":"vary_experiment <- create_experiment(name = \"I am a clone\",                                      clone_from = experiment) data.table::address(experiment) == data.table::address(vary_experiment) #> [1] FALSE vary_experiment #> Experiment Name: I am a clone  #>    Saved results at: results/Linear Regression Experiment  #>    DGPs: Linear Gaussian DGP  #>    Methods: OLS  #>    Evaluators: Rejection Prob. (alpha = 0.1)  #>    Visualizers: Power, Rejection Prob. (alpha = 0.1) Plot  #>    Vary Across: None # this works without an error vary_experiment <- vary_experiment %>%   add_vary_across(.dgp = \"Linear Gaussian DGP\", sigma = c(1, 2, 4, 8)) # add DGP dgp_new <- create_dgp(.dgp_fun = dgp_fun, .name = \"Linear Gaussian DGP (large n)\",                       n = 500, beta = c(1, 0), rho = 0, sigma = 1) vary_experiment <- vary_experiment %>%   add_dgp(dgp_new, \"Linear Gaussian DGP (large n)\") vary_experiment #> Experiment Name: I am a clone  #>    Saved results at: results/Linear Regression Experiment  #>    DGPs: Linear Gaussian DGP, Linear Gaussian DGP (large n)  #>    Methods: OLS  #>    Evaluators: Rejection Prob. (alpha = 0.1)  #>    Visualizers: Power, Rejection Prob. (alpha = 0.1) Plot  #>    Vary Across:  #>       DGP: Linear Gaussian DGP  #>          sigma:  num [1:4] 1 2 4 8 experiment #> Experiment Name: Linear Regression Experiment  #>    Saved results at: results/Linear Regression Experiment  #>    DGPs: Linear Gaussian DGP  #>    Methods: OLS  #>    Evaluators: Rejection Prob. (alpha = 0.1)  #>    Visualizers: Power, Rejection Prob. (alpha = 0.1) Plot  #>    Vary Across:  #>       DGP: Linear Gaussian DGP  #>          sigma:  num [1:4] 1 2 4 8"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"using-cached-results-from-an-experiment","dir":"Articles","previous_headings":"Additional notes and usage","what":"Using cached results from an experiment","title":"Getting started with simChef","text":"reduce computation, one may want avoid re-running previously computed saved components Experiment. can done setting argument use_cached TRUE run_experiment(). specifically, Experiment run use_cached = TRUE, previously cached results (.e., previously saved disk save = TRUE) loaded checked corresponding Experiment matches configurations current Experiment. cached Experiment configurations indeed match current Experiment, cached results used uncached components Experiment run. example, let us run following experiment save results. setting use_cached = TRUE, following line code generate new results instead simply read saved cached results disk. can also choose read smaller number cached replicates increase number replicates without re-computation previously cached replicates addition, caching works intuitively adding modifying components Experiment. following, add new DGP Experiment, run Experiment use_cached = TRUE, replicates involving new DGP run replicates involving old DGP (.e., Linear Gaussian DGP) loaded cache. Note since save Experiment results , following re-run replicates corresponding new DGP . Please set save = TRUE order cache results future use. helpful functions regarding caching include:","code":"orig_results <- experiment$run(n_reps = 100, save = TRUE) #> Fitting Linear Regression Experiment... #> Saving fit results... #> Fit results saved | time taken: 0.064421 seconds #> 100 reps completed (totals: 100/100) | time taken: 3.065995 minutes #> ============================== #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000254 minutes #> Saving eval results... #> Eval results saved | time taken: 0.045188 seconds #> ============================== #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.003177 minutes #> Saving viz results... #> Viz results saved | time taken: 0.152892 seconds #> ============================== cached_results <- experiment$run(n_reps = 100, use_cached = TRUE) #> Reading in cached fit results... #> ============================== #> Reading in cached eval results... #> ============================== #> Reading in cached viz results... #> ============================== all.equal(orig_results, cached_results) #> [1] TRUE smaller_results <- experiment$run(n_reps = 10, use_cached = TRUE) #> Reading in cached fit results... #> ============================== #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000338 minutes #> ============================== #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.002840 minutes #> ============================== max(as.numeric(smaller_results$fit_results$.rep)) #> [1] 10 larger_results <- experiment$run(n_reps = 150, use_cached = TRUE) #> Reading in cached fit results... #> Fitting Linear Regression Experiment... #> 50 reps completed (totals: 150/150) | time taken: 1.499279 minutes #> ============================== #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000244 minutes #> ============================== #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.002846 minutes #> ============================== all.equal(orig_results$fit_results,           larger_results$fit_results %>% dplyr::filter(as.numeric(.rep) <= 100)) #> [1] TRUE experiment <- experiment %>% add_dgp(dgp = dgp_new, name = \"New DGP\") new_results <- experiment$run(n_reps = 100, use_cached = TRUE) #> Fitting Linear Regression Experiment... #> Reading in cached fit results... #> Appending cached results to the new fit results... #> 100 reps completed (totals: 100/100) | time taken: 0.979687 minutes #> ============================== #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000239 minutes #> ============================== #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.002800 minutes #> ============================== all.equal(new_results$fit_results %>% dplyr::filter(.dgp_name == \"Linear Gaussian DGP\"),           orig_results$fit_results) #> [1] TRUE new_results2 <- experiment$run(n_reps = 100, use_cached = TRUE) #> Fitting Linear Regression Experiment... #> Reading in cached fit results... #> Appending cached results to the new fit results... #> 100 reps completed (totals: 100/100) | time taken: 0.957091 minutes #> ============================== #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000209 minutes #> ============================== #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.002409 minutes #> ============================== identical(new_results$fit_results %>% dplyr::filter(.dgp_name == \"New DGP\"),           new_results2$fit_results %>% dplyr::filter(.dgp_name == \"New DGP\")) #> [1] FALSE # to load in the cached fit results for an experiment fit_results <- get_cached_results(experiment, \"fit\") # to load in the cached evaluation results for an experiment eval_results <- get_cached_results(experiment, \"eval\") # to load in the cached visualization results for an experiment viz_results <- get_cached_results(experiment, \"viz\") # to load in the cached Experiment object experiment <- get_cached_results(experiment, \"experiment\") # to load in the Experiment parameters corresponding to the cached *_results cached_exp_params <- get_cached_results(experiment, \"experiment_cached_params\")  # to clear the cache clear_cache(experiment)"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"using-checkpoints-within-an-experiment","dir":"Articles","previous_headings":"Additional notes and usage","what":"Using checkpoints within an experiment","title":"Getting started with simChef","text":"checkpoint periodic snapshot simulation results, saved disk. Checkpoints help guard lost progress case unexpected problems, node failures running cluster, cost longer simulation running times. Checkpoints useful long-running simulations cost creating checkpoints small relative total cost simulation. result, users careful create checkpoints often necessary. enable checkpointing, use positive value argument checkpoint_n_reps passed Experiment$run() Experiment$fit(). example simulation run use checkpointing encounter errors simulation progresses past first checkpoint: Since full 25 replicates completed simulation failed, first checkpoint successful. can use get_cached_results(experiment, \"fit\") examine completed replicates, simply continue simulation using code already ran:","code":"# create a new experiment experiment <- create_experiment(name = \"checkpoint-exper\") %>%   ... # add dgps, methods, etc.  # run 100 reps of the experiment, checkpointing every 25 reps experiment$fit(n_reps = 100, checkpoint_n_reps = 25) #> Fitting checkpoint-exper... #> 25 reps completed (totals: 25/100) | time taken: 0.060645 minutes #> Saving fit results checkpoint... #> Fit results saved | time taken: 0.080968 seconds  # the simulation fails here! experiment$fit(n_reps = 100, checkpoint_n_reps = 25) #> Reading in cached fit results... #> Fitting checkpoint-exper... #> 25 reps completed (totals: 50/100) | time taken: 0.066513 minutes #> Saving fit results checkpoint... #> Fit results saved | time taken: 0.133003 seconds #> 25 reps completed (totals: 75/100) | time taken: 0.125143 minutes #> Saving fit results checkpoint... #> Fit results saved | time taken: 0.107203 seconds #> 25 reps completed (totals: 100/100) | time taken: 0.184656 minutes #> Saving fit results... #> Fit results saved | time taken: 0.124632 seconds #> =============================="},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"additional-r-markdown-notes-and-options","dir":"Articles","previous_headings":"Additional notes and usage","what":"Additional R Markdown notes and options","title":"Getting started with simChef","text":"several customizable options regarding aesthetics Evaluators Visualizers displayed Rmd report. can modified using doc_options argument create_evaluator() create_visualizer(). example, can customize height width Power plot via number digits evaluation table outputs via Alternatively, set_doc_options() can used update R Markdown option existing object, rather recreate Evaluator() Visualizer() scratch, e.g., hide output Evaluator() Visualizer() R Markdown report, set show = FALSE set_doc_options() create_*. additional customization options can set render_docs() including order results Evaluators Visualizers displayed (via eval_order viz_order arguments) Rmd output type theme. example,","code":"power_plot <- create_visualizer(.viz_fun = power_plot_fun,                                 .doc_options = list(height = 10, width = 8)) experiment <- experiment %>%   update_visualizer(power_plot, \"Power\") reject_prob_eval <- create_evaluator(.eval_fun = reject_prob_fun, alpha = 0.1,                                      .doc_options = list(digits = 3)) experiment <- experiment %>%   update_evaluator(reject_prob_eval, \"Rejection Prob. (alpha = 0.1)\") experiment <- experiment %>%   set_doc_options(field_name = \"visualizer\", name = \"Power\", show = TRUE,                   height = 10, width = 8) # use html_document instead of rmdformats::material (default) render_docs(experiment, open = FALSE, pretty = FALSE,             output_format = rmarkdown::html_document())  # add custom css style render_docs(experiment, open = FALSE, pretty = FALSE,             output_options = list(css = \"path/to/file.css\"))"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"saving-results","dir":"Articles","previous_headings":"Additional notes and usage","what":"Saving results","title":"Getting started with simChef","text":"Since R Markdown report heavily relies results file structure organize report summary, may helpful understand default saving structure utilized simChef. default, root results directory ./results/{EXPERIMENT_NAME}. experiment created cloning another experiment, default results directory parent experiment. change root results directory, one can specify desired directory via save_dir argument create_experiment() use set_save_dir() helper function. results experiment$run(..., save = TRUE) without vary_across component saved root results directory. experiment vary_across component, results experiment$run(..., save = TRUE) saved ./{ROOT_RESULTS_DIR}/{DGP_OR_METHOD_NAME}/Varying {PARAM_NAME}/. ’s directory tree “Linear Regression Experiment” example:","code":"fs::dir_tree(get_save_dir(experiment)) #> results #> ├── Linear Gaussian DGP #> │   ├── Varying beta #> │   │   ├── eval_results.rds #> │   │   ├── experiment.rds #> │   │   ├── experiment_cached_params.rds #> │   │   ├── fit_results.rds #> │   │   └── viz_results.rds #> │   ├── Varying rho #> │   │   ├── eval_results.rds #> │   │   ├── experiment.rds #> │   │   ├── experiment_cached_params.rds #> │   │   ├── fit_results.rds #> │   │   └── viz_results.rds #> │   └── Varying sigma #> │       ├── eval_results.rds #> │       ├── experiment.rds #> │       ├── fit_results.rds #> │       └── viz_results.rds #> ├── Linear Regression Experiment.html #> ├── docs #> │   ├── dgps #> │   │   └── Linear Gaussian DGP.md #> │   ├── evaluators #> │   │   └── Rejection Prob. (alpha = 0.1).md #> │   ├── methods #> │   │   └── OLS.md #> │   ├── objectives.md #> │   └── visualizers #> │       ├── Power.md #> │       └── Rejection Prob. (alpha = 0.1) Plot.md #> ├── eval_results.rds #> ├── experiment.rds #> ├── experiment_cached_params.rds #> ├── fit_results.rds #> └── viz_results.rds"},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"additional-handling-of-the-experiment","dir":"Articles","previous_headings":"Additional notes and usage","what":"Additional handling of the experiment","title":"Getting started with simChef","text":"Experiment$run() easiest concise way running simulation experiment start finish. However, debugging developing simulation experiment, may helpful run parts experiment repeat time-consuming, redundant computations. split experimental run following three parts: experiment$fit(): fit Method(s) experiment multiple replicates DGP(s) return results fits experiment$evaluate(): evaluate experiment Evaluator(s) return evaluation results experiment$visualize(): create visualizations fit/evaluation results experiment using Visualizer(s) return visualization results alternatively, Experiment$run() simply wrapper around three functions: fit(), evaluate(), visualize(). Thus far, neither stored returned data DGPs since can large objects require high memory loads n_reps large. However, one can generate small samples data DGPs experiment via alternatively, might helpful exploratory data analysis diagnosis experiment results. helpful methods handling experiment include get_* family methods, .e.,","code":"fit_results <- experiment$fit(n_reps = 100) #> Fitting Linear Regression Experiment... #> 100 reps completed (totals: 100/100) | time taken: 2.864435 minutes #> ============================== eval_results <- experiment$evaluate(fit_results) #> Evaluating Linear Regression Experiment... #> Evaluation completed | time taken: 0.000241 minutes #> ============================== viz_results <- experiment$visualize(fit_results, eval_results) #> Visualizing Linear Regression Experiment... #> Visualization completed | time taken: 0.002778 minutes #> ============================== fit_results <- fit_experiment(experiment, n_reps = 100) eval_results <- evaluate_experiment(experiment, fit_results) viz_results <- visualize_experiment(experiment, fit_results, eval_results) data_list <- experiment$generate_data(n_reps = 1) str(data_list) #> List of 1 #>  $ Linear Gaussian DGP:List of 4 #>   ..$ :List of 1 #>   .. ..$ :List of 2 #>   .. .. ..$ X: num [1:200, 1:2] -0.992 0.859 0.282 -2.066 0.612 ... #>   .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. ..$ : NULL #>   .. .. .. .. ..$ : NULL #>   .. .. ..$ y: num [1:200, 1] -1.963 0.698 1.486 -2 -0.271 ... #>   .. ..- attr(*, \"params\")=List of 1 #>   .. .. ..$ sigma: num 1 #>   ..$ :List of 1 #>   .. ..$ :List of 2 #>   .. .. ..$ X: num [1:200, 1:2] 0.741 -0.252 0.337 -0.948 0.66 ... #>   .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. ..$ : NULL #>   .. .. .. .. ..$ : NULL #>   .. .. ..$ y: num [1:200, 1] 0.182 -1.544 -0.694 -3.697 2.681 ... #>   .. ..- attr(*, \"params\")=List of 1 #>   .. .. ..$ sigma: num 2 #>   ..$ :List of 1 #>   .. ..$ :List of 2 #>   .. .. ..$ X: num [1:200, 1:2] -1.14 0.459 0.921 0.304 -0.268 ... #>   .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. ..$ : NULL #>   .. .. .. .. ..$ : NULL #>   .. .. ..$ y: num [1:200, 1] -0.62915 4.95518 5.8273 4.42944 0.00406 ... #>   .. ..- attr(*, \"params\")=List of 1 #>   .. .. ..$ sigma: num 4 #>   ..$ :List of 1 #>   .. ..$ :List of 2 #>   .. .. ..$ X: num [1:200, 1:2] -0.7129 0.5489 -0.0244 0.4301 0.8951 ... #>   .. .. .. ..- attr(*, \"dimnames\")=List of 2 #>   .. .. .. .. ..$ : NULL #>   .. .. .. .. ..$ : NULL #>   .. .. ..$ y: num [1:200, 1] 8.32 -8.35 -6.84 -5.13 -6.03 ... #>   .. ..- attr(*, \"params\")=List of 1 #>   .. .. ..$ sigma: num 8 data_list <- generate_data(experiment, n_reps = 1) get_dgps(experiment)         # or `experiment$get_dgps()` #> $`Linear Gaussian DGP` #> DGP Name: Linear Gaussian DGP  #>    Function: function (n, beta, rho, sigma)   #>    Parameters: List of 4 #>      $ n    : num 200 #>      $ beta : num [1:2] 1 0 #>      $ rho  : num 0 #>      $ sigma: num 1 get_methods(experiment)      # or `experiment$get_methods()` #> $OLS #> Method Name: NULL  #>    Function: function (X, y, cols = c(\"X1\", \"X2\"))   #>    Parameters:  list() get_evaluators(experiment)   # or `experiment$get_evaluators()` #> $`Rejection Prob. (alpha = 0.1)` #> Evaluator Name: NULL  #>    Function: function (fit_results, vary_params = NULL, alpha = 0.05)   #>    Parameters: List of 1 #>      $ alpha: num 0.1 #>    R Markdown Options: List of 3 #>      $ digits : num 3 #>      $ sigfig : logi FALSE #>      $ options:List of 2 #>       ..$ scrollX       : logi TRUE #>       ..$ scrollCollapse: logi TRUE #>    Show in R Markdown: TRUE get_visualizers(experiment)  # or `experiment$get_visualizers()` #> $Power #> Visualizer Name: NULL  #>    Function: function (fit_results, vary_params = NULL, col = \"X1\")   #>    Parameters:  list() #>    R Markdown Options: List of 2 #>      $ height: num 10 #>      $ width : num 8 #>    Show in R Markdown: TRUE  #>  #> $`Rejection Prob. (alpha = 0.1) Plot` #> Visualizer Name: NULL  #>    Function: function (eval_results, vary_params = NULL, alpha = 0.05)   #>    Parameters: List of 1 #>      $ alpha: num 0.1 #>    R Markdown Options: List of 2 #>      $ height: num 6 #>      $ width : num 10 #>    Show in R Markdown: TRUE get_vary_across(experiment)  # or `experiment$get_vary_across()` #> $dgp #> $dgp$`Linear Gaussian DGP` #> $dgp$`Linear Gaussian DGP`$sigma #> [1] 1 2 4 8 #>  #>  #>  #> $method #> list() get_save_dir(experiment)     # or `experiment$get_save_dir()` #> [1] \"./results/Linear Regression Experiment\""},{"path":"https://yu-group.github.io/simChef/dev/articles/simChef.html","id":"error-debugging","dir":"Articles","previous_headings":"Additional notes and usage","what":"Error debugging","title":"Getting started with simChef","text":"event error, simChef makes possible retrieve results completed replicates (error occurred) gracefully debug errors user-defined functions. sake demonstration, let us create artificial example. working interactively, error can inspected using usual call rlang::last_error(). Results run completed error can recovered via rlang::last_error()$partial_results can find errors occurred within simulation loop via rlang::last_error()$errors. Alternatively, can wrap call ran error (case, run_experiment()) tryCatch() follows: , can view results completed ran error via extract error object(s) via Note error tibble contains DGP Method (DGP error cause) processed error occurred .dgp .method columns, respectively. corresponding input parameters .dgp_params .method_params columns (NA since parameters varied experiment). Finally, captured error .err column. Using , can easily investigate reproduce error desired, work directly user-specified function raised error, e.g.,","code":"# create experiment dgp_fun <- function() return(\"data\") dgp_fun_err <- function() { stop(\"Uh oh!\") } dgp <- create_dgp(dgp_fun) dgp_err <- create_dgp(dgp_fun_err) method_fun <- function(x) return(\"result\") method <- create_method(method_fun) experiment <- create_experiment(   dgp_list = list(\"Working DGP\" = dgp, \"Buggy DGP\" = dgp_err),   method_list = list(\"Method\" = method) )  # run experiment though it should return an error results <- run_experiment(experiment, n_reps = 2) #> Fitting experiment... #> Error in `self$fit()`: #> ! Error(s) encountered while running the simulation, including: #>  #> Uh oh! #> The above error occurred while processing \"Buggy DGP\" (params empty). #>  #> Use `rlang::last_error()$partial_results`to return partial simulation results and `rlang::last_error()$errors` to get simulation errors with the `DGP`, `Method`, and params that led to the error. results <- tryCatch(run_experiment(experiment, n_reps = 2),                     error = identity) #> Fitting experiment... results #> <error/simChef_error> #> Error in `self$fit()`: #> ! Error(s) encountered while running the simulation, including: #>  #> Uh oh! #> The above error occurred while processing \"Buggy DGP\" (params empty). #>  #> Use `rlang::last_error()$partial_results`to return partial simulation results and `rlang::last_error()$errors` to get simulation errors with the `DGP`, `Method`, and params that led to the error. #> --- #> Backtrace: #>  1. base::tryCatch(run_experiment(experiment, n_reps = 2), error = identity) #>  5. simChef::run_experiment(experiment, n_reps = 2) #>  6. experiment$run(...) #>  7. self$fit(...) results$partial_results #> # A tibble: 1 × 4 #>   .rep  .dgp_name   .method_name result1 #>   <chr> <chr>       <chr>        <chr>   #> 1 1     Working DGP Method       result results$errors #> # A tibble: 1 × 9 #>   .dgp   .dgp_name .dgp_params .method .method_name .method_params .err        .pid .gc           #>   <list> <chr>     <lgl>       <lgl>   <chr>        <lgl>          <list>     <int> <list>        #> 1 <DGP>  Buggy DGP NA          NA      NA           NA             <smChf_rr> 17149 <dbl [2 × 6]> # get dgp that ran the error err_fun <- results$errors$.dgp[[1]]$dgp_fun # reproduce error via a direct call to the DGP function that raised the error err_fun() #> Error in err_fun(): Uh oh!"},{"path":"https://yu-group.github.io/simChef/dev/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"James Duncan. Author, maintainer. Tiffany Tang. Author. Corrine F. Elliott. Contributor. Philippe Boileau. Contributor. Yu Bin. Thesis advisor.","code":""},{"path":"https://yu-group.github.io/simChef/dev/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Duncan J, Tang T (2022). simChef: Intensive Computational Experiments Made Easy. R package version 0.0.2.9000, https://yu-group.github.io/simChef.","code":"@Manual{,   title = {simChef: Intensive Computational Experiments Made Easy},   author = {James Duncan and Tiffany Tang},   year = {2022},   note = {R package version 0.0.2.9000},   url = {https://yu-group.github.io/simChef}, }"},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Intensive Computational Experiments Made Easy","text":"goal simChef help quickly cook fully-realized, high-quality, reproducible, transparently documented simulation study using intuitive tidy grammar simulation experiments:","code":"experiment <- create_experiment() %>%   add_dgp(dgp1) %>%   add_dgp(dgp2) %>%   add_method(method1) %>%   add_vary_across(     dgp = dgp1,     n = c(100, 1000, 10000)   ) %>%   add_vary_across(     method = method1,     lambda = c(0.1, 0.5, 1.0)   )  results <- experiment %>%   run_experiment()"},{"path":"https://yu-group.github.io/simChef/dev/index.html","id":"installation","dir":"","previous_headings":"Overview","what":"Installation","title":"Intensive Computational Experiments Made Easy","text":"simChef active development. install package directly GitHub, please use:","code":"devtools::install_github(\"Yu-Group/simChef\")"},{"path":"https://yu-group.github.io/simChef/dev/index.html","id":"concepts","dir":"","previous_headings":"Overview","what":"Concepts","title":"Intensive Computational Experiments Made Easy","text":"simChef, simulation studies decomposed five intuitive concepts: experiments, data-generating processes, methods, evaluations, visualizations. simulation can either contained single experiment divided multiple self-contained experiments like small simulations studies right. Every experiment turn composed four parts, two optional (highly recommended): data-generating processes (DGPs), methods, evaluation (optional), visualization (optional). simChef takes object-oriented approach encapsulate simulation concepts, using R6 classes make concrete. five main objects : Experiment: corresponds experiment concept. can probably guess, class main powerhouse simulation, collecting related DGPs methods, keeping track parameters vary, checkpointing saving results, producing evaluations metrics, visualizations, documentation simulation’s findings can understood easily communicated. Moreover, uses future compute experimental replicates parallel using whatever resources choose. DGP: corresponds data-generating process concept. DGPs simply generate synthetic data reproducible flexible manner, size manner specify. library preset highly customizable DGPs, including support data-driven DGPs give added realism synthetic data, simChef sibling R package, dgpoix (currently early development). Method: corresponds method concept, can either baseline, target simulation study, means transform raw synthetic data. Together DGPs, methods make main computational course simChef meal. Evaluator: corresponds evaluation concept. computation experimental replicates completed, evaluators receive results summarize produce meaningful statistics experiment, simply transform results (e.g., using summary statistics). optional step, without experiment’s results can much difficult understand communicate. Visualizer: corresponds visualization concept. visualizations can applied directly raw experimental replicates’ outputs, can instead work evaluation transformations/summaries, . Visualizers can output anything can rendered R Markdown document: static interactive plots, tables, strings captured output, markdown, generic HTML, etc.","code":""},{"path":"https://yu-group.github.io/simChef/dev/index.html","id":"simulation-study-documentation","dir":"","previous_headings":"Overview","what":"Simulation study documentation","title":"Intensive Computational Experiments Made Easy","text":"put together, Experiment class can output R Markdown document structured provide well-organized summary simulation study. Moreover, document can contain multiple experiments, simply using common output path Experiment study. simulation complete, can use render_docs() helper generate documentation: results HTML document like one shown : Interactive R Markdown simulation documentation examples, including interactive version simulation study documentation, see vignette(\"simChef\").","code":"render_docs(experiment)"},{"path":"https://yu-group.github.io/simChef/dev/index.html","id":"origins-of-simchef","dir":"","previous_headings":"","what":"Origins of simChef","title":"Intensive Computational Experiments Made Easy","text":"2020 paper “Veridical Data Science”, Yu Kumbier propose predictability, computability, stability (PCS) framework, workflow documentation “responsible, reliable, reproducible, transparent results across data science life cycle”. umbrella PCS framework, began process deriving set guidelines tailored specifically simulation studies, inspired high-quality simulation studies literature simulations examine statistical properties methods within PCS framework. creating simulations, soon found existing R package fully satisfy developing requirements. began toolbox simulations became simChef. believe tools useful anyone intending create simulation studies R.","code":""},{"path":"https://yu-group.github.io/simChef/dev/index.html","id":"thinking-like-a-chef","dir":"","previous_headings":"Origins of simChef","what":"Thinking like a chef","title":"Intensive Computational Experiments Made Easy","text":"development simChef guided love … cooking? Perhaps surprisingly, found cooking serves useful analogy process creating simulation study. Consider following components high-quality meal: Nutritious delicious ingredients – good meals start good ingredients, true simulation experiments. realistic simulation data (entirely synthetic driven real-world data) available, hope producing high-quality simulations. Creating realistic synthetic data primary goal sibling package dgpoix, initially integrated simChef. Skill experience chef – Just every chef’s cooking informed handful cuisines specialize, simulation experiments motivated scientific questions particular domain. Just chef become expert knifemaker cooking first meal, domain scientist waste time writing boilerplate code computation documentation simulations. simChef takes care details running experiments across potentially large number data method perturbations care , freeing time focus scientific question. High-quality tools kitchen – package like excellent chef’s knife kitchen essential. chef’s knife doesn’t cut straight isn’t sharpened, kitchen speed safety suffers, final presentation. simChef won’t cook good simulation experiment , get less effort higher-quality presentation helping follow best-practices like reproducibility minimal effort part. sharpening required! high-quality meal possible almost environment – scale delicious meal may limited environment, high-quality meals found world’s Michelin-starred restaurants also home kitchens street food carts around world. effective simulation framework also agnostic environment, simChef runs equally well laptop high-performance computing cluster. Appetizing approachable presentation – Ultimately, chef prepares food specific audience, presentation almost equal importance underlying substance meal. However, chef doesn’t build plate serve food. simChef provides tools turn simulation experiment results effective displays quantitative information populated within preset customizable R Markdown templates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/index.html","id":"roadmap","dir":"","previous_headings":"","what":"Roadmap","title":"Intensive Computational Experiments Made Easy","text":"Implement abstract API allow grammar simulation experiments. Run experimental replicates parallel agnostic computational backend via R package future. Output automated R Markdown report summarizing results Experiment. Allow varying simulation experiments across arbitrary parameters DGPs Methods. Cache results avoid re-running already computed components Experiment. Checkpoint simulations avoid losing progress case unexpected problems, e.g. node failure. Gracefully handle errors user-defined functions return partial results error information user inspect upon completion. Incorporate progressr simulation progress updates. Include set --shelf DGPs (moved dgpoix), Evaluators, Visualizers allow users quickly run methods number common types simulations. Allow user customization final R Markdown report (e.g. customized R Markdown template/theme, order Evaluator Visualizer displays). Give user ability choose tasks distributed parallel workers, .e. simulation replicates, DGPs, Methods, combinations three. Enable nested parallelization, e.g. one may paralellize across DGPs using multiple nodes cluster parallelize across simulation replicates using CPU cores within node. Publish CRAN.","code":""},{"path":"https://yu-group.github.io/simChef/dev/index.html","id":"related-r-packages","dir":"","previous_headings":"","what":"Related R packages","title":"Intensive Computational Experiments Made Easy","text":", examine main functionality number existing tools running reproducible simulation experiments currently available CRAN updated within last couple years. batchtools implements abstractions “problems” (similar DGP concept), “algorithms” (Method simChef), “experiments”. addition shared-memory computation via parallel snow packages, also provides number utilities working high performance computing batch systems Slurm Torque, simChef supports via future.batchtools package. SimDesign provides helper functions define experimental conditions pass experimental conditions user-defined data generation function, analysis function, summary function. package also provides number functions user choose . experimental condition can run many replicates, computing results parallel via parallel package. simhelpers defines functions calculate Monte Carlo standard errors simulation performance metrics, generate skeleton simulation code, evaluate parallel across simulation parameters via future package. simTool package two main functions: expand_tibble() eval_tibble(). former wraps base R function expand.grid() create cartesian product simulation functions parameters, latter evaluates functions parallel via parallel package. parSim package implements single function name allows parallelization arbitrary R expressions across replicates simulation conditions. parSim uses snow package setup parallel backends. rsimsum R implementation Stata command simsum provides helper functions summarizing visualizing results simulation study.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/DGP.html","id":null,"dir":"Reference","previous_headings":"","what":"R6 class representing a data-generating process. — DGP","title":"R6 class representing a data-generating process. — DGP","text":"data-generating process used Experiment generate data.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/DGP.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"R6 class representing a data-generating process. — DGP","text":"name name DGP. dgp_fun data-generating process function. dgp_params (Named) list parameters input data-generating process function.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/DGP.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"R6 class representing a data-generating process. — DGP","text":"DGP$new() See create_dgp.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Evaluator.html","id":null,"dir":"Reference","previous_headings":"","what":"R6 class representing an evaluator. — Evaluator","title":"R6 class representing an evaluator. — Evaluator","text":"evaluator (evaluation function) evaluate performance methods Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Evaluator.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"R6 class representing an evaluator. — Evaluator","text":"name name Evaluator. eval_fun evaluation function. eval_params (Named) list parameters input evaluation function. doc_options List options control aesthetics displayed Evaluator's results table knitted R Markdown report. See vthemes::pretty_DT() possible options. doc_show TRUE (default), show Evaluator's results table R Markdown report; FALSE, hide output R Markdown report.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Evaluator.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"R6 class representing an evaluator. — Evaluator","text":"Evaluator$new() See create_evaluator.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Experiment.html","id":null,"dir":"Reference","previous_headings":"","what":"R6 class representing a simulation experiment. — Experiment","title":"R6 class representing a simulation experiment. — Experiment","text":"simulation experiment number DGPs, Methods, Evaluators, Visualizers.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Experiment.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"R6 class representing a simulation experiment. — Experiment","text":"run, Experiment seamlessly combines DGPs Methods, computing results parallel. results can evaluated using Evaluators visualized using Visualizers.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Experiment.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"R6 class representing a simulation experiment. — Experiment","text":"name name Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Experiment.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"R6 class representing a simulation experiment. — Experiment","text":"Experiment$new() See create_experiment. Experiment$run() See run_experiment. Experiment$generate_data() See generate_data. Experiment$fit() See fit_experiment. Experiment$evaluate() See evaluate_experiment. Experiment$visualize() See visualize_experiment. Experiment$init_docs() See init_docs. Experiment$render_docs() See render_docs. Experiment$add_dgp() See add_dgp. Experiment$update_dgp() See update_dgp. Experiment$remove_dgp() See remove_dgp. Experiment$get_dgps() See get_dgps. Experiment$add_method() See add_method. Experiment$update_method() See update_method. Experiment$remove_method() See remove_method. Experiment$get_methods() See get_methods. Experiment$add_evaluator() See add_evaluator. Experiment$update_evaluator() See update_evaluator. Experiment$remove_evaluator() See remove_evaluator. Experiment$get_evaluators() See get_evaluators. Experiment$add_visualizer() See add_visualizer. Experiment$update_visualizer() See update_visualizer. Experiment$remove_visualizer() See remove_visualizer. Experiment$get_visualizers() See get_visualizers. Experiment$add_vary_across() See add_vary_across. Experiment$update_vary_across() See update_vary_across. Experiment$remove_vary_across() See remove_vary_across. Experiment$get_vary_across() See get_vary_across. Experiment$clear_cache() See clear_cache. Experiment$get_cached_results() See get_cached_results. Experiment$set_doc_options() See set_doc_options. Experiment$set_save_dir() See set_save_dir. Experiment$save() See save_experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Method.html","id":null,"dir":"Reference","previous_headings":"","what":"R6 class representing a method. — Method","title":"R6 class representing a method. — Method","text":"method fit assessed Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Method.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"R6 class representing a method. — Method","text":"name name Method. method_fun data-generating process function. method_params (Named) list parameters input data-generating process function.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Method.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"R6 class representing a method. — Method","text":"Method$new() See create_method.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Visualizer.html","id":null,"dir":"Reference","previous_headings":"","what":"R6 class representing a visualizer. — Visualizer","title":"R6 class representing a visualizer. — Visualizer","text":"visualizer (visualization function) visualize performance methods /evaluation metrics Experiment run.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Visualizer.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"R6 class representing a visualizer. — Visualizer","text":"name name Visualizer. viz_fun visualizer function. viz_params (Named) list parameters input visualizer function. doc_options List options control aesthetics displayed Visualizer's visualizations knitted R Markdown report. Currently, possible options \"height\" \"width\" (inches). doc_show TRUE (default), show resulting visualization R Markdown report; FALSE, hide output R Markdown report.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/Visualizer.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"R6 class representing a visualizer. — Visualizer","text":"Visualizer$new() See create_visualizer.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/abort.html","id":null,"dir":"Reference","previous_headings":"","what":"Signals an error with default subclass ","title":"Signals an error with default subclass ","text":"Signals error default subclass \"simChef_error\".","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/abort.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Signals an error with default subclass ","text":"","code":"abort(message = NULL, class = \"simChef_error\", call = rlang::caller_env(), ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/abort.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Signals an error with default subclass ","text":"message Message include condition. class Subclass passed appropriate rlang signal function. call function environment relevant user's perspective. Default rlang::caller_env(), gives environment attached function called signal function. ... Additional arguments pass appropriate rlang signal function.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/abort_if_missing_subclass.html","id":null,"dir":"Reference","previous_headings":"","what":"Check an object for a subclass and signal an error if the subclass is\nmissing. — abort_if_missing_subclass","title":"Check an object for a subclass and signal an error if the subclass is\nmissing. — abort_if_missing_subclass","text":"Check object subclass signal error subclass missing.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/abort_if_missing_subclass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check an object for a subclass and signal an error if the subclass is\nmissing. — abort_if_missing_subclass","text":"","code":"abort_if_missing_subclass(   obj,   subclass,   cause_string,   hint_string = NULL,   call = rlang::caller_env(),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/abort_if_missing_subclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check an object for a subclass and signal an error if the subclass is\nmissing. — abort_if_missing_subclass","text":"obj object check subclass. cause_string action invalid. hint_string optional hint fix error. call function environment relevant user's perspective. Default rlang::caller_env(), gives environment attached function called signal function. ... Passed simChef::abort(). sublcass subclass obj expected .","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/abort_on_invalid_user_action.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructs a helpful message and signals an error when the user takes an\ninvalid action. Can include an optional hint to fix the error. — abort_on_invalid_user_action","title":"Constructs a helpful message and signals an error when the user takes an\ninvalid action. Can include an optional hint to fix the error. — abort_on_invalid_user_action","text":"Constructs helpful message signals error user takes invalid action. Can include optional hint fix error.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/abort_on_invalid_user_action.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructs a helpful message and signals an error when the user takes an\ninvalid action. Can include an optional hint to fix the error. — abort_on_invalid_user_action","text":"","code":"abort_on_invalid_user_action(   cause_string,   hint_string = NULL,   call = rlang::caller_env(),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/abort_on_invalid_user_action.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructs a helpful message and signals an error when the user takes an\ninvalid action. Can include an optional hint to fix the error. — abort_on_invalid_user_action","text":"cause_string action invalid. hint_string optional hint fix error. call function environment relevant user's perspective. Default rlang::caller_env(), gives environment attached function called signal function. ... Passed simChef::abort().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/add_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper functions for adding components to an Experiment. — add_funs","title":"Helper functions for adding components to an Experiment. — add_funs","text":"Helper functions adding DGPs, Methods, Evaluators, Visualizers Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/add_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper functions for adding components to an Experiment. — add_funs","text":"","code":"add_dgp(experiment, dgp, name = NULL, ...)  add_method(experiment, method, name = NULL, ...)  add_evaluator(experiment, evaluator, name = NULL, ...)  add_visualizer(experiment, visualizer, name = NULL, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/add_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper functions for adding components to an Experiment. — add_funs","text":"experiment Experiment object. dgp DGP object. name name identify object added. ... used. method Method object. evaluator Evaluator object. visualizer Visualizer object.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/add_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper functions for adding components to an Experiment. — add_funs","text":"original Experiment object passed add_*.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/check_equal.html","id":null,"dir":"Reference","previous_headings":"","what":"Check equality of Experiment components. — check_equal","title":"Check equality of Experiment components. — check_equal","text":"Check two DGPs, Methods, Evaluators, Visualizers respect function inputted arguments.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/check_equal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check equality of Experiment components. — check_equal","text":"","code":"check_equal(obj1, obj2)"},{"path":"https://yu-group.github.io/simChef/dev/reference/check_equal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check equality of Experiment components. — check_equal","text":"obj1 object class DGP, Method, Evaluator, Visualizer obj2 object class DGP, Method, Evaluator, Visualizer","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/check_equal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check equality of Experiment components. — check_equal","text":"Logical. Returns TRUE objects function arguments FALSE otherwise.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/check_results_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to throw informative error when column names are duplicated,\nin particular, when the same parameter is in the user-provided method\nresults output and also in vary_across. — check_results_names","title":"Helper function to throw informative error when column names are duplicated,\nin particular, when the same parameter is in the user-provided method\nresults output and also in vary_across. — check_results_names","text":"Helper function throw informative error column names duplicated, particular, parameter user-provided method results output also vary_across.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/check_results_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to throw informative error when column names are duplicated,\nin particular, when the same parameter is in the user-provided method\nresults output and also in vary_across. — check_results_names","text":"","code":"check_results_names(names, method_name)"},{"path":"https://yu-group.github.io/simChef/dev/reference/check_results_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to throw informative error when column names are duplicated,\nin particular, when the same parameter is in the user-provided method\nresults output and also in vary_across. — check_results_names","text":"names Vector column names check uniqueness","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/check_results_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to throw informative error when column names are duplicated,\nin particular, when the same parameter is in the user-provided method\nresults output and also in vary_across. — check_results_names","text":"Throws error duplicate names found. Returns original names otherwise.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/clean_up_worker_env.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean up future worker-local environments on exit. — clean_up_worker_env","title":"Clean up future worker-local environments on exit. — clean_up_worker_env","text":"Clean future worker-local environments exit.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/clean_up_worker_env.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean up future worker-local environments on exit. — clean_up_worker_env","text":"","code":"clean_up_worker_env(what = c(\"future\", \"dgp\", \"method\"), env = parent.frame())"},{"path":"https://yu-group.github.io/simChef/dev/reference/clear_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear cached results from Experiment. — clear_cache","title":"Clear cached results from Experiment. — clear_cache","text":"Clear (delete) cached results Experiment start experiment fresh/scratch.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/clear_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear cached results from Experiment. — clear_cache","text":"","code":"clear_cache(experiment)"},{"path":"https://yu-group.github.io/simChef/dev/reference/clear_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clear cached results from Experiment. — clear_cache","text":"experiment Experiment object.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/clear_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clear cached results from Experiment. — clear_cache","text":"original Experiment object cache cleared.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compare_tibble_rows.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare two tibbles. — compare_tibble_rows","title":"Compare two tibbles. — compare_tibble_rows","text":"Compare two tibbles equality containment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compare_tibble_rows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare two tibbles. — compare_tibble_rows","text":"","code":"compare_tibble_rows(x, y, op = c(\"equal\", \"contained_in\"))"},{"path":"https://yu-group.github.io/simChef/dev/reference/compare_tibble_rows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare two tibbles. — compare_tibble_rows","text":"x tibble unique rows. y tibble unique rows. op Name opertaion.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compare_tibble_rows.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare two tibbles. — compare_tibble_rows","text":"op == \"equal\", returns boolean indicating x y rows, ignoring row order. op == \"contained_in\", returns boolean indicating rows x contained rows y.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_dgp.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribute simulation computation by DGPs. — compute_dgp","title":"Distribute simulation computation by DGPs. — compute_dgp","text":"Distribute simulation computation DGPs.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_dgp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribute simulation computation by DGPs. — compute_dgp","text":"","code":"compute_dgp(n_reps, future.globals, future.packages, future.seed, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_dgp_method.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly nested distributed simulation computation nested by DGPs and Methods. — compute_dgp_method","title":"Doubly nested distributed simulation computation nested by DGPs and Methods. — compute_dgp_method","text":"Doubly nested distributed simulation computation nested DGPs Methods.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_dgp_method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly nested distributed simulation computation nested by DGPs and Methods. — compute_dgp_method","text":"","code":"compute_dgp_method(n_reps, future.globals, future.packages, future.seed, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_dgp_method_reps.html","id":null,"dir":"Reference","previous_headings":"","what":"Triply nested distributed simulation computation nested by DGPs, Methods, and\nreps. — compute_dgp_method_reps","title":"Triply nested distributed simulation computation nested by DGPs, Methods, and\nreps. — compute_dgp_method_reps","text":"Triply nested distributed simulation computation nested DGPs, Methods, reps.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_dgp_method_reps.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Triply nested distributed simulation computation nested by DGPs, Methods, and\nreps. — compute_dgp_method_reps","text":"","code":"compute_dgp_method_reps(   n_reps,   future.globals,   future.packages,   future.seed,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_dgp_rep.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly nested distributed simulation computation nested by DGPs and reps. — compute_dgp_rep","title":"Doubly nested distributed simulation computation nested by DGPs and reps. — compute_dgp_rep","text":"Doubly nested distributed simulation computation nested DGPs reps.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_dgp_rep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly nested distributed simulation computation nested by DGPs and reps. — compute_dgp_rep","text":"","code":"compute_dgp_rep(n_reps, future.globals, future.packages, future.seed, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_method.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribute simulation computation by Methods. — compute_method","title":"Distribute simulation computation by Methods. — compute_method","text":"Distribute simulation computation Methods.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribute simulation computation by Methods. — compute_method","text":"","code":"compute_method(n_reps, future.globals, future.packages, future.seed, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_method_rep.html","id":null,"dir":"Reference","previous_headings":"","what":"Doubly nested distributed simulation computation nested by Methods and reps. — compute_method_rep","title":"Doubly nested distributed simulation computation nested by Methods and reps. — compute_method_rep","text":"Doubly nested distributed simulation computation nested Methods reps.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_method_rep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Doubly nested distributed simulation computation nested by Methods and reps. — compute_method_rep","text":"","code":"compute_method_rep(n_reps, future.globals, future.packages, future.seed, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_rep.html","id":null,"dir":"Reference","previous_headings":"","what":"Distribute simulation computation by replicates. — compute_rep","title":"Distribute simulation computation by replicates. — compute_rep","text":"Distribute simulation computation replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/compute_rep.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Distribute simulation computation by replicates. — compute_rep","text":"","code":"compute_rep(n_reps, future.globals, future.packages, future.seed, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_assign_str.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an assignment string and print to console. — create_assign_str","title":"Create an assignment string and print to console. — create_assign_str","text":"Create assignment string print console.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_assign_str.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an assignment string and print to console. — create_assign_str","text":"","code":"create_assign_str(name, value, throw_error = FALSE)"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_dgp.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new DGP (data-generating process). — create_dgp","title":"Create a new DGP (data-generating process). — create_dgp","text":"Create new DGP (data-generating process).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_dgp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new DGP (data-generating process). — create_dgp","text":"","code":"create_dgp(.dgp_fun, .name = NULL, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_dgp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new DGP (data-generating process). — create_dgp","text":".dgp_fun data-generating process function. .name (Optional) name DGP. ... Arguments pass .dgp_fun().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_dgp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new DGP (data-generating process). — create_dgp","text":"new instance DGP.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_dgp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new DGP (data-generating process). — create_dgp","text":"","code":"# create an example DGP function dgp_fun <- function(n, beta, rho, sigma) {   cov_mat <- matrix(c(1, rho, rho, 1), byrow = T, nrow = 2, ncol = 2)   X <- MASS::mvrnorm(n = n, mu = rep(0, 2), Sigma = cov_mat)   y <- X %*% beta + rnorm(n, sd = sigma)   return(list(X = X, y = y)) }  # create DGP (with uncorrelated features) dgp_uncorr <- create_dgp(.dgp_fun = dgp_fun,                          .name = \"Uncorrelated Linear Gaussian DGP\",                          # additional named parameters to pass to dgp_fun()                          n = 200, beta = c(1, 0), rho = 0, sigma = 1) # create DGP (with correlated features) dgp_corr <- create_dgp(.dgp_fun = dgp_fun,                        .name = \"Correlated Linear Gaussian DGP\",                        # additional named parameters to pass to dgp_fun()                        n = 200, beta = c(1, 0), rho = 0.7, sigma = 1)  # create DGP from a function in the built-in DGP library dgp <- create_dgp(.dgp_fun = dgpoix::linear_gaussian_dgp,                   .name = \"Linear Gaussian DGP\",                   # additional named parameters to pass to linear_gaussian_dgp()                   n = 100, p_obs = 10, err = rnorm)"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_doc_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize documentation template for the R Markdown results report. — create_doc_template","title":"Initialize documentation template for the R Markdown results report. — create_doc_template","text":"create_doc_template() renamed init_docs() create consistent API.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_doc_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize documentation template for the R Markdown results report. — create_doc_template","text":"","code":"create_doc_template(experiment, save_dir)"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_evaluator.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new Evaluator. — create_evaluator","title":"Create a new Evaluator. — create_evaluator","text":"Create new Evaluator.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_evaluator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new Evaluator. — create_evaluator","text":"","code":"create_evaluator(   .eval_fun,   .name = NULL,   .doc_options = list(),   .doc_show = TRUE,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_evaluator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new Evaluator. — create_evaluator","text":".eval_fun evaluation function. .name (Optional) name Evaluator. argument must specified position typed whole; partial matching allowed argument. .doc_options (Optional) List options control aesthetics displayed Evaluator's results table knitted R Markdown report. See vthemes::pretty_DT() possible options. argument must specified position typed whole; partial matching allowed argument. .doc_show TRUE (default), show Evaluator's results table R Markdown report; FALSE, hide output R Markdown report. ... Arguments pass .eval_fun().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_evaluator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new Evaluator. — create_evaluator","text":"new Evaluator object.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_evaluator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a new Evaluator. — create_evaluator","text":"evaluating running Experiment (see evaluate_experiment() run_experiment()), named arguments fit_results vary_params automatically passed Evaluator function .eval_fun() serve placeholders fit_experiment() results (.e., results method fits) name varying parameter, respectively. evaluate performance method(s) fit , Evaluator function .eval_fun() almost always take named argument fit_results. See Experiment$fit() fit_experiment() details format fit_results. Evaluator used Experiments varying parameters, vary_params used stand name varying parameter.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_evaluator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new Evaluator. — create_evaluator","text":"","code":"# create an example Evaluator function reject_prob_fun <- function(fit_results, vary_params = NULL, alpha = 0.05) {   group_vars <- c(\".dgp_name\", \".method_name\", vary_params)   eval_out <- fit_results %>%     dplyr::group_by(across({{group_vars}})) %>%     dplyr::summarise(       `X1 Reject Prob.` = mean(`X1 p-value` < alpha),       `X2 Reject Prob.` = mean(`X2 p-value` < alpha)     )   return(eval_out) }  # create Evaluator using the default arguments (i.e., alpha = 0.05) reject_prob_eval <- create_evaluator(.eval_fun = reject_prob_fun,                                       .name = \"Rejection Prob (alpha = 0.05)\") # create Evaluator using non-default arguments (here, alpha = 0.1) reject_prob_eval2 <- create_evaluator(.eval_fun = reject_prob_fun,                                       .name = \"Rejection Prob (alpha = 0.1)\",                                       # additional named parameters to pass to reject_prob_fun(),                                       alpha = 0.1)  # create Evaluator from a function in the built-in Evaluator library pred_err_eval <- create_evaluator(.eval_fun = summarize_pred_err,                                   .name = \"Prediction Error\",                                    # additional named parameters to pass to summarize_pred_err()                                   truth_col = \"y\", estimate_col = \"predictions\")                                    # set doc options for displaying Evaluator in Rmd report to show 3 decimal points pred_err_eval <- create_evaluator(.eval_fun = summarize_pred_err,                                   .name = \"Prediction Error\",                                    .doc_options = list(digits = 3),                                   # additional named parameters to pass to summarize_pred_err()                                   truth_col = \"y\", estimate_col = \"predictions\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_experiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new Experiment. — create_experiment","title":"Create a new Experiment. — create_experiment","text":"Create new Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_experiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new Experiment. — create_experiment","text":"","code":"create_experiment(   name = \"experiment\",   dgp_list = list(),   method_list = list(),   evaluator_list = list(),   visualizer_list = list(),   future.globals = TRUE,   future.packages = NULL,   clone_from = NULL,   save_dir = NULL,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_experiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new Experiment. — create_experiment","text":"name name Experiment. dgp_list optional list DGP objects. method_list optional list Method objects. evaluator_list optional list Evaluator objects. visualizer_list optional list Visualizer objects. future.globals Character vector names global environment pass parallel workers. Passed argument name future.apply::future_lapply related functions. set specific run experiment, use argument Experiment$run. future.packages Character vector packages required parallel workers. Passed argument name future.apply::future_lapply related functions. set specific run experiment, use argument Experiment$run. clone_from optional Experiment object use base one. save_dir optional directory save experiment's results. NULL, results saved current working directory directory called \"results\" sub-directory named Experiment$name. ... used.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_experiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new Experiment. — create_experiment","text":"new Experiment object.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_fun_str.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a function call string and print to console. — create_fun_str","title":"Create a function call string and print to console. — create_fun_str","text":"Create function call string print console.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_fun_str.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a function call string and print to console. — create_fun_str","text":"","code":"create_fun_str(name, fun, args)"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_method.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new Method. — create_method","title":"Create a new Method. — create_method","text":"Create new Method.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new Method. — create_method","text":"","code":"create_method(.method_fun, .name = NULL, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new Method. — create_method","text":".method_fun method function. .name (Optional) name Method. ... Arguments pass .method_fun().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new Method. — create_method","text":"new instance Method.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_method.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new Method. — create_method","text":"","code":"# create an example Method function lm_fun <- function(X, y, cols = c(\"X1\", \"X2\")) {   lm_fit <- lm(y ~ X)   pvals <- summary(lm_fit)$coefficients[cols, \"Pr(>|t|)\"] %>%     setNames(paste(names(.), \"p-value\"))   return(pvals) }  # create Method with default arguments lm_method <- create_method(.method_fun = lm_fun, .name = \"OLS\")  # create Method with non-default arguments lm_method_x1 <- create_method(.method_fun = lm_fun, .name = \"OLS X1\",                               # additional named parameters to pass to lm_fun()                               cols = \"X1\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_rmd.html","id":null,"dir":"Reference","previous_headings":"","what":"Render an R Markdown file summarizing the results of an Experiment or\nset of Experiments. — create_rmd","title":"Render an R Markdown file summarizing the results of an Experiment or\nset of Experiments. — create_rmd","text":"create_rmd() renamed render_docs() create consistent API.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_rmd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Render an R Markdown file summarizing the results of an Experiment or\nset of Experiments. — create_rmd","text":"","code":"create_rmd(   experiment,   save_dir,   open = TRUE,   title = NULL,   author = \"\",   verbose = 2,   quiet = TRUE,   pretty = TRUE,   eval_order = NULL,   viz_order = NULL,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_visualizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new Visualizer. — create_visualizer","title":"Create a new Visualizer. — create_visualizer","text":"Create new Visualizer.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_visualizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new Visualizer. — create_visualizer","text":"","code":"create_visualizer(   .viz_fun,   .name = NULL,   .doc_options = list(),   .doc_show = TRUE,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/create_visualizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new Visualizer. — create_visualizer","text":".viz_fun visualization function. .name (Optional) name Visualizer. .doc_options (Optional) List options control aesthetics Visualizer's visualization knitted R Markdown report. Currently, possible options \"height\" \"width\" (inches). argument must specified position typed whole; partial matching allowed argument. .doc_show TRUE (default), show resulting visualization R Markdown report; FALSE, hide output R Markdown report. ... Arguments pass .viz_fun().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_visualizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new Visualizer. — create_visualizer","text":"new instance Visualizer.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_visualizer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a new Visualizer. — create_visualizer","text":"visualizing running Experiment (see Experiment$visualize() Experiment$run()), named arguments fit_results, eval_results, vary_params automatically passed Visualizer function .viz_fun() serve placeholders Experiment$fit() results, Experiment$evaluate() results, name varying parameter, respectively. visualize performance method(s) fit /evaluation metrics , Visualizer function .viz_fun() take named arguments fit_results /eval_results. See Experiment$fit() fit_experiment() details format fit_results. See Experiment$evaluate() evaluate_experiment() details format eval_results. Visualizer used Experiments varying parameters, vary_params used stand name varying parameter.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/create_visualizer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new Visualizer. — create_visualizer","text":"","code":"# create an example Visualizer function power_plot_fun <- function(fit_results, vary_params = NULL, col = \"X1\") {      if (!is.null(vary_params)) {     # deal with the case when we vary across a parameter that is vector-valued     if (is.list(fit_results[[vary_params]])) {       fit_results[[vary_params]] <- list_col_to_chr(fit_results[[vary_params]],                                                     name = vary_params,                                                     verbatim = TRUE)     }   }      plt <- ggplot2::ggplot(fit_results) +     ggplot2::aes(x = .data[[paste(col, \"p-value\")]],                  color = as.factor(.method_name)) +     ggplot2::geom_abline(slope = 1, intercept = 0,                           color = \"darkgray\", linetype = \"solid\", size = 1) +     ggplot2::stat_ecdf(size = 1) +     ggplot2::scale_x_continuous(limits = c(0, 1)) +     ggplot2::labs(x = \"t\", y = \"P( p-value \\u2264 t )\",                    linetype = \"\", color = \"Method\")   if (!is.null(vary_params)) {     plt <- plt + ggplot2::facet_wrap(~ .data[[vary_params]])   }   return(plt) }  # create Visualizer using the default arguments (i.e., col = \"X1\") power_plot1 <- create_visualizer(.viz_fun = power_plot_fun,                                   .name = \"Power Plot (X1)\") # create Visualizer using non-default arguments (i.e., col = \"X2\") power_plot2 <- create_visualizer(.viz_fun = power_plot_fun,                                  .name = \"Power Plot (X2)\",                                  # additional named parameters to pass to power_plot_fun()                                  col = \"X2\")  # create Visualizer from a function in the built-in Visualizer library pred_err_plot <- create_visualizer(.viz_fun = plot_pred_err,                                    .name = \"Prediction Error Plot\",                                    # additional named parameters to pass to plot_pred_err()                                    truth_col = \"y\", estimate_col = \"predictions\")                                    # change figure height/width when displaying Visualizer in Rmd report pred_err_plot <- create_visualizer(.viz_fun = plot_pred_err,                                    .name = \"Prediction Error Plot\",                                    .doc_options = list(height = 8, width = 12),                                    # additional named parameters to pass to plot_pred_err()                                    truth_col = \"y\", estimate_col = \"predictions\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/do_call_handler.html","id":null,"dir":"Reference","previous_headings":"","what":"Call a function with given parameters and capture errors, warnings, or\nmessages that occur during evaluation. — do_call_handler","title":"Call a function with given parameters and capture errors, warnings, or\nmessages that occur during evaluation. — do_call_handler","text":"Call function given parameters capture errors, warnings, messages occur evaluation.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/do_call_handler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Call a function with given parameters and capture errors, warnings, or\nmessages that occur during evaluation. — do_call_handler","text":"","code":"do_call_handler(   name,   fun,   params = list(),   verbose = 1,   call = rlang::caller_env() )"},{"path":"https://yu-group.github.io/simChef/dev/reference/do_call_handler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Call a function with given parameters and capture errors, warnings, or\nmessages that occur during evaluation. — do_call_handler","text":"name name give context call fun function call params arguments pass fun verbose Verbosity level. greater 1, handle warnings messages addition errors.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/do_call_handler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Call a function with given parameters and capture errors, warnings, or\nmessages that occur during evaluation. — do_call_handler","text":"results calling fun params","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_importance_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate and/or summarize feature importance scores. — eval_feature_importance_funs","title":"Evaluate and/or summarize feature importance scores. — eval_feature_importance_funs","text":"Evaluate estimated feature importance scores true feature support. eval_feature_importance evaluates feature importances experimental replicate separately. summarize_feature_importance summarizes feature importances across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_importance_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate and/or summarize feature importance scores. — eval_feature_importance_funs","text":"","code":"eval_feature_importance(   fit_results,   vary_params = NULL,   nested_data = NULL,   feature_col,   imp_col )  summarize_feature_importance(   fit_results,   vary_params = NULL,   nested_data = NULL,   feature_col,   imp_col,   na_rm = FALSE,   summary_funs = c(\"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\"),   custom_summary_funs = NULL,   eval_id = \"feature_importance\" )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_importance_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate and/or summarize feature importance scores. — eval_feature_importance_funs","text":"fit_results tibble, returned fit method. vary_params vector parameter names varied across Experiment. nested_data (Optional) Character string. specified, name column fit_results containing columns must unnested evaluating results. Default NULL, meaning columns fit_results need unnested prior computation. feature_col character string identifying column fit_results feature names IDs. imp_col character string identifying column fit_results estimated feature importance data. element column array length p, p number features feature order aligns truth_col. Elements array numeric higher magnitude indicates important feature. na_rm logical value indicating whether NA values stripped computation proceeds. summary_funs Character vector specifying summarize evaluation metrics. Must choose built-library summary functions - elements vector must one \"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\". custom_summary_funs Named list custom functions summarize results. Names list correspond name summary function. Values list function takes one argument, values evaluated metrics. eval_id Character string. ID used suffix naming result columns. Default NULL add ID column names.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_importance_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate and/or summarize feature importance scores. — eval_feature_importance_funs","text":"output eval_feature_importance() tibble columns .rep, .dgp_name, .method_name addition columns specified vary_params, feature_col, imp_col. output summarize_feature_importance() grouped tibble containing identifying information feature importance results aggregated experimental replicates. Specifically, identifier columns include .dgp_name, .method_name, columns specified vary_params, column specified feature_col. addition, results columns corresponding requested statistics summary_funs custom_summary_funs. columns end suffix \"_feature_importance\".","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_importance_funs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate and/or summarize feature importance scores. — eval_feature_importance_funs","text":"","code":"# generate example fit_results data for a feature selection problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),         # estimated feature importance scores         est_importance = c(10, runif(2, min = -2, max = 2))       )     }   ) )  # evaluate feature importances (using all default metrics) for each replicate eval_results <- eval_feature_importance(   fit_results,   nested_data = \"feature_info\",   feature_col = \"feature\",   imp_col = \"est_importance\" ) # summarize feature importances (using all default metric) across replicates eval_results_summary <- summarize_feature_importance(   fit_results,   nested_data = \"feature_info\",   feature_col = \"feature\",   imp_col = \"est_importance\" )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_curve_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate and/or summarize ROC or PR curves for feature selection. — eval_feature_selection_curve_funs","title":"Evaluate and/or summarize ROC or PR curves for feature selection. — eval_feature_selection_curve_funs","text":"Evaluate ROC PR curves corresponding selected features, given true feature support estimated feature importances. eval_feature_selection_curve() evaluates ROC PR curve experimental replicate separately. summarize_feature_selection_curve() summarizes ROC PR curve across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_curve_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate and/or summarize ROC or PR curves for feature selection. — eval_feature_selection_curve_funs","text":"","code":"eval_feature_selection_curve(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   imp_col,   curve = c(\"ROC\", \"PR\"),   options = list(),   na_rm = FALSE )  summarize_feature_selection_curve(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   imp_col,   curve = c(\"ROC\", \"PR\"),   options = list(),   na_rm = FALSE,   x_grid = seq(0, 1, by = 0.01),   summary_funs = c(\"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\"),   custom_summary_funs = NULL,   eval_id = ifelse(curve == \"PR\", \"precision\", \"TPR\") )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_curve_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate and/or summarize ROC or PR curves for feature selection. — eval_feature_selection_curve_funs","text":"fit_results tibble, returned fit method. vary_params vector parameter names varied across Experiment. nested_data (Optional) Character string. specified, name column fit_results containing columns must unnested evaluating results. Default NULL, meaning columns fit_results need unnested prior computation. truth_col character string identifying column fit_results true feature support data. element column array length p, p number features. Elements array binary TRUE 1 meaning feature (corresponding slot) support FALSE 0 meaning feature support. imp_col character string identifying column fit_results estimated feature importance data. element column array length p, p number features feature order aligns truth_col. Elements array numeric higher magnitude indicates important feature. curve Either \"ROC\" \"PR\" indicating whether evaluate ROC Precision-Recall curve. options list named options pass pROC::roc() smooth. options include response, predictor, levels, quiet, direction. argument used computing ROC ignored otherwise. na_rm logical value indicating whether NA values stripped computation proceeds. x_grid Vector values 0 1 evaluate ROC PR curve. curve = \"ROC\", provided vector values FPR values evaluate TPR, curve = \"PR\", values recall values evaluate precision. summary_funs Character vector specifying summarize evaluation metrics. Must choose built-library summary functions - elements vector must one \"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\". custom_summary_funs Named list custom functions summarize results. Names list correspond name summary function. Values list function takes one argument, values evaluated metrics. eval_id Character string. ID used suffix naming result columns. Default NULL add ID column names.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_curve_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate and/or summarize ROC or PR curves for feature selection. — eval_feature_selection_curve_funs","text":"output eval_feature_selection_curve() tibble following columns: .rep Replicate ID. .dgp_name Name DGP. .method_name Name Method. curve_estimate list tibbles x y coordinate values ROC/PR curve given experimental replicate. curve = \"ROC\", tibble columns .threshold, FPR, TPR threshold, false positive rate, true positive rate, respectively. curve = \"PR\", tibble columns .threshold, recall, precision. well columns specified vary_params. output summarize_feature_selection_curve() grouped tibble containing identifying information feature selection curve results aggregated experimental replicates. Specifically, identifier columns include .dgp_name, .method_name, columns specified vary_params. addition, results columns corresponding requested statistics summary_funs custom_summary_funs. curve = \"ROC\", results columns include FPR others end suffix \"_TPR\". curve = \"PR\", results columns include recall others end suffix \"_precision\".","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_curve_funs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate and/or summarize ROC or PR curves for feature selection. — eval_feature_selection_curve_funs","text":"","code":"# generate example fit_results data for a feature selection problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),         # true feature support         true_support = c(TRUE, FALSE, TRUE),         # estimated feature importance scores         est_importance = c(10, runif(2, min = -2, max = 2))       )     }   ) )  # evaluate feature selection ROC/PR curves for each replicate roc_results <- eval_feature_selection_curve(   fit_results,    curve = \"ROC\",   nested_data = \"feature_info\",   truth_col = \"true_support\",   imp_col = \"est_importance\" ) pr_results <- eval_feature_selection_curve(   fit_results,    curve = \"PR\",   nested_data = \"feature_info\",   truth_col = \"true_support\",   imp_col = \"est_importance\" ) # summarize feature selection ROC/PR curves across replicates roc_summary <- summarize_feature_selection_curve(   fit_results,    curve = \"ROC\",   nested_data = \"feature_info\",   truth_col = \"true_support\",   imp_col = \"est_importance\" ) pr_summary <- summarize_feature_selection_curve(   fit_results,    curve = \"PR\",   nested_data = \"feature_info\",   truth_col = \"true_support\",   imp_col = \"est_importance\" )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_err_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate and/or summarize feature selection errors. — eval_feature_selection_err_funs","title":"Evaluate and/or summarize feature selection errors. — eval_feature_selection_err_funs","text":"Evaluate various feature selection metrics, given true feature support estimated feature support. eval_feature_selection_err() evaluates various feature selection metrics experimental replicate separately.. summarize_feature_selection_err() summarizes various feature selection metrics across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_err_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate and/or summarize feature selection errors. — eval_feature_selection_err_funs","text":"","code":"eval_feature_selection_err(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   estimate_col = NULL,   imp_col,   metrics = NULL,   na_rm = FALSE )  summarize_feature_selection_err(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   estimate_col = NULL,   imp_col,   metrics = NULL,   na_rm = FALSE,   summary_funs = c(\"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\"),   custom_summary_funs = NULL,   eval_id = \"feature_selection\" )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_err_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate and/or summarize feature selection errors. — eval_feature_selection_err_funs","text":"fit_results tibble, returned fit method. vary_params vector parameter names varied across Experiment. nested_data (Optional) Character string. specified, name column fit_results containing columns must unnested evaluating results. Default NULL, meaning columns fit_results need unnested prior computation. truth_col character string identifying column fit_results true feature support data. element column array length p, p number features. Elements array binary TRUE 1 meaning feature (corresponding slot) support FALSE 0 meaning feature support. estimate_col (optional) character string identifying column fit_results estimated feature support data. element column array length p, p number features feature order aligns truth_col. Elements array binary TRUE 1 meaning feature (corresponding slot) estimated support FALSE 0 meaning feature estimated support. NULL (default), non-zero elements imp_col used estimated feature support. imp_col character string identifying column fit_results estimated feature importance data. element column array length p, p number features feature order aligns truth_col. Elements array numeric higher magnitude indicates important feature. metrics metric_set object indicating metrics evaluate. See yardstick::metric_set() details. Default NULL evaluate following: number true positives (tp), number false positives (fp), sensitivity (sens), specificity (spec), positive predictive value (ppv), number features estimated support (pos), number features estimated support (neg), AUROC (roc_auc), AUPRC (pr_auc). na_rm = TRUE, number NA values (num_na) also computed. na_rm logical value indicating whether NA values stripped computation proceeds. summary_funs Character vector specifying summarize evaluation metrics. Must choose built-library summary functions - elements vector must one \"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\". custom_summary_funs Named list custom functions summarize results. Names list correspond name summary function. Values list function takes one argument, values evaluated metrics. eval_id Character string. ID used suffix naming result columns. Default NULL add ID column names.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_err_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate and/or summarize feature selection errors. — eval_feature_selection_err_funs","text":"output eval_feature_selection_err() tibble following columns: .rep Replicate ID. .dgp_name Name DGP. .method_name Name Method. .metric Name evaluation metric. .estimate Value evaluation metric. well columns specified vary_params. output summarize_feature_selection_err() grouped tibble containing identifying information feature selection results aggregated experimental replicates. Specifically, identifier columns include .dgp_name, .method_name, columns specified vary_params, .metric. addition, results columns corresponding requested statistics summary_funs custom_summary_funs. columns end suffix \"_feature_selection\".","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_feature_selection_err_funs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate and/or summarize feature selection errors. — eval_feature_selection_err_funs","text":"","code":"# generate example fit_results data for a feature selection problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),           # true feature support         true_support = c(TRUE, FALSE, TRUE),           # estimated feature support         est_support = c(TRUE, FALSE, FALSE),           # estimated feature importance scores         est_importance = c(10, runif(2, min = -2, max = 2))         )     }   ) )  # evaluate feature selection (using all default metrics) for each replicate eval_results <- eval_feature_selection_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   estimate_col = \"est_support\",   imp_col = \"est_importance\" ) # summarize feature selection error (using all default metric) across replicates eval_results_summary <- summarize_feature_selection_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   estimate_col = \"est_support\",   imp_col = \"est_importance\" )  # evaluate/summarize feature selection errors using specific yardstick metrics metrics <- yardstick::metric_set(yardstick::sens, yardstick::spec) eval_results <- eval_feature_selection_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   estimate_col = \"est_support\",   imp_col = \"est_importance\",   metrics = metrics ) eval_results_summary <- summarize_feature_selection_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   estimate_col = \"est_support\",   imp_col = \"est_importance\",   metrics = metrics )  # summarize feature selection errors using specific summary metric range_fun <- function(x) return(max(x) - min(x)) eval_results_summary <- summarize_feature_selection_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   estimate_col = \"est_support\",   imp_col = \"est_importance\",   custom_summary_funs = list(range_feature_selection = range_fun) )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_curve_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate and/or summarize ROC or PR curves. — eval_pred_curve_funs","title":"Evaluate and/or summarize ROC or PR curves. — eval_pred_curve_funs","text":"Evaluate ROC PR curves, given true responses predicted probabilities class. eval_pred_curve() evaluates ROC PR curve experimental replicate separately. summarize_pred_curve() summarizes ROC PR curve across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_curve_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate and/or summarize ROC or PR curves. — eval_pred_curve_funs","text":"","code":"eval_pred_curve(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   prob_cols,   curve = c(\"ROC\", \"PR\"),   groups = NULL,   options = list(),   na_rm = FALSE )  summarize_pred_curve(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   prob_cols,   curve = c(\"ROC\", \"PR\"),   groups = NULL,   options = list(),   na_rm = FALSE,   x_grid = seq(0, 1, by = 0.01),   summary_funs = c(\"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\"),   custom_summary_funs = NULL,   eval_id = ifelse(curve == \"PR\", \"precision\", \"TPR\") )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_curve_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate and/or summarize ROC or PR curves. — eval_pred_curve_funs","text":"fit_results tibble, returned fit method. vary_params vector parameter names varied across Experiment. nested_data (Optional) Character string. specified, name column fit_results containing columns must unnested evaluating results. Default NULL, meaning columns fit_results need unnested prior computation. truth_col character string identifying column true responses. column numeric regression problem factor classification problem. prob_cols character string vector identifying column(s) containing class probabilities. truth_col column binary, 1 column name provided. Otherwise, length prob_cols equal number factor levels truth_col column. argument used evaluating numeric metrics. curve Either \"ROC\" \"PR\" indicating whether evaluate ROC Precision-Recall curve. groups (Optional) vector group IDs group observations evaluating prediction errors. useful assessing within-group prediction errors. Note: (unstratified) prediction errors, aggregated across full data set, computed addition stratified within-group errors. options list named options pass pROC::roc() smooth. options include response, predictor, levels, quiet, direction. argument used computing ROC ignored otherwise. na_rm logical value indicating whether NA values stripped computation proceeds. x_grid Vector values 0 1 evaluate ROC PR curve. curve = \"ROC\", provided vector values FPR values evaluate TPR, curve = \"PR\", values recall values evaluate precision. summary_funs Character vector specifying summarize evaluation metrics. Must choose built-library summary functions - elements vector must one \"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\". custom_summary_funs Named list custom functions summarize results. Names list correspond name summary function. Values list function takes one argument, values evaluated metrics. eval_id Character string. ID used suffix naming result columns. Default NULL add ID column names.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_curve_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate and/or summarize ROC or PR curves. — eval_pred_curve_funs","text":"output eval_pred_curve() tibble following columns: .rep Replicate ID. .dgp_name Name DGP. .method_name Name Method. .group groups NULL, column specifies name group evaluation. Otherwise, column returned. curve_estimate list tibbles x y coordinate values ROC/PR curve given experimental replicate. curve = \"ROC\", tibble columns .threshold, FPR, TPR threshold, false positive rate, true positive rate, respectively. curve = \"PR\", tibble columns .threshold, recall, precision. well columns specified vary_params. output summarize_pred_curve() grouped tibble containing identifying information prediction curve results aggregated experimental replicates. Specifically, identifier columns include .dgp_name, .method_name, columns specified vary_params. addition, results columns corresponding requested statistics summary_funs custom_summary_funs. curve = \"ROC\", results columns include FPR others end suffix \"_TPR\". curve = \"PR\", results columns include recall others end suffix \"_precision\".","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_curve_funs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate and/or summarize ROC or PR curves. — eval_pred_curve_funs","text":"","code":"####################################### #### Binary Classification Problem #### ####################################### # generate example fit_results data for a binary classification problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4,              FUN = function(x) {                as.factor(sample(0:1, size = 100, replace = TRUE))              }),   # predicted class probabilities   class_probs = lapply(1:4, FUN = function(x) runif(n = 100, min = 0, max = 1)) )  # evaluate ROC/PR curve for each replicate roc_results <- eval_pred_curve(fit_results, curve = \"ROC\",                                truth_col = \"y\", prob_cols = \"class_probs\") pr_results <- eval_pred_curve(fit_results, curve = \"PR\",                               truth_col = \"y\", prob_cols = \"class_probs\")  # summarize ROC/PR curves across replicates roc_summary <- summarize_pred_curve(fit_results, curve = \"ROC\",                                     truth_col = \"y\", prob_cols = \"class_probs\") pr_summary <- summarize_pred_curve(fit_results, curve = \"PR\",                                    truth_col = \"y\", prob_cols = \"class_probs\")  ############################################ #### Multi-class Classification Problem #### ############################################ # generate example fit_results data for a multi-class classification problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4,              FUN = function(x) {                as.factor(sample(c(\"a\", \"b\", \"c\"), size = 100, replace = TRUE))              }),   # predicted class probabilities   class_probs = lapply(1:4,                        FUN = function(x) {                          tibble::tibble(a = runif(n = 100, min = 0, max = 0.5),                                         b = runif(n = 100, min = 0, max = 0.5),                                         c = 1 - a - b)                        }) )  # evaluate ROC/PR curve for each replicate roc_results <- eval_pred_curve(fit_results, curve = \"ROC\",                                nested_data = \"class_probs\",                                truth_col = \"y\",                                prob_cols = c(\"a\", \"b\", \"c\")) pr_results <- eval_pred_curve(fit_results, curve = \"PR\",                               nested_data = \"class_probs\",                               truth_col = \"y\",                               prob_cols = c(\"a\", \"b\", \"c\"))  # summarize ROC/PR curves across replicates roc_summary <- summarize_pred_curve(fit_results, curve = \"ROC\",                                     nested_data = \"class_probs\",                                     truth_col = \"y\",                                     prob_cols = c(\"a\", \"b\", \"c\")) pr_summary <- summarize_pred_curve(fit_results, curve = \"PR\",                                    nested_data = \"class_probs\",                                    truth_col = \"y\",                                    prob_cols = c(\"a\", \"b\", \"c\"))"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_err_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate and/or summarize prediction errors. — eval_pred_err_funs","title":"Evaluate and/or summarize prediction errors. — eval_pred_err_funs","text":"Evaluate various prediction error metrics, given true responses predicted (estimated) responses. eval_pred_err() evaluates various prediction error metrics experimental replicate separately. summarize_pred_err() summarizes various prediction error metrics across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_err_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate and/or summarize prediction errors. — eval_pred_err_funs","text":"","code":"eval_pred_err(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   estimate_col,   prob_cols = NULL,   metrics = NULL,   groups = NULL,   options = list(),   na_rm = FALSE )  summarize_pred_err(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   estimate_col,   prob_cols = NULL,   metrics = NULL,   groups = NULL,   options = list(),   na_rm = FALSE,   summary_funs = c(\"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\"),   custom_summary_funs = NULL,   eval_id = \"pred_err\" )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_err_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate and/or summarize prediction errors. — eval_pred_err_funs","text":"fit_results tibble, returned fit method. vary_params vector parameter names varied across Experiment. nested_data (Optional) Character string. specified, name column fit_results containing columns must unnested evaluating results. Default NULL, meaning columns fit_results need unnested prior computation. truth_col character string identifying column true responses. column numeric regression problem factor classification problem. estimate_col character string identifying column estimated predicted responses. column numeric regression problem factor (predicted classes) classification problem. prob_cols character string vector identifying column(s) containing class probabilities. truth_col column binary, 1 column name provided. Otherwise, length prob_cols equal number factor levels truth_col column. argument used evaluating numeric metrics. metrics metric_set object indicating metrics evaluate. See yardstick::metric_set() details. Default NULL use default metrics yardstick::metrics(). groups (Optional) vector group IDs group observations evaluating prediction errors. useful assessing within-group prediction errors. Note: (unstratified) prediction errors, aggregated across full data set, computed addition stratified within-group errors. options list named options pass pROC::roc() smooth. options include response, predictor, levels, quiet, direction. argument used computing ROC ignored otherwise. na_rm logical value indicating whether NA values stripped computation proceeds. summary_funs Character vector specifying summarize evaluation metrics. Must choose built-library summary functions - elements vector must one \"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\". custom_summary_funs Named list custom functions summarize results. Names list correspond name summary function. Values list function takes one argument, values evaluated metrics. eval_id Character string. ID used suffix naming result columns. Default NULL add ID column names.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_err_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate and/or summarize prediction errors. — eval_pred_err_funs","text":"output eval_pred_err() tibble following columns: .rep Replicate ID. .dgp_name Name DGP. .method_name Name Method. .group groups NULL, column specifies name group evaluation. Otherwise, column returned. .metric Name evaluation metric. .estimate Value evaluation metric. well columns specified vary_params. output summarize_pred_err() grouped tibble containing identifying information prediction error results aggregated experimental replicates. Specifically, identifier columns include .dgp_name, .method_name, columns specified vary_params,  .metric. addition, results columns corresponding requested statistics summary_funs custom_summary_funs. columns end suffix \"_pred_err\".","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_pred_err_funs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate and/or summarize prediction errors. — eval_pred_err_funs","text":"","code":"############################ #### Regression Problem #### ############################  # generate example fit_results data for a regression problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4, FUN = function(x) rnorm(100)),   # predicted response   predictions = lapply(1:4, FUN = function(x) rnorm(100)) )  # evaluate prediction error (using all default metrics) for each replicate eval_results <- eval_pred_err(fit_results,                               truth_col = \"y\",                               estimate_col = \"predictions\") # summarize prediction error (using all default metric) across replicates eval_results_summary <- summarize_pred_err(fit_results,                                            truth_col = \"y\",                                            estimate_col = \"predictions\")  # evaluate/summarize prediction error within subgroups group_ids <- rep(c(\"a\", \"b\"), length.out = 100) eval_results <- eval_pred_err(fit_results,                               truth_col = \"y\",                               estimate_col = \"predictions\",                               groups = group_ids) eval_results_summary <- summarize_pred_err(fit_results,                                            truth_col = \"y\",                                            estimate_col = \"predictions\",                                            groups = group_ids)  # evaluate/summarize prediction errors using specific yardstick metrics metrics <- yardstick::metric_set(yardstick::rmse, yardstick::rsq) eval_results <- eval_pred_err(fit_results,                               truth_col = \"y\",                               estimate_col = \"predictions\",                               metrics = metrics) eval_results_summary <- summarize_pred_err(fit_results,                                            truth_col = \"y\",                                            estimate_col = \"predictions\",                                            metrics = metrics)  # summarize prediction errors using specific summary metric range_fun <- function(x) return(max(x) - min(x)) eval_results_summary <- summarize_pred_err(   fit_results,   truth_col = \"y\",   estimate_col = \"predictions\",   custom_summary_funs = list(range_pred_err = range_fun) )  ####################################### #### Binary Classification Problem #### ####################################### # generate example fit_results data for a binary classification problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4,              FUN = function(x) {                as.factor(sample(0:1, size = 100, replace = TRUE))              }),   # predicted class probabilities   class_probs = lapply(1:4, FUN = function(x) runif(n = 100, min = 0, max = 1)),   # predicted class responses   predictions = lapply(class_probs,                        FUN = function(x) as.factor(ifelse(x > 0.5, 1, 0))) )  # evaluate prediction error (using all default metrics) for each replicate eval_results <- eval_pred_err(fit_results,                               truth_col = \"y\",                               estimate_col = \"predictions\",                               prob_cols = \"class_probs\") # summarize prediction error (using all default metric) across replicates eval_results_summary <- summarize_pred_err(fit_results,                                            truth_col = \"y\",                                            estimate_col = \"predictions\",                                            prob_cols = \"class_probs\")  # can also evaluate results using only class predictions (without class probs.) eval_results <- eval_pred_err(fit_results,                               truth_col = \"y\",                               estimate_col = \"predictions\") eval_results_summary <- summarize_pred_err(fit_results,                                            truth_col = \"y\",                                            estimate_col = \"predictions\")  ############################################ #### Multi-class Classification Problem #### ############################################ # generate example fit_results data for a multi-class classification problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4,              FUN = function(x) {                as.factor(sample(c(\"a\", \"b\", \"c\"), size = 100, replace = TRUE))              }),   # predicted class probabilities   class_probs = lapply(1:4,                        FUN = function(x) {                          tibble::tibble(a = runif(n = 100, min = 0, max = 0.5),                                         b = runif(n = 100, min = 0, max = 0.5),                                         c = 1 - a - b)                        }),   # predicted class responses   predictions = lapply(class_probs,                        FUN = function(x) {                          yhat <- apply(x, 1,                                        FUN = function(xi) names(which.max(xi)))                          return(as.factor(yhat))                        }) )  # evaluate prediction error (using all default metrics) for each replicate eval_results <- eval_pred_err(fit_results,                               truth_col = \"y\",                               estimate_col = \"predictions\",                               prob_cols = c(\"a\", \"b\", \"c\"),                               nested_data = \"class_probs\") #' summarize prediction error (using all default metric) across replicates eval_results_summary <- summarize_pred_err(fit_results,                                            truth_col = \"y\",                                            estimate_col = \"predictions\",                                            prob_cols = c(\"a\", \"b\", \"c\"),                                            nested_data = \"class_probs\")  # can also evaluate results using only class predictions (without class probs.) eval_results <- eval_pred_err(fit_results,                               truth_col = \"y\",                               estimate_col = \"predictions\") eval_results_summary <- summarize_pred_err(fit_results,                                            truth_col = \"y\",                                            estimate_col = \"predictions\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_reject_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate the rejection probability of a hypothesis test. — eval_reject_prob","title":"Evaluate the rejection probability of a hypothesis test. — eval_reject_prob","text":"Evaluate probability rejecting null hypothesis across various levels significance (possibly multiple hypothesis tests, one feature).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_reject_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate the rejection probability of a hypothesis test. — eval_reject_prob","text":"","code":"eval_reject_prob(   fit_results,   vary_params = NULL,   nested_data = NULL,   feature_col = NULL,   pval_col,   alphas = NULL,   na_rm = FALSE )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_reject_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate the rejection probability of a hypothesis test. — eval_reject_prob","text":"fit_results tibble, returned fit method. vary_params vector parameter names varied across Experiment. nested_data (Optional) Character string. specified, name column fit_results containing columns must unnested evaluating results. Default NULL, meaning columns fit_results need unnested prior computation. feature_col character string identifying column fit_results feature names IDs. pval_col character string identifying column fit_results estimated p-values data. element column array length p, p number features feature order aligns truth_col. alphas (Optional) Vector significance levels evaluate rejection probability. default, alphas NULL, evaluates full empirical cumulative distribution p-values, .e., rejection probability evaluated possible significance levels. na_rm logical value indicating whether NA values stripped computation proceeds.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_reject_prob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate the rejection probability of a hypothesis test. — eval_reject_prob","text":"grouped tibble containing identifying information rejection probability results aggregated experimental replicates. Specifically, identifier columns include .dgp_name, .method_name, columns specified vary_params, feature names given feature_col applicable. addition, results columns .alpha reject_prob, respectively give significance level estimated rejection probabilities (averaged across experimental replicates).","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_reject_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate the rejection probability of a hypothesis test. — eval_reject_prob","text":"","code":"# generate example fit_results data for a feature selection problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),         # true feature support         true_support = c(TRUE, FALSE, TRUE),         # estimated p-values         pval = 10^(sample(-3:0, 3, replace = TRUE))       )     }   ) )  # evaluate rejection probabilities for each feature across all possible values of alpha eval_results <- eval_reject_prob(   fit_results,   nested_data = \"feature_info\",   feature_col = \"feature\",   pval_col = \"pval\" )  # evaluate rejection probability for each feature at specific values of alpha eval_results <- eval_reject_prob(   fit_results,   nested_data = \"feature_info\",   feature_col = \"feature\",   pval_col = \"pval\",   alphas = c(0.05, 0.1) )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_curve_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate and/or summarize ROC or PR curves for feature rankings, ranked by\np-value. — eval_testing_curve_funs","title":"Evaluate and/or summarize ROC or PR curves for feature rankings, ranked by\np-value. — eval_testing_curve_funs","text":"Evaluate ROC PR curves corresponding feature importances ranked p-values. eval_testing_curve() evaluates ROC PR curve experimental replicate separately. summarize_testing_curve() summarizes ROC PR curve across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_curve_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate and/or summarize ROC or PR curves for feature rankings, ranked by\np-value. — eval_testing_curve_funs","text":"","code":"eval_testing_curve(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   pval_col,   curve = c(\"ROC\", \"PR\"),   options = list(),   na_rm = FALSE )  summarize_testing_curve(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   pval_col,   curve = c(\"ROC\", \"PR\"),   options = list(),   na_rm = FALSE,   x_grid = seq(0, 1, by = 0.01),   summary_funs = c(\"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\"),   custom_summary_funs = NULL,   eval_id = ifelse(curve == \"PR\", \"precision\", \"TPR\") )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_curve_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate and/or summarize ROC or PR curves for feature rankings, ranked by\np-value. — eval_testing_curve_funs","text":"fit_results tibble, returned fit method. vary_params vector parameter names varied across Experiment. nested_data (Optional) Character string. specified, name column fit_results containing columns must unnested evaluating results. Default NULL, meaning columns fit_results need unnested prior computation. truth_col character string identifying column fit_results true feature support data. element column array length p, p number features. Elements array binary TRUE 1 meaning feature (corresponding slot) support FALSE 0 meaning feature support. pval_col character string identifying column fit_results estimated p-values data. element column array length p, p number features feature order aligns truth_col. curve Either \"ROC\" \"PR\" indicating whether evaluate ROC Precision-Recall curve. options list named options pass pROC::roc() smooth. options include response, predictor, levels, quiet, direction. argument used computing ROC ignored otherwise. na_rm logical value indicating whether NA values stripped computation proceeds. x_grid Vector values 0 1 evaluate ROC PR curve. curve = \"ROC\", provided vector values FPR values evaluate TPR, curve = \"PR\", values recall values evaluate precision. summary_funs Character vector specifying summarize evaluation metrics. Must choose built-library summary functions - elements vector must one \"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\". custom_summary_funs Named list custom functions summarize results. Names list correspond name summary function. Values list function takes one argument, values evaluated metrics. eval_id Character string. ID used suffix naming result columns. Default NULL add ID column names.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_curve_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate and/or summarize ROC or PR curves for feature rankings, ranked by\np-value. — eval_testing_curve_funs","text":"output eval_testing_curve() tibble following columns: .rep Replicate ID. .dgp_name Name DGP. .method_name Name Method. curve_estimate list tibbles x y coordinate values ROC/PR curve given experimental replicate. curve = \"ROC\", tibble columns .threshold, FPR, TPR threshold, false positive rate, true positive rate, respectively. curve = \"PR\", tibble columns .threshold, recall, precision. well columns specified vary_params. output summarize_testing_curve() grouped tibble containing identifying information evaluation curve results aggregated experimental replicates. Specifically, identifier columns include .dgp_name, .method_name, columns specified vary_params. addition, results columns corresponding requested statistics summary_funs custom_summary_funs. curve = \"ROC\", results columns include FPR others end suffix \"_TPR\". curve = \"PR\", results columns include recall others end suffix \"_precision\".","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_curve_funs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate and/or summarize ROC or PR curves for feature rankings, ranked by\np-value. — eval_testing_curve_funs","text":"","code":"# generate example fit_results data for a feature selection problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),         # true feature support         true_support = c(TRUE, FALSE, TRUE),         # estimated p-values         pval = 10^(sample(-3:0, 3, replace = TRUE))       )     }   ) )  # evaluate feature selection ROC/PR curves for each replicate roc_results <- eval_testing_curve(   fit_results,   curve = \"ROC\",   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\" ) pr_results <- eval_testing_curve(   fit_results,   curve = \"PR\",   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\" ) # summarize feature selection ROC/PR curves across replicates roc_summary <- summarize_testing_curve(   fit_results,   curve = \"ROC\",   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\" ) pr_summary <- summarize_testing_curve(   fit_results,   curve = \"PR\",   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\" )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_err_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate and/or summarize error metrics when conducting multiple hypothesis\ntests. — eval_testing_err_funs","title":"Evaluate and/or summarize error metrics when conducting multiple hypothesis\ntests. — eval_testing_err_funs","text":"Evaluate various testing error metrics, given true feature support estimated p-values pre-specified significance level thresholds. eval_testing_err() evaluates various testing error metrics experimental replicate separately. summarize_testing_err() summarizes various testing error metrics across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_err_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate and/or summarize error metrics when conducting multiple hypothesis\ntests. — eval_testing_err_funs","text":"","code":"eval_testing_err(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   pval_col = NULL,   metrics = NULL,   alphas = 0.05,   na_rm = FALSE )  summarize_testing_err(   fit_results,   vary_params = NULL,   nested_data = NULL,   truth_col,   pval_col = NULL,   metrics = NULL,   alphas = 0.05,   na_rm = FALSE,   summary_funs = c(\"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\"),   custom_summary_funs = NULL,   eval_id = \"testing_err\" )"},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_err_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate and/or summarize error metrics when conducting multiple hypothesis\ntests. — eval_testing_err_funs","text":"fit_results tibble, returned fit method. vary_params vector parameter names varied across Experiment. nested_data (Optional) Character string. specified, name column fit_results containing columns must unnested evaluating results. Default NULL, meaning columns fit_results need unnested prior computation. truth_col character string identifying column fit_results true feature support data. element column array length p, p number features. Elements array binary TRUE 1 meaning feature (corresponding slot) support FALSE 0 meaning feature support. pval_col character string identifying column fit_results estimated p-values data. element column array length p, p number features feature order aligns truth_col. metrics metric_set object indicating metrics evaluate. See yardstick::metric_set() details. Default NULL evaluate following: number true positives (tp), number false positives (fp), sensitivity (sens), specificity (spec), positive predictive value (ppv), number tests rejected (pos), number tests rejected (neg), AUROC (roc_auc), AUPRC (pr_auc). alphas Vector significance levels evaluate various metrics. Default alphas = 0.05. na_rm logical value indicating whether NA values stripped computation proceeds. summary_funs Character vector specifying summarize evaluation metrics. Must choose built-library summary functions - elements vector must one \"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\". custom_summary_funs Named list custom functions summarize results. Names list correspond name summary function. Values list function takes one argument, values evaluated metrics. eval_id Character string. ID used suffix naming result columns. Default NULL add ID column names.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_err_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate and/or summarize error metrics when conducting multiple hypothesis\ntests. — eval_testing_err_funs","text":"output eval_testing_err() tibble following columns: .rep Replicate ID. .dgp_name Name DGP. .method_name Name Method. .alpha Level significance. .metric Name evaluation metric. .estimate Value evaluation metric. well columns specified vary_params. output summarize_testing_err() grouped tibble containing identifying information evaluation results aggregated experimental replicates. Specifically, identifier columns include .dgp_name, .method_name, columns specified vary_params, .metric. addition, results columns corresponding requested statistics summary_funs custom_summary_funs. columns end suffix \"_testing_err\".","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/eval_testing_err_funs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate and/or summarize error metrics when conducting multiple hypothesis\ntests. — eval_testing_err_funs","text":"","code":"# generate example fit_results data for an inference problem fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),         # true feature support         true_support = c(TRUE, FALSE, TRUE),         # estimated p-values         pval = 10^(sample(-3:0, 3, replace = TRUE))       )     }   ) )  # evaluate feature selection (using all default metrics and alpha = 0.05) for each replicate eval_results <- eval_testing_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\" ) # summarize feature selection error (using all default metric and alpha = 0.05) across replicates eval_results_summary <- summarize_testing_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\" )  # evaluate/summarize feature selection (at alpha = 0.05) using specific yardstick metrics metrics <- yardstick::metric_set(yardstick::sens, yardstick::spec) eval_results <- eval_testing_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\",   metrics = metrics ) eval_results_summary <- summarize_testing_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\",   metrics = metrics )  # can evaluate/summarize feature selection at multiple values of alpha eval_results <- eval_testing_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\",   alphas = c(0.05, 0.1) ) eval_results_summary <- summarize_testing_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\",   alphas = c(0.05, 0.1) )  # summarize feature selection (at alpha = 0.05) using specific summary metric range_fun <- function(x) return(max(x) - min(x)) eval_results_summary <- summarize_testing_err(   fit_results,   nested_data = \"feature_info\",   truth_col = \"true_support\",   pval_col = \"pval\",   custom_summary_funs = list(range_testing_err = range_fun) )"},{"path":"https://yu-group.github.io/simChef/dev/reference/evaluate_experiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate an Experiment. — evaluate_experiment","title":"Evaluate an Experiment. — evaluate_experiment","text":"Evaluate performance method(s) across Evaluators Experiment return results.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/evaluate_experiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate an Experiment. — evaluate_experiment","text":"","code":"evaluate_experiment(   experiment,   fit_results,   use_cached = FALSE,   save = FALSE,   verbose = 1,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/evaluate_experiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate an Experiment. — evaluate_experiment","text":"experiment Experiment object. fit_results tibble, returned fit method. use_cached Logical. TRUE, find return previously saved results. cached results found, continue use_cached FALSE. save TRUE, save outputs disk. verbose Level verbosity. Default 1, prints messages major checkpoints experiment. 2, prints additional debugging information warnings messages user-defined functions (addition error debugging information). 0, messages printed user-defined function error debugging information. ... used.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/evaluate_experiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate an Experiment. — evaluate_experiment","text":"list evaluation result tibbles, one Evaluator.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/event_col.html","id":null,"dir":"Reference","previous_headings":"","what":"Logic for event_level in custom yardstick metrics. — event_col","title":"Logic for event_level in custom yardstick metrics. — event_col","text":"Logic event_level custom yardstick metrics.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/event_col.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logic for event_level in custom yardstick metrics. — event_col","text":"","code":"event_col(xtab, event_level)"},{"path":"https://yu-group.github.io/simChef/dev/reference/event_col.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logic for event_level in custom yardstick metrics. — event_col","text":"xtab Frequency table table() event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper generally defaults \"first\", however, deprecated global option yardstick.event_first set, used instead warning.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/event_col.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logic for event_level in custom yardstick metrics. — event_col","text":"Name factor level use \"event\" computing evaluation metrics.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/finalize_estimator_internal_constructor.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for constructing finalize_esitmator_internal for\ncustom yardstick metrics. — finalize_estimator_internal_constructor","title":"Helper function for constructing finalize_esitmator_internal for\ncustom yardstick metrics. — finalize_estimator_internal_constructor","text":"Helper function constructing finalize_esitmator_internal custom yardstick metrics.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/finalize_estimator_internal_constructor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for constructing finalize_esitmator_internal for\ncustom yardstick metrics. — finalize_estimator_internal_constructor","text":"","code":"finalize_estimator_internal_constructor(metric_dispatcher, x, estimator)"},{"path":"https://yu-group.github.io/simChef/dev/reference/fit_experiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit an Experiment. — fit_experiment","title":"Fit an Experiment. — fit_experiment","text":"Fit Methods Experiment across DGPs n_reps repetitions return results fits.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/fit_experiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit an Experiment. — fit_experiment","text":"","code":"fit_experiment(   experiment,   n_reps = 1,   parallel_strategy = c(\"reps\"),   future.globals = NULL,   future.packages = NULL,   future.seed = TRUE,   use_cached = FALSE,   return_all_cached_reps = FALSE,   save = FALSE,   checkpoint_n_reps = 0,   verbose = 1,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/fit_experiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit an Experiment. — fit_experiment","text":"experiment Experiment object. n_reps number replicates Experiment run. parallel_strategy vector combination \"reps\", \"dgps\", \"methods\". Determines computation distributed across available resources. Default \"reps\". future.globals Character vector names global environment pass parallel workers. Passed argument name future.apply::future_lapply related functions. set runs experiment, use argument initialization. future.packages Character vector packages required parallel workers. Passed argument name future.apply::future_lapply related functions. set runs experiment, use argument initialization. future.seed Passed argument name future.apply::future_apply. use_cached Logical. TRUE, find return previously saved results. cached results found, continue use_cached FALSE. return_all_cached_reps Logical. FALSE (default), returns fit results requested n_reps. TRUE, returns fit results requested n_reps plus additional cached replicates (DGP, Method) combinations Experiment. save TRUE, save outputs disk. checkpoint_n_reps number experiment replicates compute saving results disk. 0 (default), checkpoints saved. verbose Level verbosity. Default 1, prints messages major checkpoints experiment. 2, prints additional debugging information warnings messages user-defined functions (addition error debugging information). 0, messages printed user-defined function error debugging information. ... Additional future.* arguments pass future.apply functions. See future.apply::future_lapply() future.apply::future_mapply().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/fit_experiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit an Experiment. — fit_experiment","text":"tibble containing results fitting Methods across DGPs n_reps repetitions. addition results columns, columns named '.rep', '.dgp_name', '.method_name', vary_across parameter names applicable.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/fix_duplicate_param_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Fix duplicate vary across parameter names. — fix_duplicate_param_names","title":"Fix duplicate vary across parameter names. — fix_duplicate_param_names","text":"Add \"_dgp\" \"_method\" suffixes parameter names found DGP Method vary across components. avoid errors occur duplicate column names trying create tibble.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/fix_duplicate_param_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fix duplicate vary across parameter names. — fix_duplicate_param_names","text":"","code":"fix_duplicate_param_names(   dgp_params,   method_params,   duplicate_param_names = NULL )"},{"path":"https://yu-group.github.io/simChef/dev/reference/fix_duplicate_param_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fix duplicate vary across parameter names. — fix_duplicate_param_names","text":"dgp_params named list DGP parameters. method_params named list Method parameters. duplicate_param_names vector parameter names varied across DGP Method","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/fix_duplicate_param_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fix duplicate vary across parameter names. — fix_duplicate_param_names","text":"named list DGP Method parameters duplicate names.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/fp.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of false positives — fp","title":"Number of false positives — fp","text":"functions calculate fp() (number false positives) measurement system compared reference results (\"truth\").","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/fp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of false positives — fp","text":"","code":"fp(data, ...)  # S3 method for data.frame fp(   data,   truth,   estimate,   estimator = NULL,   na_rm = FALSE,   event_level = \"first\",   ... )  fp_vec(   truth,   estimate,   estimator = NULL,   na_rm = FALSE,   event_level = \"first\",   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/fp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of false positives — fp","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper generally defaults \"first\", however, deprecated global option yardstick.event_first set, used instead warning.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/fp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of false positives — fp","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. fp_vec(), single numeric value (NA).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/generate_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate data from each DGP in the Experiment. — generate_data","title":"Generate data from each DGP in the Experiment. — generate_data","text":"Generate data DGP Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/generate_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate data from each DGP in the Experiment. — generate_data","text":"","code":"generate_data(experiment, n_reps = 1, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/generate_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate data from each DGP in the Experiment. — generate_data","text":"experiment Experiment object. n_reps number datasets generate per DGP. ... used.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/generate_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate data from each DGP in the Experiment. — generate_data","text":"list length equal number DGPs Experiment. Experiment vary_across component, element list list n_reps datasets generated given DGP. Experiment vary_across component, element outermost list list lists. second layer lists corresponds specific parameter setting within vary_across scheme, innermost layer lists length n_reps dataset replicates, generated DGP.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_cached_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve cached results from previously saved Experiment. — get_cached_results","title":"Retrieve cached results from previously saved Experiment. — get_cached_results","text":"Read cached results disk previously saved Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_cached_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve cached results from previously saved Experiment. — get_cached_results","text":"","code":"get_cached_results(experiment, results_type, verbose = 0)"},{"path":"https://yu-group.github.io/simChef/dev/reference/get_cached_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve cached results from previously saved Experiment. — get_cached_results","text":"experiment Experiment object. results_type Character string indicating type results read . Must one \"experiment\", \"experiment_cached_params\", \"fit\", \"eval\", \"viz\". verbose Level verbosity. Default 1, prints messages major checkpoints experiment. 2, prints additional debugging information warnings messages user-defined functions (addition error debugging information). 0, messages printed user-defined function error debugging information.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_cached_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve cached results from previously saved Experiment. — get_cached_results","text":"cached results, specifically cached Experiment object results_type = \"experiment\", cached fit results results_type = \"fit\", cached evaluation results results_type = \"eval\", cached visualization results results_type = \"viz\", experiment parameters used cache results_type = \"experiment_cached_params\".","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_dot_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Get dot (...) arguments. — get_dot_args","title":"Get dot (...) arguments. — get_dot_args","text":"Helper function merge default user-specified dot (...) arguments default arguments overwritten user-specified arguments.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_dot_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get dot (...) arguments. — get_dot_args","text":"","code":"get_dot_args(user_args, default_args)"},{"path":"https://yu-group.github.io/simChef/dev/reference/get_dot_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get dot (...) arguments. — get_dot_args","text":"user_args List user-specified dot (...) arguments. default_args List default dot (...) arguments.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_dot_args.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get dot (...) arguments. — get_dot_args","text":"named list arguments includes arguments user defaults, user-specified arguments overwriting defaults.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_dot_args.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get dot (...) arguments. — get_dot_args","text":"","code":"arg_list <- get_dot_args(user_args = list(a = 1, b = 2, c = 3),                           default_args = list(a = \"a\", d = \"d\"))"},{"path":"https://yu-group.github.io/simChef/dev/reference/get_eval_tibble.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the summarized evaluation results tibble for plotting. — get_eval_tibble","title":"Get the summarized evaluation results tibble for plotting. — get_eval_tibble","text":"Helper function get summarized evaluation results tibble plotting. function compute summarized evaluation results computed previously. Otherwise, read previously computed results compute append new results necessary construct specified plot.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_eval_tibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the summarized evaluation results tibble for plotting. — get_eval_tibble","text":"","code":"get_eval_tibble(   fit_results,   eval_tib = NULL,   eval_id = NULL,   eval_fun = paste0(\"summarize_\", eval_id),   vary_params = NULL,   show,   y_str = NULL,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/get_eval_tibble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the summarized evaluation results tibble for plotting. — get_eval_tibble","text":"fit_results tibble, returned fit method. eval_tib (Optional) Tibble (typically output eval_summary_constructor) containing summarized evaluation results plot. provided, evaluation results automatically computed calling eval_fun(). summarized evaluation results already computed previously, eval_tib specified avoid duplicate computations. eval_id Character string. ID used suffix naming columns eval_summary_constructor(). eval_id argument eval_summary_constructor(). eval_fun Function used compute evaluation results summary. function used (required) necessary results already computed eval_tib. vary_params vector parameter names varied across Experiment. show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. y_str (Optional) Name column eval_tib plot y-axis show anything \"boxplot\". Default \"auto\" chooses plot y-axis automatically. ... Additional arguments pass eval_fun(). used necessary results already computed eval_tib.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_eval_tibble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the summarized evaluation results tibble for plotting. — get_eval_tibble","text":"tibble summarized evaluation results.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_eval_tibble.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the summarized evaluation results tibble for plotting. — get_eval_tibble","text":"","code":"# generate example fit results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4, FUN = function(x) rnorm(100)),   # predicted response   predictions = lapply(1:4, FUN = function(x) rnorm(100)) )  # compute (from scratch) the evaluation results that are necessary for plotting eval_tib <- get_eval_tibble(fit_results = fit_results,                              eval_tib = NULL,                             eval_id = \"pred_err\",                             eval_fun = \"summarize_pred_err\",                              show = c(\"point\", \"errorbar\"),                             y_str = NULL,  # or equivalently, \"mean_pred_err\"                             # arguments to pass to `eval_fun`                             truth_col = \"y\",                             estimate_col = \"predictions\") # this is equivalent to: eval_tib2 <- summarize_pred_err(   fit_results = fit_results,    truth_col = \"y\",   estimate_col = \"predictions\",   summary_funs = c(\"mean\", \"sd\") ) all.equal(eval_tib, eval_tib2) #> [1] TRUE  # read in pre-computed evaluation results since it has everything needed for plotting eval_tib <- get_eval_tibble(fit_results = fit_results,                             eval_tib = eval_tib,                              eval_id = \"pred_err\",                             eval_fun = \"summarize_pred_err\",                              show = c(\"point\", \"errorbar\"),                             y_str = NULL)  # or equivalently, \"mean_pred_err\" all.equal(eval_tib, eval_tib2) #> [1] TRUE  # if columns that are needed for plotting are missing in `eval_tib`, then # `get_eval_tibble` will call the `eval_fun` and compute the necessary results eval_tib <- get_eval_tibble(fit_results = fit_results,                              eval_tib = eval_tib %>% dplyr::select(-mean_pred_err),                             eval_id = \"pred_err\",                             eval_fun = \"summarize_pred_err\",                              show = c(\"point\", \"errorbar\"),                             y_str = NULL,  # or equivalently, \"mean_pred_err\"                             # arguments to pass to `eval_fun`                             truth_col = \"y\",                             estimate_col = \"predictions\") all.equal(eval_tib, eval_tib2) #> [1] TRUE"},{"path":"https://yu-group.github.io/simChef/dev/reference/get_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper functions for getting components in an Experiment. — get_funs","title":"Helper functions for getting components in an Experiment. — get_funs","text":"Helper functions getting retrieving DGPs, Methods, Evaluators, Visualizers Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper functions for getting components in an Experiment. — get_funs","text":"","code":"get_dgps(experiment, ...)  get_methods(experiment, ...)  get_evaluators(experiment, ...)  get_visualizers(experiment, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/get_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper functions for getting components in an Experiment. — get_funs","text":"experiment Experiment object. ... used.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper functions for getting components in an Experiment. — get_funs","text":"original Experiment object passed get_*.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_save_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Get results directory for an Experiment. — get_save_dir","title":"Get results directory for an Experiment. — get_save_dir","text":"Get directory Experiment's results visualizations saved.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_save_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get results directory for an Experiment. — get_save_dir","text":"","code":"get_save_dir(experiment)"},{"path":"https://yu-group.github.io/simChef/dev/reference/get_save_dir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get results directory for an Experiment. — get_save_dir","text":"experiment Experiment object.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/get_save_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get results directory for an Experiment. — get_save_dir","text":"relative path Experiment's results visualizations saved.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/inform.html","id":null,"dir":"Reference","previous_headings":"","what":"Signals a message with default subclass ","title":"Signals a message with default subclass ","text":"Signals message default subclass \"simChef_message\".","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/inform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Signals a message with default subclass ","text":"","code":"inform(   message = NULL,   class = \"simChef_message\",   call = rlang::caller_env(),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/inform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Signals a message with default subclass ","text":"message Message include condition. class Subclass passed appropriate rlang signal function. call function environment relevant user's perspective. Default rlang::caller_env(), gives environment attached function called signal function. ... Additional arguments pass appropriate rlang signal function.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/init_docs.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize documentation template for the R Markdown results report. — init_docs","title":"Initialize documentation template for the R Markdown results report. — init_docs","text":"Create documentation template (series .md files) fill R Markdown results report. experiment provided, documentation files can found Experiment's results directory (see Experiment$get_save_dir()) docs/. Otherwise, documentation files can found specified save_dir directory docs/. documentation files generated include objectives.md .md files corresponding DGPs, Methods, Evaluators, Visualizers Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/init_docs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize documentation template for the R Markdown results report. — init_docs","text":"","code":"init_docs(experiment, save_dir)"},{"path":"https://yu-group.github.io/simChef/dev/reference/init_docs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize documentation template for the R Markdown results report. — init_docs","text":"experiment Experiment object. provided, documentation created previously saved Experiments found directory given experiment$get_save_dir(). Experiments previously saved directory, current experiment saved disk used create documentation template. save_dir optional directory find previously saved Experiment objects. Documentation created found Experiments. used experiment provided.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/init_docs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize documentation template for the R Markdown results report. — init_docs","text":"original Experiment object provided. Otherwise, returns NULL.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/init_docs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize documentation template for the R Markdown results report. — init_docs","text":"","code":"if (FALSE) { # create documentation template from an experiment (of class `Experiment`) init_docs(experiment)  # or alternatively, create documentation template from a specific directory init_docs(save_dir = experiment$get_save_dir())}"},{"path":"https://yu-group.github.io/simChef/dev/reference/library_templates.html","id":null,"dir":"Reference","previous_headings":"","what":"Functions to create boilerplate code for specific types of experiments. — library_templates","title":"Functions to create boilerplate code for specific types of experiments. — library_templates","text":"functions make suggestions code performing common types experiments (.e., prediction, feature selection, inference). print code console considered minimal syntax.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/library_templates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Functions to create boilerplate code for specific types of experiments. — library_templates","text":"","code":"use_prediction_template(   experiment_name = \"Prediction Experiment\",   type = c(\"regression\", \"classification\"),   support = FALSE,   include_dgp_example = FALSE,   include_method_example = FALSE )  use_feature_selection_template(   experiment_name = \"Feature Selection Experiment\",   include_dgp_example = FALSE,   include_method_example = FALSE )  use_inference_template(   experiment_name = \"Inference Experiment\",   include_dgp_example = FALSE,   include_method_example = FALSE )"},{"path":"https://yu-group.github.io/simChef/dev/reference/library_templates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Functions to create boilerplate code for specific types of experiments. — library_templates","text":"experiment_name Name experiment. type Either \"regression\" \"classification\" specifying type prediction problem. support Logical. TRUE, include code evaluate estimated feature support. include_dgp_example Logical. TRUE, include completed DGP example, rather fill---blank template. include_method_example Logical. TRUE, include completed Method example, rather fill---blank template.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/library_templates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Functions to create boilerplate code for specific types of experiments. — library_templates","text":"Invisible NULL code printed console.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/library_templates.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Functions to create boilerplate code for specific types of experiments. — library_templates","text":"","code":"# prediction templates use_prediction_template(type = \"regression\") #> dgp <- create_dgp( #>   dgp_fun = stop('Add DGP function here.'), #>   name = stop('Add name of DGP here.'), #>   stop('Add additional arguments (if necessary) to pass to DGP here.') #> )  #>  #> method <- create_method( #>   method_fun = stop('Add Method function here.'), #>   name = stop('Add name of Method here.'), #>   stop('Add additional arguments (if necessary) to pass to Method here.') #> )  #>  #> nested_pred_data <- stop('(Optional) Add name of column in `fit_results` with prediction result columns to be unnested.') #> true_pred_col <- stop('Add name of column in `fit_results` with true responses here.') #> est_pred_col <- stop('Add name of column in `fit_results` with the predicted responses here.') #>  #>  #> pred_err <- create_evaluator( #>   eval_fun = summarize_pred_err, #>   name = 'Prediction Accuracy', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   estimate_col = est_pred_col #> )  #>  #> pred_err_plot <- create_visualizer( #>   viz_fun = plot_pred_err, #>   name = 'Prediction Accuracy Plot', #>   evaluator_name = 'Prediction Accuracy' #> )  #>  #> experiment <- create_experiment(name = 'Prediction Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(pred_err) %>%  #>   add_visualizer(pred_err_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment) #>  use_prediction_template(type = \"classification\") #> dgp <- create_dgp( #>   dgp_fun = stop('Add DGP function here.'), #>   name = stop('Add name of DGP here.'), #>   stop('Add additional arguments (if necessary) to pass to DGP here.') #> )  #>  #> method <- create_method( #>   method_fun = stop('Add Method function here.'), #>   name = stop('Add name of Method here.'), #>   stop('Add additional arguments (if necessary) to pass to Method here.') #> )  #>  #> nested_pred_data <- stop('(Optional) Add name of column in `fit_results` with prediction result columns to be unnested.') #> true_pred_col <- stop('Add name of column in `fit_results` with true responses here.') #> est_pred_col <- stop('Add name of column in `fit_results` with the predicted responses here.') #> prob_pred_cols <- stop('Add name of column(s) in `fit_results` with the predicted probabilities here.') #>  #>  #> pred_err <- create_evaluator( #>   eval_fun = summarize_pred_err, #>   name = 'Prediction Accuracy', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   estimate_col = est_pred_col, #>   prob_cols = prob_pred_cols #> )  #>  #> pred_err_plot <- create_visualizer( #>   viz_fun = plot_pred_err, #>   name = 'Prediction Accuracy Plot', #>   evaluator_name = 'Prediction Accuracy' #> )  #>  #> roc_plot <- create_visualizer( #>   viz_fun = plot_pred_curve, #>   name = 'ROC Plot', #>   curve = 'ROC', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   prob_cols = prob_pred_cols #> )  #>  #> pr_plot <- create_visualizer( #>   viz_fun = plot_pred_curve, #>   name = 'PR Plot', #>   curve = 'PR', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   prob_cols = prob_pred_cols #> )  #>  #> experiment <- create_experiment(name = 'Prediction Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(pred_err) %>%  #>   add_visualizer(pred_err_plot) %>%  #>   add_visualizer(roc_plot) %>%  #>   add_visualizer(pr_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment) #>   # prediction templates with example DGP and Method use_prediction_template(type = \"regression\",                          include_dgp_example = TRUE,                         include_method_example = TRUE) #> dgp <- create_dgp( #>   dgp_fun = xy_dgp_constructor, #>   name = 'Example DGP (Uncorrelated Gaussian Linear DGP)', #>   X_fun = generate_X_gaussian, #>   y_fun = generate_y_linear, #>   err_fun = rnorm, #>   n = 200, #>   p = 10, #>   betas = c(rep(1, 5), rep(0, 5)), #>   .err_sd = 1, #>   data_split = TRUE, #>   train_prop = 0.5, #>   return_support = TRUE #> )  #>  #> rf_method <-function (X, y, Xtest, ytest, support, ...)  #> { #>     data <- as.data.frame(X) %>% cbind(.y = y) #>     if (is.factor(y)) { #>         mtry <- round(sqrt(ncol(X))) #>     } #>     else { #>         mtry <- round(ncol(X)/3) #>     } #>     fit <- ranger::ranger(data = data, dependent.variable.name = \".y\",  #>         importance = \"impurity\", mtry = mtry, num.threads = 1,  #>         ...) #>     preds <- stats::predict(fit, as.data.frame(Xtest))$predictions #>     if (is.factor(y)) { #>         k <- nlevels(y) #>         prob_preds <- stats::predict(fit, as.data.frame(Xtest),  #>             predict.all = TRUE, num.threads = 1)$predictions #>         prob_preds <- purrr::map_dfr(1:nrow(prob_preds), function(i) { #>             x <- factor(prob_preds[i, ], levels = 1:k) #>             c(prop.table(table(x))) #>         }) %>% stats::setNames(levels(y)) %>% dplyr::select(-1) #>     } #>     else { #>         prob_preds <- NULL #>     } #>     p <- ncol(X) #>     if (is.null(colnames(X))) { #>         features <- 1:p #>     } #>     else { #>         features <- colnames(X) #>     } #>     out <- list(y = y, predictions = preds, prob_predictions = prob_preds,  #>         support_df = data.frame(feature = features, true_support = 1:p %in%  #>             support, imp = fit$variable.importance, selected = fit$variable.importance >  #>             mean(fit$variable.importance))) #>     return(out) #> }  #>  #> method <- create_method( #>   method_fun = rf_method, #>   name = 'RF' #> )  #>  #> nested_pred_data <- c('y', 'predictions', 'prob_predictions')  # prediction results columns to be unnested #> true_pred_col <- 'y'  # true response column #> est_pred_col <- 'predictions'  # predicted response column #>  #>  #> pred_err <- create_evaluator( #>   eval_fun = summarize_pred_err, #>   name = 'Prediction Accuracy', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   estimate_col = est_pred_col #> )  #>  #> pred_err_plot <- create_visualizer( #>   viz_fun = plot_pred_err, #>   name = 'Prediction Accuracy Plot', #>   evaluator_name = 'Prediction Accuracy' #> )  #>  #> experiment <- create_experiment(name = 'Prediction Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(pred_err) %>%  #>   add_visualizer(pred_err_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment) #>  use_prediction_template(type = \"classification\",                          include_dgp_example = TRUE,                         include_method_example = TRUE) #> dgp <- create_dgp( #>   dgp_fun = xy_dgp_constructor, #>   name = 'Example DGP (Uncorrelated Gaussian Logistic DGP)', #>   X_fun = generate_X_gaussian, #>   y_fun = generate_y_logistic, #>   n = 200, #>   p = 10, #>   betas = c(rep(1, 5), rep(0, 5)), #>   data_split = TRUE, #>   train_prop = 0.5, #>   return_support = TRUE #> )  #>  #> rf_method <-function (X, y, Xtest, ytest, support, ...)  #> { #>     data <- as.data.frame(X) %>% cbind(.y = y) #>     if (is.factor(y)) { #>         mtry <- round(sqrt(ncol(X))) #>     } #>     else { #>         mtry <- round(ncol(X)/3) #>     } #>     fit <- ranger::ranger(data = data, dependent.variable.name = \".y\",  #>         importance = \"impurity\", mtry = mtry, num.threads = 1,  #>         ...) #>     preds <- stats::predict(fit, as.data.frame(Xtest))$predictions #>     if (is.factor(y)) { #>         k <- nlevels(y) #>         prob_preds <- stats::predict(fit, as.data.frame(Xtest),  #>             predict.all = TRUE, num.threads = 1)$predictions #>         prob_preds <- purrr::map_dfr(1:nrow(prob_preds), function(i) { #>             x <- factor(prob_preds[i, ], levels = 1:k) #>             c(prop.table(table(x))) #>         }) %>% stats::setNames(levels(y)) %>% dplyr::select(-1) #>     } #>     else { #>         prob_preds <- NULL #>     } #>     p <- ncol(X) #>     if (is.null(colnames(X))) { #>         features <- 1:p #>     } #>     else { #>         features <- colnames(X) #>     } #>     out <- list(y = y, predictions = preds, prob_predictions = prob_preds,  #>         support_df = data.frame(feature = features, true_support = 1:p %in%  #>             support, imp = fit$variable.importance, selected = fit$variable.importance >  #>             mean(fit$variable.importance))) #>     return(out) #> }  #>  #> method <- create_method( #>   method_fun = rf_method, #>   name = 'RF' #> )  #>  #> nested_pred_data <- c('y', 'predictions', 'prob_predictions')  # prediction results columns to be unnested #> true_pred_col <- 'y'  # true response column #> est_pred_col <- 'predictions'  # predicted response column #> prob_pred_cols <- '1'  # predicted probability columns #>  #>  #> pred_err <- create_evaluator( #>   eval_fun = summarize_pred_err, #>   name = 'Prediction Accuracy', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   estimate_col = est_pred_col, #>   prob_cols = prob_pred_cols #> )  #>  #> pred_err_plot <- create_visualizer( #>   viz_fun = plot_pred_err, #>   name = 'Prediction Accuracy Plot', #>   evaluator_name = 'Prediction Accuracy' #> )  #>  #> roc_plot <- create_visualizer( #>   viz_fun = plot_pred_curve, #>   name = 'ROC Plot', #>   curve = 'ROC', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   prob_cols = prob_pred_cols #> )  #>  #> pr_plot <- create_visualizer( #>   viz_fun = plot_pred_curve, #>   name = 'PR Plot', #>   curve = 'PR', #>   nested_data = nested_pred_data, #>   truth_col = true_pred_col, #>   prob_cols = prob_pred_cols #> )  #>  #> experiment <- create_experiment(name = 'Prediction Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(pred_err) %>%  #>   add_visualizer(pred_err_plot) %>%  #>   add_visualizer(roc_plot) %>%  #>   add_visualizer(pr_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment) #>   # feature selection template use_feature_selection_template() #> dgp <- create_dgp( #>   dgp_fun = stop('Add DGP function here.'), #>   name = stop('Add name of DGP here.'), #>   stop('Add additional arguments (if necessary) to pass to DGP here.') #> )  #>  #> method <- create_method( #>   method_fun = stop('Add Method function here.'), #>   name = stop('Add name of Method here.'), #>   stop('Add additional arguments (if necessary) to pass to Method here.') #> )  #>  #> nested_feature_data <- stop('(Optional) Add name of column in `fit_results` with feature importance columns to be unnested here.') #> feature_col <- stop('Add name of column in `fit_results` containing the feature names here.') #> true_feature_col <- stop('Add name of column in `fit_results` containing the true feature support here.') #> feature_imp_col <- stop('Add name of column in `fit_results` containing the feature importances here.') #> feature_sel_col <- stop('(Optional) Add name of column in `fit_results` containing the (estimated) selected features here.') #>  #> fi <- create_evaluator( #>   eval_fun = summarize_feature_importance, #>   name = 'Feature Importances', #>   nested_data = nested_feature_data, #>   feature_col = feature_col, #>   imp_col = feature_imp_col #> )  #>  #> feature_sel <- create_evaluator( #>   eval_fun = summarize_feature_selection_err, #>   name = 'Feature Selection Error', #>   nested_data = nested_feature_data, #>   truth_col = true_feature_col, #>   estimate_col = feature_sel_col, #>   imp_col = feature_imp_col #> )  #>  #> fi_plot <- create_visualizer( #>   viz_fun = plot_feature_importance, #>   name = 'Feature Importances Plot', #>   evaluator_name = 'Feature Importances', #>   feature_col = feature_col #> )  #>  #> feature_sel_plot <- create_visualizer( #>   viz_fun = plot_feature_selection_err, #>   name = 'Feature Selection Error Plot', #>   evaluator_name = 'Feature Selection Error' #> )  #>  #> experiment <- create_experiment(name = 'Feature Selection Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(fi) %>%  #>   add_evaluator(feature_sel) %>%  #>   add_visualizer(fi_plot) %>%  #>   add_visualizer(feature_sel_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment) #>  # feature selection template with example DGP and Method use_feature_selection_template(include_dgp_example = TRUE,                                 include_method_example = TRUE) #> dgp <- create_dgp( #>   dgp_fun = xy_dgp_constructor, #>   name = 'Example DGP (Uncorrelated Gaussian Linear DGP)', #>   X_fun = generate_X_gaussian, #>   y_fun = generate_y_linear, #>   err_fun = rnorm, #>   n = 200, #>   p = 10, #>   betas = c(rep(1, 5), rep(0, 5)), #>   .err_sd = 1, #>   data_split = TRUE, #>   train_prop = 0.5, #>   return_support = TRUE #> )  #>  #> rf_method <-function (X, y, Xtest, ytest, support, ...)  #> { #>     data <- as.data.frame(X) %>% cbind(.y = y) #>     if (is.factor(y)) { #>         mtry <- round(sqrt(ncol(X))) #>     } #>     else { #>         mtry <- round(ncol(X)/3) #>     } #>     fit <- ranger::ranger(data = data, dependent.variable.name = \".y\",  #>         importance = \"impurity\", mtry = mtry, num.threads = 1,  #>         ...) #>     preds <- stats::predict(fit, as.data.frame(Xtest))$predictions #>     if (is.factor(y)) { #>         k <- nlevels(y) #>         prob_preds <- stats::predict(fit, as.data.frame(Xtest),  #>             predict.all = TRUE, num.threads = 1)$predictions #>         prob_preds <- purrr::map_dfr(1:nrow(prob_preds), function(i) { #>             x <- factor(prob_preds[i, ], levels = 1:k) #>             c(prop.table(table(x))) #>         }) %>% stats::setNames(levels(y)) %>% dplyr::select(-1) #>     } #>     else { #>         prob_preds <- NULL #>     } #>     p <- ncol(X) #>     if (is.null(colnames(X))) { #>         features <- 1:p #>     } #>     else { #>         features <- colnames(X) #>     } #>     out <- list(y = y, predictions = preds, prob_predictions = prob_preds,  #>         support_df = data.frame(feature = features, true_support = 1:p %in%  #>             support, imp = fit$variable.importance, selected = fit$variable.importance >  #>             mean(fit$variable.importance))) #>     return(out) #> }  #>  #> method <- create_method( #>   method_fun = rf_method, #>   name = 'RF' #> )  #>  #> nested_feature_data <- 'support_df'  # feature importance columns to be unnested #> feature_col <- 'feature'  # feature names column #> true_feature_col <- 'true_support'  # true feature support column #> feature_imp_col <- 'imp'  # feature importance column #> feature_sel_col <- 'selected'  # estimated feature support column #>  #> fi <- create_evaluator( #>   eval_fun = summarize_feature_importance, #>   name = 'Feature Importances', #>   nested_data = nested_feature_data, #>   feature_col = feature_col, #>   imp_col = feature_imp_col #> )  #>  #> feature_sel <- create_evaluator( #>   eval_fun = summarize_feature_selection_err, #>   name = 'Feature Selection Error', #>   nested_data = nested_feature_data, #>   truth_col = true_feature_col, #>   estimate_col = feature_sel_col, #>   imp_col = feature_imp_col #> )  #>  #> fi_plot <- create_visualizer( #>   viz_fun = plot_feature_importance, #>   name = 'Feature Importances Plot', #>   evaluator_name = 'Feature Importances', #>   feature_col = feature_col #> )  #>  #> feature_sel_plot <- create_visualizer( #>   viz_fun = plot_feature_selection_err, #>   name = 'Feature Selection Error Plot', #>   evaluator_name = 'Feature Selection Error' #> )  #>  #> experiment <- create_experiment(name = 'Feature Selection Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(fi) %>%  #>   add_evaluator(feature_sel) %>%  #>   add_visualizer(fi_plot) %>%  #>   add_visualizer(feature_sel_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment) #>   # inference template use_inference_template() #> dgp <- create_dgp( #>   dgp_fun = stop('Add DGP function here.'), #>   name = stop('Add name of DGP here.'), #>   stop('Add additional arguments (if necessary) to pass to DGP here.') #> )  #>  #> method <- create_method( #>   method_fun = stop('Add Method function here.'), #>   name = stop('Add name of Method here.'), #>   stop('Add additional arguments (if necessary) to pass to Method here.') #> )  #>  #> nested_feature_data <- stop('(Optional) Add name of column in `fit_results` with feature importance columns to be unnested here.') #> feature_col <- stop('Add name of column in `fit_results` containing the feature names here.') #> true_feature_col <- stop('Add name of column in `fit_results` containing the true feature support here.') #> pval_col <- stop('Add name of column in `fit_results` containing the p-values here.') #>  #> inf_err <- create_evaluator( #>   eval_fun = summarize_testing_err, #>   name = 'Hypothesis Testing Error', #>   nested_data = nested_feature_data, #>   truth_col = true_feature_col, #>   pval_col = pval_col #> )  #>  #> fi_pval <- create_evaluator( #>   eval_fun = summarize_feature_importance, #>   eval_id = 'pval', #>   name = 'P-value Summary Statistics', #>   nested_data = nested_feature_data, #>   feature_col = feature_col, #>   imp_col = pval_col #> )  #>  #> inf_err_plot <- create_visualizer( #>   viz_fun = plot_testing_err, #>   name = 'Hypothesis Testing Error Plot', #>   evaluator_name = 'Hypothesis Testing Error' #> )  #>  #> inf_roc_plot <- create_visualizer( #>   viz_fun = plot_testing_curve, #>   name = 'Feature ROC Plot', #>   curve = 'ROC', #>   nested_data = nested_feature_data, #>   truth_col = true_feature_col, #>   pval_col = pval_col #> )  #>  #> inf_pr_plot <- create_visualizer( #>   viz_fun = plot_testing_curve, #>   name = 'Feature Selection PR Plot', #>   curve = 'PR', #>   nested_data = nested_feature_data, #>   truth_col = true_feature_col, #>   pval_col = pval_col #> )  #>  #> reject_prob_plot <- create_visualizer( #>   viz_fun = plot_reject_prob, #>   name = 'Rejection Probability Curve', #>   nested_data = nested_feature_data, #>   feature_col = feature_col, #>   pval_col = pval_col #> )  #>  #> experiment <- create_experiment(name = 'Inference Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(inf_err) %>%  #>   add_evaluator(fi_pval) %>%  #>   add_visualizer(inf_err_plot) %>%  #>   add_visualizer(inf_roc_plot) %>%  #>   add_visualizer(inf_pr_plot) %>%  #>   add_visualizer(reject_prob_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment) #>  # inference template with example DGP and Method use_inference_template(include_dgp_example = TRUE,                        include_method_example = TRUE) #> dgp <- create_dgp( #>   dgp_fun = xy_dgp_constructor, #>   name = 'Example DGP (Uncorrelated Gaussian Linear DGP)', #>   X_fun = generate_X_gaussian, #>   y_fun = generate_y_linear, #>   err_fun = rnorm, #>   n = 200, #>   p = 10, #>   betas = c(rep(1, 5), rep(0, 5)), #>   .err_sd = 1, #>   data_split = TRUE, #>   train_prop = 0.5, #>   return_support = TRUE #> )  #>  #> ols_method <-function (X, y, Xtest, ytest, support, ...)  #> { #>     data <- as.data.frame(X) %>% cbind(.y = y) #>     if (is.factor(y)) { #>         stop(\"OLS cannot be applied to a factor response.\") #>     } #>     fit <- stats::lm(.y ~ ., data = data) #>     p <- ncol(X) #>     if (is.null(colnames(X))) { #>         features <- 1:p #>     } #>     else { #>         features <- colnames(X) #>     } #>     out <- list(support_df = data.frame(feature = features, true_support = 1:p %in%  #>         support, pval = broom::tidy(fit)$p.value[-1])) #>     return(out) #> }  #>  #> method <- create_method( #>   method_fun = ols_method, #>   name = 'OLS' #> )  #>  #> nested_feature_data <- 'support_df'  # feature importance columns to be unnested #> feature_col <- 'feature'  # feature names column #> true_feature_col <- 'true_support'  # true feature support column #> pval_col <- 'pval'  # p-values column #>  #> inf_err <- create_evaluator( #>   eval_fun = summarize_testing_err, #>   name = 'Hypothesis Testing Error', #>   nested_data = nested_feature_data, #>   truth_col = true_feature_col, #>   pval_col = pval_col #> )  #>  #> fi_pval <- create_evaluator( #>   eval_fun = summarize_feature_importance, #>   eval_id = 'pval', #>   name = 'P-value Summary Statistics', #>   nested_data = nested_feature_data, #>   feature_col = feature_col, #>   imp_col = pval_col #> )  #>  #> inf_err_plot <- create_visualizer( #>   viz_fun = plot_testing_err, #>   name = 'Hypothesis Testing Error Plot', #>   evaluator_name = 'Hypothesis Testing Error' #> )  #>  #> inf_roc_plot <- create_visualizer( #>   viz_fun = plot_testing_curve, #>   name = 'Feature ROC Plot', #>   curve = 'ROC', #>   nested_data = nested_feature_data, #>   truth_col = true_feature_col, #>   pval_col = pval_col #> )  #>  #> inf_pr_plot <- create_visualizer( #>   viz_fun = plot_testing_curve, #>   name = 'Feature Selection PR Plot', #>   curve = 'PR', #>   nested_data = nested_feature_data, #>   truth_col = true_feature_col, #>   pval_col = pval_col #> )  #>  #> reject_prob_plot <- create_visualizer( #>   viz_fun = plot_reject_prob, #>   name = 'Rejection Probability Curve', #>   nested_data = nested_feature_data, #>   feature_col = feature_col, #>   pval_col = pval_col #> )  #>  #> experiment <- create_experiment(name = 'Inference Experiment') %>%  #>   add_dgp(dgp) %>%  #>   add_method(method) %>%  #>   add_evaluator(inf_err) %>%  #>   add_evaluator(fi_pval) %>%  #>   add_visualizer(inf_err_plot) %>%  #>   add_visualizer(inf_roc_plot) %>%  #>   add_visualizer(inf_pr_plot) %>%  #>   add_visualizer(reject_prob_plot)  #>  #> init_docs(experiment)  #> fill out documentation before proceeding! #>  #> results <- run_experiment( #>   experiment = experiment, #>   n_reps = stop('Add number of replicates here.'), #>   save = TRUE #> )  #>  #> render_docs(experiment) #>"},{"path":"https://yu-group.github.io/simChef/dev/reference/list_col_to_chr.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert a list column to a readable character column. — list_col_to_chr","title":"Convert a list column to a readable character column. — list_col_to_chr","text":"Convert list-type column (typically tibble) character-type column. Often useful plotting along column.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/list_col_to_chr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert a list column to a readable character column. — list_col_to_chr","text":"","code":"list_col_to_chr(list_col, name = NULL, verbatim = FALSE)"},{"path":"https://yu-group.github.io/simChef/dev/reference/list_col_to_chr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert a list column to a readable character column. — list_col_to_chr","text":"list_col list-type column converted character. name Name column. Used prefix returned character strings. Default NULL, adds prefix. verbatim TRUE, paste list contents together character vector. FALSE (default), map items list unique identifiers (.e., 1, 2, 3, ...).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/list_col_to_chr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert a list column to a readable character column. — list_col_to_chr","text":"character vector length list_col.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/list_col_to_chr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert a list column to a readable character column. — list_col_to_chr","text":"","code":"# create example tibble with list columns to convert plot_tib <- tibble::tibble(a = 1:3,                            b = list(1, 2, 3),                            c = list(1:2, 3:4, 5:6),                            d = list(tibble::tibble(a = 1:3,                                                     b = c(4, 5, 6)),                                     \"abc\",                                     123)) # verbatim = TRUE pastes lists together verbatim plot_tib_chr_verbatim <- plot_tib %>%   dplyr::mutate(dplyr::across(tidyselect::everything(),                               ~list_col_to_chr(.x,                                                 name = dplyr::cur_column(),                                                verbatim = TRUE)))  # verbatim = FALSE maps items in list to unique ids (i.e., 1, 2, 3, ...) plot_tib_chr <- plot_tib %>%   dplyr::mutate(dplyr::across(tidyselect::everything(),                               ~list_col_to_chr(.x,                                                 name = dplyr::cur_column(),                                                verbatim = FALSE)))"},{"path":"https://yu-group.github.io/simChef/dev/reference/list_to_tibble.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce list into a tibble. — list_to_tibble","title":"Coerce list into a tibble. — list_to_tibble","text":"Coerce list tibble. Default coerce using tibble::as_tibble(), fails, coerce list tibble, non-scalar column tibble type list.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/list_to_tibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce list into a tibble. — list_to_tibble","text":"","code":"list_to_tibble(lst)"},{"path":"https://yu-group.github.io/simChef/dev/reference/list_to_tibble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce list into a tibble. — list_to_tibble","text":"lst List convert tibble.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/list_to_tibble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce list into a tibble. — list_to_tibble","text":"tibble.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/list_to_tibble_row.html","id":null,"dir":"Reference","previous_headings":"","what":"Coerce list into a tibble row. — list_to_tibble_row","title":"Coerce list into a tibble row. — list_to_tibble_row","text":"Coerce list single row tibble. Default coerce using tibble::as_tibble_row(), fails, coerce list tibble row, column tibble type list.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/list_to_tibble_row.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coerce list into a tibble row. — list_to_tibble_row","text":"","code":"list_to_tibble_row(lst, simplify = FALSE)"},{"path":"https://yu-group.github.io/simChef/dev/reference/list_to_tibble_row.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coerce list into a tibble row. — list_to_tibble_row","text":"lst List convert tibble row.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/list_to_tibble_row.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coerce list into a tibble row. — list_to_tibble_row","text":"tibble one row.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/metric_vec_constructor.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function for constructing metric_vec methods for\ncustom yardstick metrics. — metric_vec_constructor","title":"Helper function for constructing metric_vec methods for\ncustom yardstick metrics. — metric_vec_constructor","text":"Helper function constructing metric_vec methods custom yardstick metrics.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/metric_vec_constructor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function for constructing metric_vec methods for\ncustom yardstick metrics. — metric_vec_constructor","text":"","code":"metric_vec_constructor(   name,   fun,   truth,   estimate,   estimator,   na_rm,   event_level,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/neg.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of estimated negative cases — neg","title":"Number of estimated negative cases — neg","text":"functions calculate neg() (number estimated negative cases) measurement system compared reference results (\"truth\").","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/neg.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of estimated negative cases — neg","text":"","code":"neg(data, ...)  # S3 method for data.frame neg(   data,   truth,   estimate,   estimator = NULL,   na_rm = FALSE,   event_level = \"first\",   ... )  neg_vec(   truth,   estimate,   estimator = NULL,   na_rm = FALSE,   event_level = \"first\",   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/neg.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of estimated negative cases — neg","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper generally defaults \"first\", however, deprecated global option yardstick.event_first set, used instead warning.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/neg.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of estimated negative cases — neg","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. neg_vec(), single numeric value (NA).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/obj_size.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the size of an object, including environments. — obj_size","title":"Get the size of an object, including environments. — obj_size","text":"Get size object, including environments.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/obj_size.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the size of an object, including environments. — obj_size","text":"","code":"obj_size(obj = rlang::caller_env())"},{"path":"https://yu-group.github.io/simChef/dev/reference/obj_size.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the size of an object, including environments. — obj_size","text":"obj object measure. Default calling environment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pasteMd.html","id":null,"dir":"Reference","previous_headings":"","what":"Read Markdown file into R Markdown. — pasteMd","title":"Read Markdown file into R Markdown. — pasteMd","text":"Read contents Markdown file R Markdown.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pasteMd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read Markdown file into R Markdown. — pasteMd","text":"","code":"pasteMd(filename)"},{"path":"https://yu-group.github.io/simChef/dev/reference/pasteMd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read Markdown file into R Markdown. — pasteMd","text":"filename filepath markdown file read R Markdown","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pasteMd.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Read Markdown file into R Markdown. — pasteMd","text":"Adapted https://stackoverflow.com/questions/56328581/--read-markdown-code---file---r-markdown-document.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://yu-group.github.io/simChef/dev/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pipe_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Find last non-comment line, add a %>% to the end, then add another line. — pipe_value","title":"Find last non-comment line, add a %>% to the end, then add another line. — pipe_value","text":"function adapted function name usemodels package.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pipe_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find last non-comment line, add a %>% to the end, then add another line. — pipe_value","text":"","code":"pipe_value(base, value, expr_width = 80)"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_eval_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Developer function for plotting summary of evaluation results. — plot_eval_summary","title":"Developer function for plotting summary of evaluation results. — plot_eval_summary","text":"helper function developing new Visualizer plotting functions plot summarized evaluation results boxplot, scatter plot, line plot, bar plot without 1 SD error bars/ribbons. function accepts either (1) pre-computed tibble containing summarized evaluation results (2) Evaluator function corresponding function arguments computing evaluation results within function call.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_eval_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Developer function for plotting summary of evaluation results. — plot_eval_summary","text":"","code":"plot_eval_summary(   fit_results,   eval_tib = NULL,   eval_id = NULL,   eval_fun = paste0(\"summarize_\", eval_id),   vary_params = NULL,   show = c(\"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\"),   x_str = \"auto\",   y_str = \"auto\",   err_sd_str = \"auto\",   color_str = \"auto\",   linetype_str = \"auto\",   facet_formula = NULL,   facet_type = c(\"grid\", \"wrap\"),   plot_by = \"auto\",   add_ggplot_layers = NULL,   boxplot_args = NULL,   point_args = NULL,   line_args = NULL,   bar_args = NULL,   errorbar_args = NULL,   ribbon_args = NULL,   facet_args = NULL,   interactive = FALSE,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_eval_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Developer function for plotting summary of evaluation results. — plot_eval_summary","text":"fit_results tibble, returned fit method. eval_tib (Optional) Tibble (typically output eval_summary_constructor) containing summarized evaluation results plot. provided, evaluation results automatically computed calling eval_fun(). summarized evaluation results already computed previously, eval_tib specified avoid duplicate computations. eval_id Character string. ID used suffix naming columns eval_summary_constructor(). eval_id argument eval_summary_constructor(). eval_fun Function used compute evaluation results summary. function used (required) necessary results already computed eval_tib. vary_params vector parameter names varied across Experiment. show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. x_str (Optional) Name column eval_tib plot x-axis. Default \"auto\" chooses plot x-axis automatically. y_str (Optional) Name column eval_tib plot y-axis show anything \"boxplot\". Default \"auto\" chooses plot y-axis automatically. err_sd_str (Optional) Name column eval_tib containing standard deviations y_str. Used plotting errorbar ribbon ggplot layers. Default \"auto\" chooses column use standard deviations automatically. color_str (Optional) Name column eval_tib use color fill aesthetics plotting. Default \"auto\" chooses use color fill aesthetics automatically. Use NULL avoid adding color fill aesthetic. linetype_str (Optional) Name column eval_tib use linetype aesthetic plotting. Used show = \"line\". Default \"auto\" chooses use linetype aesthetic automatically. Use NULL avoid adding linetype aesthetic. facet_formula (Optional) Formula ggplot2::facet_wrap() ggplot2::facet_grid() need . facet_type One \"grid\" \"wrap\" specifying whether use ggplot2::facet_wrap() ggplot2::facet_grid() need . plot_by (Optional) Name column eval_tib use subsetting data creating different plots unique value. Default \"auto\" chooses column use subsetting automatically. Use NULL avoid creating multiple plots. add_ggplot_layers List additional layers add ggplot object via +. boxplot_args (Optional) Additional arguments pass ggplot2::geom_boxplot(). point_args (Optional) Additional arguments pass ggplot2::geom_point(). line_args (Optional) Additional arguments pass ggplot2::geom_line(). bar_args (Optional) Additional arguments pass ggplot2::geom_bar(). errorbar_args (Optional) Additional arguments pass ggplot2::geom_errorbar(). ribbon_args (Optional) Additional arguments pass ggplot2::geom_ribbon(). facet_args (Optional) Additional arguments pass ggplot2::facet_grid() ggplot2::facet_wrap(). interactive Logical. TRUE, returns interactive plotly plots. FALSE, returns static ggplot plots. ... Additional arguments pass eval_fun(). used necessary results already computed eval_tib.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_eval_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Developer function for plotting summary of evaluation results. — plot_eval_summary","text":"interactive = TRUE, returns plotly object plot_by NULL list plotly objects plot_by NULL. interactive = FALSE, returns ggplot object plot_by NULL list ggplot objects plot_by NULL.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_eval_summary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Developer function for plotting summary of evaluation results. — plot_eval_summary","text":"","code":"# generate example fit results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4, FUN = function(x) rnorm(100)),   # predicted response   predictions = lapply(1:4, FUN = function(x) rnorm(100)) )  # generate example evaluation results data eval_results <- list(   `Prediction Errors` = summarize_pred_err(     fit_results = fit_results,      truth_col = \"y\",      estimate_col = \"predictions\",      eval_id = \"pred_err\"   ) )  # create plot using pre-computed evaluation results plt <- plot_eval_summary(fit_results = fit_results,                           eval_tib = eval_results[[\"Prediction Errors\"]],                          eval_id = \"pred_err\",                          show = c(\"point\", \"errorbar\"),                          facet_formula = ~ .metric) # can customize plots using additional arguments or ggplot2::`+` plt <- plot_eval_summary(fit_results = fit_results,                           eval_tib = eval_results[[\"Prediction Errors\"]],                          eval_id = \"pred_err\",                          show = c(\"point\", \"errorbar\"),                          facet_formula = ~ .metric,                          facet_type = \"wrap\",                          errorbar_args = list(width = 0.5),                          facet_args = list(scales = \"free\")) +   ggplot2::labs(y = \"Mean Prediction Error\") # can return interactive plotly plot plt <- plot_eval_summary(fit_results = fit_results,                           eval_tib = eval_results[[\"Prediction Errors\"]],                          eval_id = \"pred_err\",                          show = c(\"point\", \"errorbar\"),                          facet_formula = ~ .metric,                          interactive = TRUE)  # create plot without pre-computing evaluation results; instead, need to  # pass in summarize_* function and its arguments plt <- plot_eval_summary(fit_results = fit_results,                          eval_id = \"pred_err\",                          eval_fun = \"summarize_pred_err\",                          truth_col = \"y\",                           estimate_col = \"predictions\",                          show = c(\"point\", \"errorbar\"),                          facet_formula = ~ .metric)"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_importance.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot feature importances. — plot_feature_importance","title":"Plot feature importances. — plot_feature_importance","text":"Plot raw summarized feature importances boxplot, scatter plot, line plot, bar plot without 1 SD error bars.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_importance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot feature importances. — plot_feature_importance","text":"","code":"plot_feature_importance(   fit_results,   eval_results = NULL,   evaluator_name = NULL,   vary_params = NULL,   feature_col,   show_max_features = NULL,   show = c(\"errorbar\", \"bar\"),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_importance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot feature importances. — plot_feature_importance","text":"fit_results tibble, returned fit method. eval_results list result tibbles, returned evaluate method. evaluator_name Name Evaluator containing results plot. compute evaluation summary results scratch evaluation summary results yet evaluated, set NULL. vary_params vector parameter names varied across Experiment. feature_col character string identifying column fit_results feature names IDs. show_max_features Maximum number features plot. show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. ... Additional arguments pass plot_eval_summary(). includes arguments plotting passing summarize_feature_importance().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_importance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot feature importances. — plot_feature_importance","text":"interactive = TRUE, returns plotly object plot_by NULL list plotly objects plot_by NULL. interactive = FALSE, returns ggplot object plot_by NULL list ggplot objects plot_by NULL.","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_importance.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot feature importances. — plot_feature_importance","text":"","code":"# generate example fit_results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),         # estimated feature importance scores         est_importance = c(10, runif(2, min = -2, max = 2))         )     }   ) )  # generate example eval_results data eval_results <- list(   `Feature Importance` = summarize_feature_importance(     fit_results,     nested_data = \"feature_info\",     feature_col = \"feature\",     imp_col = \"est_importance\"   ) )  # create bar plot using pre-computed evaluation results plt <- plot_feature_importance(fit_results = fit_results,                                eval_results = eval_results,                                evaluator_name = \"Feature Importance\",                                feature_col = \"feature\") # or alternatively, create the same plot without pre-computing evaluation results plt <- plot_feature_importance(fit_results,                                nested_data = \"feature_info\",                                feature_col = \"feature\",                                imp_col = \"est_importance\")  # can customize plot (see plot_eval_summary() for possible arguments) plt <- plot_feature_importance(fit_results = fit_results,                                eval_results = eval_results,                                evaluator_name = \"Feature Importance\",                                feature_col = \"feature\",                                errorbar_args = list(width = .5, position = \"dodge\"),                                bar_args = list(width = .5))"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot ROC/PR curves for feature selection. — plot_feature_selection_curve","title":"Plot ROC/PR curves for feature selection. — plot_feature_selection_curve","text":"Plot ROC/PR curves feature selection summary thereof across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot ROC/PR curves for feature selection. — plot_feature_selection_curve","text":"","code":"plot_feature_selection_curve(   fit_results,   eval_results = NULL,   evaluator_name = NULL,   vary_params = NULL,   curve = c(\"ROC\", \"PR\"),   show = c(\"line\", \"ribbon\"),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot ROC/PR curves for feature selection. — plot_feature_selection_curve","text":"fit_results tibble, returned fit method. eval_results list result tibbles, returned evaluate method. evaluator_name Name Evaluator containing results plot. compute evaluation summary results scratch evaluation summary results yet evaluated, set NULL. vary_params vector parameter names varied across Experiment. curve Either \"ROC\" \"PR\" indicating whether plot ROC Precision-Recall curve. show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. ... Additional arguments pass plot_eval_summary(). includes arguments plotting passing summarize_feature_selection_curve().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot ROC/PR curves for feature selection. — plot_feature_selection_curve","text":"interactive = TRUE, returns plotly object plot_by NULL list plotly objects plot_by NULL. interactive = FALSE, returns ggplot object plot_by NULL list ggplot objects plot_by NULL.","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot ROC/PR curves for feature selection. — plot_feature_selection_curve","text":"","code":"# generate example fit_results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),           # true feature support         true_support = c(TRUE, FALSE, TRUE),           # estimated feature support         est_support = c(TRUE, FALSE, FALSE),           # estimated feature importance scores         est_importance = c(10, runif(2, min = -2, max = 2))         )     }   ) )  # generate example eval_results data eval_results <- list(   ROC = summarize_feature_selection_curve(     fit_results,      curve = \"ROC\",     nested_data = \"feature_info\",     truth_col = \"true_support\",      imp_col = \"est_importance\"   ),   PR = summarize_feature_selection_curve(     fit_results,      curve = \"PR\",     nested_data = \"feature_info\",     truth_col = \"true_support\",      imp_col = \"est_importance\"   ) )  # create summary ROC/PR plots using pre-computed evaluation results roc_plt <- plot_feature_selection_curve(fit_results = fit_results,                                          eval_results = eval_results,                                         evaluator_name = \"ROC\", curve = \"ROC\",                                         show = c(\"line\", \"ribbon\")) pr_plt <- plot_feature_selection_curve(fit_results = fit_results,                                         eval_results = eval_results,                                        evaluator_name = \"PR\", curve = \"PR\",                                        show = c(\"line\", \"ribbon\")) # or alternatively, create the same plots without pre-computing evaluation results roc_plt <- plot_feature_selection_curve(fit_results, show = c(\"line\", \"ribbon\"),                                         nested_data = \"feature_info\",                                         truth_col = \"true_support\",                                         imp_col = \"est_importance\",                                         curve = \"ROC\") pr_plt <- plot_feature_selection_curve(fit_results, show = c(\"line\", \"ribbon\"),                                        nested_data = \"feature_info\",                                        truth_col = \"true_support\",                                        imp_col = \"est_importance\",                                        curve = \"PR\")  # can customize plot (see plot_eval_summary() for possible arguments) roc_plt <- plot_feature_selection_curve(fit_results = fit_results,                                          eval_results = eval_results,                                         evaluator_name = \"ROC\", curve = \"ROC\",                                         show = c(\"line\", \"ribbon\"),                                         plot_by = \".dgp_name\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_err.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot feature selection error according to various metrics. — plot_feature_selection_err","title":"Plot feature selection error according to various metrics. — plot_feature_selection_err","text":"Plot raw summarized feature selection errors boxplot, scatter plot, line plot, bar plot without 1 SD error bars.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_err.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot feature selection error according to various metrics. — plot_feature_selection_err","text":"","code":"plot_feature_selection_err(   fit_results,   eval_results = NULL,   evaluator_name = NULL,   vary_params = NULL,   metrics = NULL,   show = c(\"point\", \"line\", \"errorbar\"),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_err.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot feature selection error according to various metrics. — plot_feature_selection_err","text":"fit_results tibble, returned fit method. eval_results list result tibbles, returned evaluate method. evaluator_name Name Evaluator containing results plot. compute evaluation summary results scratch evaluation summary results yet evaluated, set NULL. vary_params vector parameter names varied across Experiment. metrics metric_set object indicating metrics plot. See yardstick::metric_set() details. Default NULL use default metrics yardstick::metrics(). show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. ... Additional arguments pass plot_eval_summary(). includes arguments plotting passing summarize_feature_selection_err().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_err.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot feature selection error according to various metrics. — plot_feature_selection_err","text":"interactive = TRUE, returns plotly object plot_by NULL list plotly objects plot_by NULL. interactive = FALSE, returns ggplot object plot_by NULL list ggplot objects plot_by NULL.","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_feature_selection_err.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot feature selection error according to various metrics. — plot_feature_selection_err","text":"","code":"# generate example fit_results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),           # true feature support         true_support = c(TRUE, FALSE, TRUE),           # estimated feature support         est_support = c(TRUE, FALSE, FALSE),           # estimated feature importance scores         est_importance = c(10, runif(2, min = -2, max = 2))         )     }   ) )  # generate example eval_results data eval_results <- list(   `Feature Selection Errors` = summarize_feature_selection_err(     fit_results,      nested_data = \"feature_info\",     truth_col = \"true_support\",      estimate_col = \"est_support\",     imp_col = \"est_importance\"   ) )  # create bar plot using pre-computed evaluation results plt <- plot_feature_selection_err(fit_results = fit_results,                                    eval_results = eval_results,                                   evaluator_name = \"Feature Selection Errors\",                                   show = c(\"bar\")) # or alternatively, create the same plot without pre-computing evaluation results plt <- plot_feature_selection_err(fit_results,                                   show = c(\"bar\"),                                   nested_data = \"feature_info\",                                   truth_col = \"true_support\",                                   estimate_col = \"est_support\",                                   imp_col = \"est_importance\")  # can customize plot (see plot_eval_summary() for possible arguments) plt <- plot_feature_selection_err(fit_results = fit_results,                                    eval_results = eval_results,                                   evaluator_name = \"Feature Selection Errors\",                                   show = c(\"bar\"),                                   color_str = \".dgp_name\",                                   interactive = TRUE)"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_fit_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Developer function for plotting results from particular replicate(s) in the\nExperiment fit. — plot_fit_results","title":"Developer function for plotting results from particular replicate(s) in the\nExperiment fit. — plot_fit_results","text":"helper function developing new Visualizer plotting functions plot results particular replicate(s) Experiment fit. function construct one plot row Experiment's fit_results specified replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_fit_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Developer function for plotting results from particular replicate(s) in the\nExperiment fit. — plot_fit_results","text":"","code":"plot_fit_results(   fit_results,   vary_params = NULL,   reps = 1,   plot_fun,   interactive = FALSE,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_fit_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Developer function for plotting results from particular replicate(s) in the\nExperiment fit. — plot_fit_results","text":"fit_results tibble, returned fit method. vary_params vector parameter names varied across Experiment. reps Vector replicates plot results. plot_fun plotting function, takes arguments fit_results, vary_params, possibly others passed .... interactive Logical. TRUE, returns interactive plotly plots. FALSE, returns static ggplot plots. ... Additional arguments pass plot_fun().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_fit_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Developer function for plotting results from particular replicate(s) in the\nExperiment fit. — plot_fit_results","text":"interactive = TRUE, returns plotly object list plotly objects multiple replicates, DGPs, Methods plot. interactive = FALSE, returns ggplot object list ggplot objects multiple replicates, DGPs, Methods plot.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_fit_results.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Developer function for plotting results from particular replicate(s) in the\nExperiment fit. — plot_fit_results","text":"","code":"# generate example fit results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4, FUN = function(x) rnorm(100)),   # predicted response   predictions = lapply(1:4, FUN = function(x) rnorm(100)) )  # function to plot scatter plot of y vs predictions plot_fun <- function(fit_results, vary_params = NULL) {   plt <- fit_results %>%     tidyr::unnest(c(\"y\", \"predictions\")) %>%     ggplot2::ggplot() +     ggplot2::aes(x = y, y = predictions) +     ggplot2::geom_point() +     ggplot2::labs(title = sprintf(\"DGP: %s | Method: %s | Rep: %s\",                                    fit_results$.dgp_name,                                   fit_results$.method_name,                                   fit_results$.rep))   return(plt) }  # returns the scatter plot for each (DGP, Method) combination from rep 1 plt <- plot_fit_results(fit_results, reps = 1, plot_fun = plot_fun)"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot ROC/PR curves. — plot_pred_curve","title":"Plot ROC/PR curves. — plot_pred_curve","text":"Plot ROC/PR curves summary thereof across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot ROC/PR curves. — plot_pred_curve","text":"","code":"plot_pred_curve(   fit_results,   eval_results = NULL,   evaluator_name = NULL,   vary_params = NULL,   curve = c(\"ROC\", \"PR\"),   show = c(\"line\", \"ribbon\"),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot ROC/PR curves. — plot_pred_curve","text":"fit_results tibble, returned fit method. eval_results list result tibbles, returned evaluate method. evaluator_name Name Evaluator containing results plot. compute evaluation summary results scratch evaluation summary results yet evaluated, set NULL. vary_params vector parameter names varied across Experiment. curve Either \"ROC\" \"PR\" indicating whether plot ROC Precision-Recall curve. show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. ... Additional arguments pass plot_eval_summary(). includes arguments plotting passing summarize_pred_curve().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot ROC/PR curves. — plot_pred_curve","text":"interactive = TRUE, returns plotly object plot_by NULL list plotly objects plot_by NULL. interactive = FALSE, returns ggplot object plot_by NULL list ggplot objects plot_by NULL.","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot ROC/PR curves. — plot_pred_curve","text":"","code":"# generate example fit_results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4,              FUN = function(x) {                as.factor(sample(0:1, size = 100, replace = TRUE))              }),   # predicted class probabilities    class_probs = lapply(1:4, FUN = function(x) runif(n = 100, min = 0, max = 1)) )  # generate example eval_results data eval_results <- list(   ROC = summarize_pred_curve(     fit_results, truth_col = \"y\", prob_cols = \"class_probs\", curve = \"ROC\"   ),   PR = summarize_pred_curve(     fit_results, truth_col = \"y\", prob_cols = \"class_probs\", curve = \"PR\"   ) )  # create summary ROC/PR plots using pre-computed evaluation results roc_plt <- plot_pred_curve(fit_results = fit_results, eval_results = eval_results,                            evaluator_name = \"ROC\", curve = \"ROC\",                            show = c(\"line\", \"ribbon\")) pr_plt <- plot_pred_curve(fit_results = fit_results, eval_results = eval_results,                           evaluator_name = \"PR\", curve = \"PR\",                           show = c(\"line\", \"ribbon\")) # or alternatively, create the same plots without pre-computing evaluation results roc_plt <- plot_pred_curve(fit_results, show = c(\"line\", \"ribbon\"),                            truth_col = \"y\", prob_cols = \"class_probs\",                             curve = \"ROC\") pr_plt <- plot_pred_curve(fit_results, show = c(\"line\", \"ribbon\"),                           truth_col = \"y\", prob_cols = \"class_probs\",                            curve = \"PR\")  # can customize plot (see plot_eval_summary() for possible arguments) roc_plt <- plot_pred_curve(fit_results = fit_results, eval_results = eval_results,                            evaluator_name = \"ROC\", curve = \"ROC\",                            show = c(\"line\", \"ribbon\"),                            plot_by = \".dgp_name\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_err.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot prediction error according to various metrics. — plot_pred_err","title":"Plot prediction error according to various metrics. — plot_pred_err","text":"Plot raw summarized prediction errors boxplot, scatter plot, line plot, bar plot without 1 SD error bars.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_err.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot prediction error according to various metrics. — plot_pred_err","text":"","code":"plot_pred_err(   fit_results,   eval_results = NULL,   evaluator_name = NULL,   vary_params = NULL,   metrics = NULL,   show = c(\"point\", \"line\"),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_err.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot prediction error according to various metrics. — plot_pred_err","text":"fit_results tibble, returned fit method. eval_results list result tibbles, returned evaluate method. evaluator_name Name Evaluator containing results plot. compute evaluation summary results scratch evaluation summary results yet evaluated, set NULL. vary_params vector parameter names varied across Experiment. metrics metric_set object indicating metrics plot. See yardstick::metric_set() details. Default NULL use default metrics yardstick::metrics(). show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. ... Additional arguments pass plot_eval_summary(). includes arguments plotting passing summarize_pred_err().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_err.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot prediction error according to various metrics. — plot_pred_err","text":"interactive = TRUE, returns plotly object plot_by NULL list plotly objects plot_by NULL. interactive = FALSE, returns ggplot object plot_by NULL list ggplot objects plot_by NULL.","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_pred_err.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot prediction error according to various metrics. — plot_pred_err","text":"","code":"# generate example fit_results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   # true response   y = lapply(1:4, FUN = function(x) rnorm(100)),   # predicted response   predictions = lapply(1:4, FUN = function(x) rnorm(100)) )  # generate example eval_results data eval_results <- list(   `Prediction Errors` = summarize_pred_err(     fit_results, truth_col = \"y\", estimate_col = \"predictions\"   ) )  # create errorbar plot using pre-computed evaluation results plt <- plot_pred_err(fit_results = fit_results, eval_results = eval_results,                      evaluator_name = \"Prediction Errors\",                      show = c(\"point\", \"errorbar\")) # or alternatively, create the same plot without pre-computing evaluation results plt <- plot_pred_err(fit_results, show = c(\"point\", \"errorbar\"),                      truth_col = \"y\", estimate_col = \"predictions\")  # can customize plot (see plot_eval_summary() for possible arguments) plt <- plot_pred_err(fit_results = fit_results, eval_results = eval_results,                      evaluator_name = \"Prediction Errors\",                      show = c(\"point\", \"errorbar\"),                       color_str = NULL,                      facet_formula = .method_name ~ .metric,                      facet_type = \"grid\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_reject_prob.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the rejection probability of a hypothesis test. — plot_reject_prob","title":"Plot the rejection probability of a hypothesis test. — plot_reject_prob","text":"Plot probability rejecting null hypothesis across various levels significance.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_reject_prob.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the rejection probability of a hypothesis test. — plot_reject_prob","text":"","code":"plot_reject_prob(   fit_results,   eval_results = NULL,   evaluator_name = NULL,   vary_params = NULL,   feature_col = NULL,   show_features = NULL,   show_identity_line = FALSE,   show = c(\"line\"),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_reject_prob.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the rejection probability of a hypothesis test. — plot_reject_prob","text":"fit_results tibble, returned fit method. eval_results list result tibbles, returned evaluate method. evaluator_name Name Evaluator containing results plot. compute evaluation summary results scratch evaluation summary results yet evaluated, set NULL. vary_params vector parameter names varied across Experiment. feature_col character string identifying column fit_results feature names IDs. show_features Vector feature names corresponding features display plot. NULL (default), shows features data. show_identity_line Logical indicating whether plot y = x line. show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. ... Additional arguments pass plot_eval_summary(). includes arguments plotting passing eval_reject_prob().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_reject_prob.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the rejection probability of a hypothesis test. — plot_reject_prob","text":"interactive = TRUE, returns plotly object plot_by NULL list plotly objects plot_by NULL. interactive = FALSE, returns ggplot object plot_by NULL list ggplot objects plot_by NULL.","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_reject_prob.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the rejection probability of a hypothesis test. — plot_reject_prob","text":"","code":"# generate example fit_results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),           # estimated p-values         pval = 10^(sample(-3:0, 3, replace = TRUE))       )     }   ) )  # generate example eval_results data eval_results <- list(   `Reject Prob.` = eval_reject_prob(     fit_results,      nested_data = \"feature_info\",     feature_col = \"feature\",      pval_col = \"pval\"   ) )  # create bar plot using pre-computed evaluation results plt <- plot_reject_prob(fit_results = fit_results,                         eval_results = eval_results,                         evaluator_name = \"Reject Prob.\",                         feature_col = \"feature\") # or alternatively, create the same plot without pre-computing evaluation results plt <- plot_reject_prob(fit_results,                          nested_data = \"feature_info\",                         feature_col = \"feature\",                         pval_col = \"pval\")  # can customize plot (see plot_eval_summary() for possible arguments) plt <- plot_reject_prob(fit_results = fit_results,                         eval_results = eval_results,                         evaluator_name = \"Reject Prob.\",                         facet_formula = NULL,                         plot_by = \"feature\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot ROC/PR curves for feature rankings, ranked by p-values. — plot_testing_curve","title":"Plot ROC/PR curves for feature rankings, ranked by p-values. — plot_testing_curve","text":"Plot ROC/PR curves feature rankings, ranked p-values summary thereof across experimental replicates.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot ROC/PR curves for feature rankings, ranked by p-values. — plot_testing_curve","text":"","code":"plot_testing_curve(   fit_results,   eval_results = NULL,   evaluator_name = NULL,   vary_params = NULL,   curve = c(\"ROC\", \"PR\"),   show = c(\"line\", \"ribbon\"),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot ROC/PR curves for feature rankings, ranked by p-values. — plot_testing_curve","text":"fit_results tibble, returned fit method. eval_results list result tibbles, returned evaluate method. evaluator_name Name Evaluator containing results plot. compute evaluation summary results scratch evaluation summary results yet evaluated, set NULL. vary_params vector parameter names varied across Experiment. curve Either \"ROC\" \"PR\" indicating whether plot ROC Precision-Recall curve. show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. ... Additional arguments pass plot_eval_summary(). includes arguments plotting passing summarize_testing_curve().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot ROC/PR curves for feature rankings, ranked by p-values. — plot_testing_curve","text":"interactive = TRUE, returns plotly object plot_by NULL list plotly objects plot_by NULL. interactive = FALSE, returns ggplot object plot_by NULL list ggplot objects plot_by NULL.","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_curve.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot ROC/PR curves for feature rankings, ranked by p-values. — plot_testing_curve","text":"","code":"# generate example fit_results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),           # true feature support         true_support = c(TRUE, FALSE, TRUE),           # estimated p-values         pval = 10^(sample(-3:0, 3, replace = TRUE))       )     }   ) )  # generate example eval_results data eval_results <- list(   `ROC` = summarize_testing_curve(     fit_results,      curve = \"ROC\",     nested_data = \"feature_info\",     truth_col = \"true_support\",      pval_col = \"pval\"   ),   `PR` = summarize_testing_curve(     fit_results,      curve = \"PR\",     nested_data = \"feature_info\",     truth_col = \"true_support\",      pval_col = \"pval\"   ) )   # create summary ROC/PR plots using pre-computed evaluation results roc_plt <- plot_testing_curve(fit_results = fit_results,                               eval_results = eval_results,                               evaluator_name = \"ROC\", curve = \"ROC\",                               show = c(\"line\", \"ribbon\")) pr_plt <- plot_testing_curve(fit_results = fit_results,                              eval_results = eval_results,                              evaluator_name = \"PR\", curve = \"PR\",                              show = c(\"line\", \"ribbon\")) # or alternatively, create the same plots without pre-computing evaluation results roc_plt <- plot_testing_curve(fit_results, show = c(\"line\", \"ribbon\"),                               nested_data = \"feature_info\",                               truth_col = \"true_support\",                               pval_col = \"pval\",                               curve = \"ROC\") pr_plt <- plot_testing_curve(fit_results, show = c(\"line\", \"ribbon\"),                              nested_data = \"feature_info\",                              truth_col = \"true_support\",                              pval_col = \"pval\",                              curve = \"PR\")  # can customize plot (see plot_eval_summary() for possible arguments) roc_plt <- plot_testing_curve(fit_results = fit_results,                               eval_results = eval_results,                               evaluator_name = \"ROC\", curve = \"ROC\",                               show = c(\"line\", \"ribbon\"),                               plot_by = \".dgp_name\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_err.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot testing error evaluation results according to various metrics. — plot_testing_err","title":"Plot testing error evaluation results according to various metrics. — plot_testing_err","text":"Plot raw summarized testing errors boxplot, scatter plot, line plot, bar plot without 1 SD error bars.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_err.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot testing error evaluation results according to various metrics. — plot_testing_err","text":"","code":"plot_testing_err(   fit_results,   eval_results = NULL,   evaluator_name = NULL,   vary_params = NULL,   metrics = NULL,   show = c(\"point\", \"line\", \"errorbar\"),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_err.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot testing error evaluation results according to various metrics. — plot_testing_err","text":"fit_results tibble, returned fit method. eval_results list result tibbles, returned evaluate method. evaluator_name Name Evaluator containing results plot. compute evaluation summary results scratch evaluation summary results yet evaluated, set NULL. vary_params vector parameter names varied across Experiment. metrics metric_set object indicating metrics plot. See yardstick::metric_set() details. Default NULL use default metrics yardstick::metrics(). show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct. ... Additional arguments pass plot_eval_summary(). includes arguments plotting passing summarize_testing_err().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_err.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot testing error evaluation results according to various metrics. — plot_testing_err","text":"interactive = TRUE, returns plotly object plot_by NULL list plotly objects plot_by NULL. interactive = FALSE, returns ggplot object plot_by NULL list ggplot objects plot_by NULL.","code":""},{"path":[]},{"path":"https://yu-group.github.io/simChef/dev/reference/plot_testing_err.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot testing error evaluation results according to various metrics. — plot_testing_err","text":"","code":"# generate example fit_results data fit_results <- tibble::tibble(   .rep = rep(1:2, times = 2),   .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),   .method_name = c(\"Method\"),   feature_info = lapply(     1:4,     FUN = function(i) {       tibble::tibble(         # feature names         feature = c(\"featureA\", \"featureB\", \"featureC\"),           # true feature support         true_support = c(TRUE, FALSE, TRUE),           # estimated p-values         pval = 10^(sample(-3:0, 3, replace = TRUE))       )     }   ) )  # generate example eval_results data eval_results <- list(   `Testing Errors` = summarize_testing_err(     fit_results,      nested_data = \"feature_info\",     truth_col = \"true_support\",      pval_col = \"pval\"   ) )  # create bar plot using pre-computed evaluation results plt <- plot_testing_err(fit_results = fit_results,                         eval_results = eval_results,                         evaluator_name = \"Testing Errors\",                         show = c(\"bar\", \"errorbar\")) # or alternatively, create the same plot without pre-computing evaluation results plt <- plot_testing_err(fit_results,                          show = c(\"bar\", \"errorbar\"),                         nested_data = \"feature_info\",                         truth_col = \"true_support\",                         pval_col = \"pval\")  # can customize plot (see plot_eval_summary() for possible arguments) plt <- plot_testing_err(fit_results = fit_results,                         eval_results = eval_results,                         evaluator_name = \"Testing Errors\",                         show = c(\"bar\", \"errorbar\"),                         plot_by = \".alpha\")"},{"path":"https://yu-group.github.io/simChef/dev/reference/pos.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of estimated positive cases — pos","title":"Number of estimated positive cases — pos","text":"functions calculate pos() (number estimated positive cases) measurement system compared reference results (\"truth\").","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of estimated positive cases — pos","text":"","code":"pos(data, ...)  # S3 method for data.frame pos(   data,   truth,   estimate,   estimator = NULL,   na_rm = FALSE,   event_level = \"first\",   ... )  pos_vec(   truth,   estimate,   estimator = NULL,   na_rm = FALSE,   event_level = \"first\",   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/pos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of estimated positive cases — pos","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper generally defaults \"first\", however, deprecated global option yardstick.event_first set, used instead warning.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/pos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of estimated positive cases — pos","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. pos_vec(), single numeric value (NA).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/remove_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper functions for removing components of an Experiment. — remove_funs","title":"Helper functions for removing components of an Experiment. — remove_funs","text":"Helper functions removing DGPs, Methods, Evaluators, Visualizers already added Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/remove_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper functions for removing components of an Experiment. — remove_funs","text":"","code":"remove_dgp(experiment, name = NULL, ...)  remove_method(experiment, name = NULL, ...)  remove_evaluator(experiment, name = NULL, ...)  remove_visualizer(experiment, name = NULL, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/remove_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper functions for removing components of an Experiment. — remove_funs","text":"experiment Experiment object. name name identify object removed. NULL (default), remove objects class experiment. example, remove_dgp() remove DGPs experiment. ... used.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/remove_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper functions for removing components of an Experiment. — remove_funs","text":"original Experiment object passed remove_*.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/render_docs.html","id":null,"dir":"Reference","previous_headings":"","what":"Render an R Markdown file summarizing the results of an Experiment or\nset of Experiments. — render_docs","title":"Render an R Markdown file summarizing the results of an Experiment or\nset of Experiments. — render_docs","text":"Knits R Markdown file summarizing results Experiment set Experiments. Outputs R Markdown-generated html file. experiment provided, results saved Experiment's root results directory (see Experiment$get_save_dir()). Otherwise, root results directory taken specified save_dir. Note render_docs() process include results Experiments found root directory.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/render_docs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Render an R Markdown file summarizing the results of an Experiment or\nset of Experiments. — render_docs","text":"","code":"render_docs(   experiment,   save_dir,   open = TRUE,   title = NULL,   author = \"\",   verbose = 2,   quiet = TRUE,   pretty = TRUE,   eval_order = NULL,   viz_order = NULL,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/render_docs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Render an R Markdown file summarizing the results of an Experiment or\nset of Experiments. — render_docs","text":"experiment Experiment object. provided, documentation created previously saved Experiments found directory given experiment$get_save_dir(). Experiments previously saved directory, current experiment saved disk used create documentation template. save_dir optional directory find previously saved Experiment objects. Documentation created found Experiments. used experiment provided. open TRUE, open R Markdown-generated html file web browser. title Character string. Title report. default, name experiment experiment provided. author Character string author names display knitted R Markdown document. verbose Level verboseness (0, 1, 2) knitting R Markdown. Default 2. quiet Default TRUE. See rmarkdown::render() details. pretty Logical. Specifies whether use pretty R Markdown results template barebones R Markdown results template. Default TRUE uses pretty template. Set FALSE start barebones template, can helpful using custom R Markdown theme. eval_order Vector Evaluator names desired order display. default, report display Evaluator results order computed. viz_order Vector Visualizer names desired order display. default, report display Visualizer results order computed. ... Additional arguments pass rmarkdown::render(). Useful applying custom R Markdown output theme.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/render_docs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Render an R Markdown file summarizing the results of an Experiment or\nset of Experiments. — render_docs","text":"original Experiment object provided. Otherwise, returns NULL.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/render_docs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Render an R Markdown file summarizing the results of an Experiment or\nset of Experiments. — render_docs","text":"","code":"if (FALSE) { # create basic Rmd from an experiment (of class `Experiment`) render_docs(experiment)  # or alternatively, create basic Rmd from a specific directory render_docs(save_dir = experiment$get_save_dir())}"},{"path":"https://yu-group.github.io/simChef/dev/reference/rescale_curve.html","id":null,"dir":"Reference","previous_headings":"","what":"Rescale ROC/PR curves onto the same x-axis grid — rescale_curve","title":"Rescale ROC/PR curves onto the same x-axis grid — rescale_curve","text":"helper function map ROC/PR curve unique coordinates given data.frame onto new set x-axis values (.e., FPR ROC curve recall PR curve).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/rescale_curve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rescale ROC/PR curves onto the same x-axis grid — rescale_curve","text":"","code":"rescale_curve(curve_data, x_grid, xvar, yvar)"},{"path":"https://yu-group.github.io/simChef/dev/reference/rescale_curve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rescale ROC/PR curves onto the same x-axis grid — rescale_curve","text":"curve_data data.frame containing x- y-coordinates define ROC/PR curve. x_grid Vector x-coordinates evaluate ROC/PR curve xvar Name column curve_data FPR values ROC curve recall values PR curve. yvar Name column curve_data TPR values ROC curve precision values PR curve.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/rescale_curve.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rescale ROC/PR curves onto the same x-axis grid — rescale_curve","text":"data.frame coordinates ROC/PR curve using new x-axis scale. data.frame two columns names given specified xvar yvar.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/run_experiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Run the full Experiment pipeline (fitting, evaluating, and visualizing). — run_experiment","title":"Run the full Experiment pipeline (fitting, evaluating, and visualizing). — run_experiment","text":"Run full Experiment pipeline (fitting, evaluating, visualizing).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/run_experiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run the full Experiment pipeline (fitting, evaluating, and visualizing). — run_experiment","text":"","code":"run_experiment(   experiment,   n_reps = 1,   parallel_strategy = c(\"reps\"),   future.globals = NULL,   future.packages = NULL,   future.seed = TRUE,   use_cached = FALSE,   return_all_cached_reps = FALSE,   save = FALSE,   checkpoint_n_reps = 0,   verbose = 1,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/run_experiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run the full Experiment pipeline (fitting, evaluating, and visualizing). — run_experiment","text":"experiment Experiment object. n_reps number replicates Experiment run. parallel_strategy vector combination \"reps\", \"dgps\", \"methods\". Determines computation distributed across available resources. Default \"reps\". future.globals Character vector names global environment pass parallel workers. Passed argument name future.apply::future_lapply related functions. set runs experiment, use argument initialization. future.packages Character vector packages required parallel workers. Passed argument name future.apply::future_lapply related functions. set runs experiment, use argument initialization. future.seed Passed argument name future.apply::future_apply. use_cached Logical. TRUE, find return previously saved results. cached results found, continue use_cached FALSE. return_all_cached_reps Logical. FALSE (default), returns fit results requested n_reps. TRUE, returns fit results requested n_reps plus additional cached replicates (DGP, Method) combinations Experiment. Note even return_all_cached_reps = TRUE, n_reps replicates used evaluating visualizing Experiment. save TRUE, save outputs disk. checkpoint_n_reps number experiment replicates compute saving results disk. 0 (default), checkpoints saved. verbose Level verbosity. Default 1, prints messages major checkpoints experiment. 2, prints additional debugging information warnings messages user-defined functions (addition error debugging information). 0, messages printed user-defined function error debugging information. ... used.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/run_experiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run the full Experiment pipeline (fitting, evaluating, and visualizing). — run_experiment","text":"list results simulation experiment. fit_results tibble containing results fit method. addition results columns, columns named '.rep', '.dgp_name', '.method_name', vary_across parameter names applicable. eval_results list tibbles containing results evaluate method, evaluates Evaluator Experiment. Length list equivalent number Evaluators. viz_results list tibbles containing results visualize method, visualizes Visualizer Experiment. Length list equivalent number Visualizers.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/save_experiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Save an Experiment. — save_experiment","title":"Save an Experiment. — save_experiment","text":"Save Experiment object .rds file Experiment's results directory (see Experiment$get_save_dir()).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/save_experiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save an Experiment. — save_experiment","text":"","code":"save_experiment(experiment)"},{"path":"https://yu-group.github.io/simChef/dev/reference/save_experiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save an Experiment. — save_experiment","text":"experiment Experiment object.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/save_experiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save an Experiment. — save_experiment","text":"original Experiment object passed save_experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/set_doc_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set R Markdown options for Evaluator and Visualizer outputs in\nsummary report. — set_doc_options","title":"Set R Markdown options for Evaluator and Visualizer outputs in\nsummary report. — set_doc_options","text":"Set R Markdown options Evaluator Visualizer outputs summary report. options include height/width plots number digits show tables.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/set_doc_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set R Markdown options for Evaluator and Visualizer outputs in\nsummary report. — set_doc_options","text":"","code":"set_doc_options(   experiment,   field_name = c(\"evaluator\", \"visualizer\"),   name,   show = NULL,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/set_doc_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set R Markdown options for Evaluator and Visualizer outputs in\nsummary report. — set_doc_options","text":"experiment Experiment object. field_name One \"evaluator\" \"visualizer\". name Name Evaluator Visualizer set R Markdown options. show TRUE, show output; FALSE, hide output R Markdown report. Default NULL change \"show\" field Evaluator/Visualizer. ... Named R Markdown options set. field_name = \"visualizer\", options \"height\" \"width\". field_name = \"evaluator\", see options vthemes::pretty_DT().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/set_doc_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set R Markdown options for Evaluator and Visualizer outputs in\nsummary report. — set_doc_options","text":"original Experiment object doc_options /show fields modified Evaluator/Visualizer.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/set_rmd_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set R Markdown options for Evaluator and Visualizer outputs in\nsummary report. — set_rmd_options","title":"Set R Markdown options for Evaluator and Visualizer outputs in\nsummary report. — set_rmd_options","text":"set_rmd_options() renamed set_doc_options() create consistent API.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/set_rmd_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set R Markdown options for Evaluator and Visualizer outputs in\nsummary report. — set_rmd_options","text":"","code":"set_rmd_options(   experiment,   field_name = c(\"evaluator\", \"visualizer\"),   name,   show = NULL,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/set_save_dir.html","id":null,"dir":"Reference","previous_headings":"","what":"Set results directory for an Experiment. — set_save_dir","title":"Set results directory for an Experiment. — set_save_dir","text":"Set directory Experiment's results visualizations saved.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/set_save_dir.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set results directory for an Experiment. — set_save_dir","text":"","code":"set_save_dir(experiment, save_dir)"},{"path":"https://yu-group.github.io/simChef/dev/reference/set_save_dir.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set results directory for an Experiment. — set_save_dir","text":"experiment Experiment object. save_dir directory Experiment's results saved.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/set_save_dir.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set results directory for an Experiment. — set_save_dir","text":"original Experiment object updated saving directory.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/shared_error_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Arguments that are shared by multiple signal functions. — shared_error_args","title":"Arguments that are shared by multiple signal functions. — shared_error_args","text":"Arguments shared multiple signal functions.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/shared_error_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arguments that are shared by multiple signal functions. — shared_error_args","text":"message Message include condition. class Subclass passed appropriate rlang signal function. call function environment relevant user's perspective. Default rlang::caller_env(), gives environment attached function called signal function. ... Additional arguments pass appropriate rlang signal function.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/shared_eval_lib_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Arguments that are shared by multiple Evaluator library functions. — shared_eval_lib_args","title":"Arguments that are shared by multiple Evaluator library functions. — shared_eval_lib_args","text":"Arguments shared multiple Evaluator library functions.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/shared_eval_lib_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arguments that are shared by multiple Evaluator library functions. — shared_eval_lib_args","text":"custom_summary_funs Named list custom functions summarize results. Names list correspond name summary function. Values list function takes one argument, values evaluated metrics. curve Either \"ROC\" \"PR\" indicating whether evaluate ROC Precision-Recall curve. eval_id Character string. ID used suffix naming result columns. Default NULL add ID column names. feature_col character string identifying column fit_results feature names IDs. na_rm logical value indicating whether NA values stripped computation proceeds. nested_data (Optional) Character string. specified, name column fit_results containing columns must unnested evaluating results. Default NULL, meaning columns fit_results need unnested prior computation. options list named options pass pROC::roc() smooth. options include response, predictor, levels, quiet, direction. argument used computing ROC ignored otherwise. summary_funs Character vector specifying summarize evaluation metrics. Must choose built-library summary functions - elements vector must one \"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\". x_grid Vector values 0 1 evaluate ROC PR curve. curve = \"ROC\", provided vector values FPR values evaluate TPR, curve = \"PR\", values recall values evaluate precision.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/shared_experiment_helpers_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Arguments that are shared by multiple Experiment helper funs. — shared_experiment_helpers_args","title":"Arguments that are shared by multiple Experiment helper funs. — shared_experiment_helpers_args","text":"Arguments shared multiple Experiment helper funs.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/shared_experiment_helpers_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arguments that are shared by multiple Experiment helper funs. — shared_experiment_helpers_args","text":"checkpoint_n_reps number experiment replicates compute saving results disk. 0 (default), checkpoints saved. dgp DGP object. evaluator Evaluator object. eval_results list result tibbles, returned evaluate method. experiment Experiment object. fit_results tibble, returned fit method. future.globals Character vector names global environment pass parallel workers. Passed argument name future.apply::future_lapply related functions. set runs experiment, use argument initialization. future.packages Character vector packages required parallel workers. Passed argument name future.apply::future_lapply related functions. set runs experiment, use argument initialization. future.seed Passed argument name future.apply::future_apply. method Method object. n_reps number replicates Experiment run. parallel_strategy vector combination \"reps\", \"dgps\", \"methods\". Determines computation distributed across available resources. Default \"reps\". save TRUE, save outputs disk. use_cached Logical. TRUE, find return previously saved results. cached results found, continue use_cached FALSE. vary_params vector parameter names varied across Experiment. verbose Level verbosity. Default 1, prints messages major checkpoints experiment. 2, prints additional debugging information warnings messages user-defined functions (addition error debugging information). 0, messages printed user-defined function error debugging information. visualizer Visualizer object. ... used.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/shared_viz_lib_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Arguments that are shared by multiple Visualizer library functions. — shared_viz_lib_args","title":"Arguments that are shared by multiple Visualizer library functions. — shared_viz_lib_args","text":"Arguments shared multiple Visualizer library functions.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/shared_viz_lib_args.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Arguments that are shared by multiple Visualizer library functions. — shared_viz_lib_args","text":"evaluator_name Name Evaluator containing results plot. compute evaluation summary results scratch evaluation summary results yet evaluated, set NULL. interactive Logical. TRUE, returns interactive plotly plots. FALSE, returns static ggplot plots. curve Either \"ROC\" \"PR\" indicating whether plot ROC Precision-Recall curve. show Character vector elements one \"boxplot\", \"point\", \"line\", \"bar\", \"errorbar\", \"ribbon\" indicating plot layer(s) construct.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/simplify_tibble.html","id":null,"dir":"Reference","previous_headings":"","what":"Simplify tibble. — simplify_tibble","title":"Simplify tibble. — simplify_tibble","text":"Simplify unlist list columns tibble element list scalar value.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/simplify_tibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simplify tibble. — simplify_tibble","text":"","code":"simplify_tibble(tbl, empty_as_na = TRUE)"},{"path":"https://yu-group.github.io/simChef/dev/reference/simplify_tibble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simplify tibble. — simplify_tibble","text":"empty_as_na TRUE (default), 0-length values treated NA. tib tibble::tibble simplify.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/simplify_tibble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simplify tibble. — simplify_tibble","text":"tibble \"simplified\".","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/summarize_eval_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Developer function for summarizing evaluation results. — summarize_eval_results","title":"Developer function for summarizing evaluation results. — summarize_eval_results","text":"helper function developing new Evaluator functions summarize results pre-specified groups grouped data.frame (e.g., multiple experimental replicates).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/summarize_eval_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Developer function for summarizing evaluation results. — summarize_eval_results","text":"","code":"summarize_eval_results(   eval_data,   eval_id = NULL,   value_col,   summary_funs = c(\"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\"),   custom_summary_funs = NULL,   na_rm = FALSE )"},{"path":"https://yu-group.github.io/simChef/dev/reference/summarize_eval_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Developer function for summarizing evaluation results. — summarize_eval_results","text":"eval_data grouped data.frame evaluation results summarize. eval_id Character string. ID used suffix naming result columns. Default NULL add ID column names. value_col Character string. Name column eval_data values summarize. summary_funs Character vector specifying summarize evaluation metrics. Must choose built-library summary functions - elements vector must one \"mean\", \"median\", \"min\", \"max\", \"sd\", \"raw\". custom_summary_funs Named list custom functions summarize results. Names list correspond name summary function. Values list function takes one argument, values evaluated metrics. na_rm logical value indicating whether NA values stripped computation proceeds.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/summarize_eval_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Developer function for summarizing evaluation results. — summarize_eval_results","text":"tibble containing summarized results aggregated given groups. columns correspond requested statistics summary_funs custom_summary_funs end suffix specified eval_id. Note group IDs also retained returned tibble.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/summarize_eval_results.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Developer function for summarizing evaluation results. — summarize_eval_results","text":"","code":"# create example eval_data to summarize eval_data <- tibble::tibble(.rep = rep(1:2, times = 2),                              .dgp_name = c(\"DGP1\", \"DGP1\", \"DGP2\", \"DGP2\"),                             .method_name = \"Method\",                             result = 1:4) %>%   dplyr::group_by(.dgp_name, .method_name)    # summarize `result` column in eval_data results <- summarize_eval_results(eval_data = eval_data, eval_id = \"res\",                                   value_col = \"result\")                                    # only compute mean and sd of `result` column in eval_data over given groups results <- summarize_eval_results(eval_data = eval_data, eval_id = \"res\",                                   value_col = \"result\",                                   summary_funs = c(\"mean\", \"sd\"))                                    # summarize `results` column using custom summary function range_fun <- function(x) return(max(x) - min(x)) results <- summarize_eval_results(eval_data = eval_data, value_col = \"result\",                                   custom_summary_funs = list(range = range_fun))"},{"path":"https://yu-group.github.io/simChef/dev/reference/tp.html","id":null,"dir":"Reference","previous_headings":"","what":"Number of true positives — tp","title":"Number of true positives — tp","text":"functions calculate tp() (number true positives) measurement system compared reference results (\"truth\").","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/tp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Number of true positives — tp","text":"","code":"tp(data, ...)  # S3 method for data.frame tp(   data,   truth,   estimate,   estimator = NULL,   na_rm = FALSE,   event_level = \"first\",   ... )  tp_vec(   truth,   estimate,   estimator = NULL,   na_rm = FALSE,   event_level = \"first\",   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/tp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Number of true positives — tp","text":"data Either data.frame containing columns specified truth estimate arguments, table/matrix true class results columns table. ... currently used. truth column identifier true class results (factor). unquoted column name although argument passed expression supports quasiquotation (can unquote column names). _vec() functions, factor vector. estimate column identifier predicted class results (also factor). truth can specified different ways primary method use unquoted variable name. _vec() functions, factor vector. estimator One : \"binary\", \"macro\", \"macro_weighted\", \"micro\" specify type averaging done. \"binary\" relevant two class case. three general methods calculating multiclass metrics. default automatically choose \"binary\" \"macro\" based estimate. na_rm logical value indicating whether NA values stripped computation proceeds. event_level single string. Either \"first\" \"second\" specify level truth consider \"event\". argument applicable estimator = \"binary\". default uses internal helper generally defaults \"first\", however, deprecated global option yardstick.event_first set, used instead warning.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/tp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Number of true positives — tp","text":"tibble columns .metric, .estimator, .estimate 1 row values. grouped data frames, number rows returned number groups. tp_vec(), single numeric value (NA).","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/update_funs.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper functions for updating components of an Experiment. — update_funs","title":"Helper functions for updating components of an Experiment. — update_funs","text":"Helper functions updating DGPs, Methods, Evaluators, Visualizers already added Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/update_funs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper functions for updating components of an Experiment. — update_funs","text":"","code":"update_dgp(experiment, dgp, name, ...)  update_method(experiment, method, name, ...)  update_evaluator(experiment, evaluator, name, ...)  update_visualizer(experiment, visualizer, name, ...)"},{"path":"https://yu-group.github.io/simChef/dev/reference/update_funs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper functions for updating components of an Experiment. — update_funs","text":"experiment Experiment object. dgp DGP object. name name identify object updated. ... used. method Method object. evaluator Evaluator object. visualizer Visualizer object.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/update_funs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper functions for updating components of an Experiment. — update_funs","text":"original Experiment object passed update_*.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_dgp_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create boilerplate code for creating DGPs. — use_dgp_template","title":"Function to create boilerplate code for creating DGPs. — use_dgp_template","text":"Function create boilerplate code creating DGPs.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_dgp_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create boilerplate code for creating DGPs. — use_dgp_template","text":"","code":"use_dgp_template(ids = NULL)"},{"path":"https://yu-group.github.io/simChef/dev/reference/use_evaluator_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create boilerplate code for creating Evaluators. — use_evaluator_template","title":"Function to create boilerplate code for creating Evaluators. — use_evaluator_template","text":"Function create boilerplate code creating Evaluators.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_evaluator_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create boilerplate code for creating Evaluators. — use_evaluator_template","text":"","code":"use_evaluator_template(   ids = NULL,   pred_nested_data,   pred_truth_col,   pred_estimate_col,   pred_prob_cols,   feature_nested_data,   feature_col,   feature_truth_col,   feature_imp_col,   feature_sel_col,   feature_pval_col )"},{"path":"https://yu-group.github.io/simChef/dev/reference/use_experiment_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create boilerplate code for creating Experiments. — use_experiment_template","title":"Function to create boilerplate code for creating Experiments. — use_experiment_template","text":"Function create boilerplate code creating Experiments.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_experiment_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create boilerplate code for creating Experiments. — use_experiment_template","text":"","code":"use_experiment_template(   name = \"Experiment\",   dgp_names = NULL,   method_names = NULL,   eval_names = NULL,   viz_names = NULL )"},{"path":"https://yu-group.github.io/simChef/dev/reference/use_init_docs_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create boilerplate code for creating the documentation template. — use_init_docs_template","title":"Function to create boilerplate code for creating the documentation template. — use_init_docs_template","text":"Function create boilerplate code creating documentation template.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_init_docs_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create boilerplate code for creating the documentation template. — use_init_docs_template","text":"","code":"use_init_docs_template()"},{"path":"https://yu-group.github.io/simChef/dev/reference/use_method_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create boilerplate code for creating Methods. — use_method_template","title":"Function to create boilerplate code for creating Methods. — use_method_template","text":"Function create boilerplate code creating Methods.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_method_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create boilerplate code for creating Methods. — use_method_template","text":"","code":"use_method_template(ids = NULL)"},{"path":"https://yu-group.github.io/simChef/dev/reference/use_render_docs_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create boilerplate code for creating the Rmd report. — use_render_docs_template","title":"Function to create boilerplate code for creating the Rmd report. — use_render_docs_template","text":"Function create boilerplate code creating Rmd report.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_render_docs_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create boilerplate code for creating the Rmd report. — use_render_docs_template","text":"","code":"use_render_docs_template()"},{"path":"https://yu-group.github.io/simChef/dev/reference/use_run_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create boilerplate code for running an Experiment. — use_run_template","title":"Function to create boilerplate code for running an Experiment. — use_run_template","text":"Function create boilerplate code running Experiment.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_run_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create boilerplate code for running an Experiment. — use_run_template","text":"","code":"use_run_template()"},{"path":"https://yu-group.github.io/simChef/dev/reference/use_variable_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create boilerplate code for assigning descriptive errors to\nvariables. — use_variable_template","title":"Function to create boilerplate code for assigning descriptive errors to\nvariables. — use_variable_template","text":"Function create boilerplate code assigning descriptive errors variables.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_variable_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create boilerplate code for assigning descriptive errors to\nvariables. — use_variable_template","text":"","code":"use_variable_template(id)"},{"path":"https://yu-group.github.io/simChef/dev/reference/use_visualizer_template.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create boilerplate code for creating Visualizers — use_visualizer_template","title":"Function to create boilerplate code for creating Visualizers — use_visualizer_template","text":"Function create boilerplate code creating Visualizers","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/use_visualizer_template.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create boilerplate code for creating Visualizers — use_visualizer_template","text":"","code":"use_visualizer_template(   ids = NULL,   pred_nested_data,   pred_truth_col,   pred_prob_cols,   feature_nested_data,   feature_col,   feature_truth_col,   feature_imp_col,   feature_pval_col )"},{"path":"https://yu-group.github.io/simChef/dev/reference/vary_across.html","id":null,"dir":"Reference","previous_headings":"","what":"Varying across parameters in an Experiment. — vary_across","title":"Varying across parameters in an Experiment. — vary_across","text":"Helper functions adding, updating, removing, getting vary_across component Experiment. vary_across component added Experiment run, Experiment systematically varied across values specified parameter DGP Method parameters held constant baseline value.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/vary_across.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Varying across parameters in an Experiment. — vary_across","text":"","code":"add_vary_across(.experiment, .dgp, .method, ...)  update_vary_across(.experiment, .dgp, .method, ...)  remove_vary_across(experiment, dgp, method, param_names = NULL)  get_vary_across(experiment)"},{"path":"https://yu-group.github.io/simChef/dev/reference/vary_across.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Varying across parameters in an Experiment. — vary_across","text":".experiment, experiment Experiment object. .dgp, dgp Name DGP vary Experiment. Can also DGP object matches one Experiment even vector/list DGP names/objects, assuming can take specified param_names. .method, method Name Method vary Experiment. Can also Method object matches one Experiment even vector/listo f Method names/objects, assuming can take specified param_names. ... number named arguments names match argument user-specified DGP Method function values vectors (scalar parameters) lists (arbitrary parameters). param_names character vector parameter names remove. provided, entire set vary_across parameters removed specified DGP/Method.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/vary_across.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Varying across parameters in an Experiment. — vary_across","text":"case get_vary_across, nested list entries \"dgp\" \"method\" contains parameters vary across DGP Method Experiment. Otherwise, original Experiment object passed *_vary_across().","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/vary_across.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Varying across parameters in an Experiment. — vary_across","text":"One .dgp .method arguments () must provided using add_vary_across() update_vary_across. remove_vary_across(), dgp method arguments provided, vary_across parameters experiment removed.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/visualize_experiment.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize results of an Experiment. — visualize_experiment","title":"Visualize results of an Experiment. — visualize_experiment","text":"Visualize performance methods /evaluation metrics using Visualizers Experiment return visualization results.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/visualize_experiment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize results of an Experiment. — visualize_experiment","text":"","code":"visualize_experiment(   experiment,   fit_results,   eval_results = NULL,   use_cached = FALSE,   save = FALSE,   verbose = 1,   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/visualize_experiment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize results of an Experiment. — visualize_experiment","text":"experiment Experiment object. fit_results tibble, returned fit method. eval_results list result tibbles, returned evaluate method. use_cached Logical. TRUE, find return previously saved results. cached results found, continue use_cached FALSE. save TRUE, save outputs disk. verbose Level verbosity. Default 1, prints messages major checkpoints experiment. 2, prints additional debugging information warnings messages user-defined functions (addition error debugging information). 0, messages printed user-defined function error debugging information. ... used.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/visualize_experiment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize results of an Experiment. — visualize_experiment","text":"list visualizations, one Visualizer.","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/warn.html","id":null,"dir":"Reference","previous_headings":"","what":"Signals a warning with default subclass ","title":"Signals a warning with default subclass ","text":"Signals warning default subclass \"simChef_warning\".","code":""},{"path":"https://yu-group.github.io/simChef/dev/reference/warn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Signals a warning with default subclass ","text":"","code":"warn(   message = NULL,   class = \"simChef_warning\",   call = rlang::caller_env(),   ... )"},{"path":"https://yu-group.github.io/simChef/dev/reference/warn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Signals a warning with default subclass ","text":"message Message include condition. class Subclass passed appropriate rlang signal function. call function environment relevant user's perspective. Default rlang::caller_env(), gives environment attached function called signal function. ... Additional arguments pass appropriate rlang signal function.","code":""},{"path":[]}]
