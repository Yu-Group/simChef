% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/visualizer-lib-inference.R
\name{plot_testing_err}
\alias{plot_testing_err}
\title{Plot testing error evaluation results according to various metrics.}
\usage{
plot_testing_err(
  fit_results,
  eval_results = NULL,
  evaluator_name = NULL,
  vary_params = NULL,
  metrics = NULL,
  show = c("point", "line", "errorbar"),
  ...
)
}
\arguments{
\item{fit_results}{A tibble, as returned by the \code{fit} method.}

\item{eval_results}{A list of result tibbles, as returned by the
\code{evaluate} method.}

\item{evaluator_name}{Name of \code{Evaluator} containing results to plot.
To compute the evaluation summary results from scratch or if the evaluation
summary results have not yet been evaluated, set to \code{NULL}.}

\item{vary_params}{A vector of parameter names that are varied across in the
\code{Experiment}.}

\item{metrics}{A \code{metric_set} object indicating the metrics to plot.
See \code{\link[yardstick:metric_set]{yardstick::metric_set()}} for more details. Default \code{NULL} will
use the default metrics in \code{\link[yardstick:metrics]{yardstick::metrics()}}.}

\item{show}{Character vector with elements being one of "boxplot", "point",
"line", "bar", "errorbar", "ribbon" indicating what plot layer(s) to
construct.}

\item{...}{Additional arguments to pass to \code{plot_eval_summary()}. This
includes arguments for plotting and for passing into
\code{summarize_testing_err()}.}
}
\value{
If \code{interactive = TRUE}, returns a \code{plotly} object if
\code{plot_by} is \code{NULL} and a list of \code{plotly} objects if
\code{plot_by} is not \code{NULL}. If \code{interactive = FALSE}, returns
a \code{ggplot} object if \code{plot_by} is \code{NULL} and a list of
\code{ggplot} objects if \code{plot_by} is not \code{NULL}.
}
\description{
Plot the raw or summarized testing errors as a
boxplot, scatter plot, line plot, or bar plot with or without 1 SD error
bars.
}
\examples{
# generate example fit_results data
fit_results <- tibble::tibble(
  .rep = rep(1:2, times = 2),
  .dgp_name = c("DGP1", "DGP1", "DGP2", "DGP2"),
  .method_name = c("Method"),
  feature_info = lapply(
    1:4,
    FUN = function(i) {
      tibble::tibble(
        # feature names
        feature = c("featureA", "featureB", "featureC"),  
        # true feature support
        true_support = c(TRUE, FALSE, TRUE),  
        # estimated p-values
        pval = 10^(sample(-3:0, 3, replace = TRUE))
      )
    }
  )
)

# generate example eval_results data
eval_results <- list(
  `Testing Errors` = summarize_testing_err(
    fit_results, 
    nested_data = "feature_info",
    truth_col = "true_support", 
    pval_col = "pval"
  )
)

# create bar plot using pre-computed evaluation results
plt <- plot_testing_err(fit_results = fit_results,
                        eval_results = eval_results,
                        evaluator_name = "Testing Errors",
                        show = c("bar", "errorbar"))
# or alternatively, create the same plot without pre-computing evaluation results
plt <- plot_testing_err(fit_results, 
                        show = c("bar", "errorbar"),
                        nested_data = "feature_info",
                        truth_col = "true_support",
                        pval_col = "pval")

# can customize plot (see plot_eval_summary() for possible arguments)
plt <- plot_testing_err(fit_results = fit_results,
                        eval_results = eval_results,
                        evaluator_name = "Testing Errors",
                        show = c("bar", "errorbar"),
                        plot_by = ".alpha")

}
\seealso{
Other inference_funs: 
\code{\link{eval_reject_prob}()},
\code{\link{eval_testing_curve_funs}},
\code{\link{eval_testing_err_funs}},
\code{\link{plot_reject_prob}()},
\code{\link{plot_testing_curve}()}
}
\concept{inference_funs}
