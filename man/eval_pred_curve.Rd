% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluator-lib-prediction-metrics.R
\name{eval_pred_curve}
\alias{eval_pred_curve}
\title{Evaluate ROC or PR curves.}
\usage{
eval_pred_curve(
  data,
  truth,
  probs,
  metric = c("ROC", "PR"),
  groups = NULL,
  options = list(),
  na_rm = FALSE
)
}
\arguments{
\item{data}{A \code{data.frame} containing the \code{truth} and
\code{estimate} columns. Each row in this \code{data.frame} typically
corresponds to a sample or observation in the data.}

\item{truth}{A character string identifying the column with the true
responses. The column should be numeric for a regression problem and a
factor for a classification problem.}

\item{probs}{A character string or vector identifying the column(s) with the
columns containing class probabilities. If \code{truth} is binary, only
1 column name should be provided. Otherwise, the length of the character
vector should be equal to the number of factor levels of \code{truth}.
This argument is not used when evaluating numeric metrics.}

\item{metric}{Either "ROC" or "PR" indicating whether to evaluate the ROC or
Precision-Recall curve.}

\item{groups}{(Optional) vector of group IDs to group observations by before
evaluating prediction errors. This is useful for assessing within-group
prediction errors. Note: the (unstratified) prediction errors, aggregated
across the full data set, are computed in addition to these stratified
within-group errors.}

\item{options}{A \code{list} of named options to pass to \code{\link[pROC:roc]{pROC::roc()}}
such as \code{smooth}. These options should not include \code{response},
\code{predictor}, \code{levels}, \code{quiet}, or \code{direction}.}

\item{na_rm}{A \code{logical} value indicating whether \code{NA} values
should be stripped before the computation proceeds.}
}
\value{
If \code{metric = "ROC"}, returns a \code{tibble} with the columns
\code{.threshold}, \code{FPR}, and \code{TPR} for the threshold, false
positive rate, and true positive rate, respectively. If
\code{metric = "PR"}, returns a \code{tibble} with columns
\code{.threshold}, \code{recall}, and \code{precision}.
}
\description{
Evaluate the ROC or PR curves and return a tibble with the
results.
}
\seealso{
Other prediction_error_funs: 
\code{\link{eval_pred_err}()},
\code{\link{plot_pred_curve}()},
\code{\link{plot_pred_err}()},
\code{\link{summarize_pred_curve}()},
\code{\link{summarize_pred_err}()}
}
\concept{prediction_error_funs}
