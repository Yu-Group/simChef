% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluator-lib-feature-selection.R
\name{eval_feature_importance_funs}
\alias{eval_feature_importance_funs}
\alias{eval_feature_importance}
\alias{summarize_feature_importance}
\title{Evaluate and/or summarize feature importance scores.}
\usage{
eval_feature_importance(
  fit_results,
  vary_params = NULL,
  nested_data = NULL,
  feature_col,
  imp_col
)

summarize_feature_importance(
  fit_results,
  vary_params = NULL,
  nested_data = NULL,
  feature_col,
  imp_col,
  na_rm = FALSE,
  summary_funs = c("mean", "median", "min", "max", "sd", "raw"),
  custom_summary_funs = NULL,
  eval_id = "feature_importance"
)
}
\arguments{
\item{fit_results}{A tibble, as returned by the \code{fit} method.}

\item{vary_params}{A vector of parameter names that are varied across in the
\code{Experiment}.}

\item{nested_data}{(Optional) Character string. If specified, should be the
name of the column in \code{fit_results} containing columns that must be
unnested before evaluating results. Default is \code{NULL}, meaning no
columns in \code{fit_results} need to be unnested prior to computation.}

\item{feature_col}{A character string identifying the column in
\code{fit_results} with the feature names or IDs.}

\item{imp_col}{A character string identifying the column in
\code{fit_results} with the estimated feature importance data. Each element
in this column should be an array of length \code{p}, where \code{p} is the
number of features and the feature order aligns with that of
\code{truth_col}. Elements in this array should be numeric where a higher
magnitude indicates a more important feature.}

\item{na_rm}{A \code{logical} value indicating whether \code{NA} values
should be stripped before the computation proceeds.}

\item{summary_funs}{Character vector specifying how to summarize
evaluation metrics. Must choose from a built-in library of summary
functions - elements of the vector must be one of "mean", "median",
"min", "max", "sd", "raw".}

\item{custom_summary_funs}{Named list of custom functions to summarize
results. Names in the list should correspond to the name of the summary
function. Values in the list should be a function that takes in one
argument, that being the values of the evaluated metrics.}

\item{eval_id}{Character string. ID to be used as a suffix when naming result
columns. Default \code{NULL} does not add any ID to the column names.}
}
\value{
The output of \code{eval_feature_importance()} is a \code{tibble} with
the columns \code{.rep}, \code{.dgp_name}, and \code{.method_name} in
addition to the columns specified by \code{vary_params}, \code{feature_col},
and \code{imp_col}.

The output of \code{summarize_feature_importance()} is a grouped
\code{tibble} containing both identifying information and the feature
importance results aggregated over experimental replicates. Specifically, the
identifier columns include \code{.dgp_name}, \code{.method_name}, any columns
specified by \code{vary_params}, and the column specified by
\code{feature_col}. In addition, there are results columns corresponding to
the requested statistics in \code{summary_funs} and
\code{custom_summary_funs}. These columns end in the suffix
"_feature_importance".
}
\description{
Evaluate the estimated feature importance scores against the
true feature support. \code{eval_feature_importance} evaluates the
feature importances for each experimental replicate separately.
\code{summarize_feature_importance} summarizes the feature importances
across experimental replicates.
}
\examples{
# generate example fit_results data for a feature selection problem
fit_results <- tibble::tibble(
  .rep = rep(1:2, times = 2),
  .dgp_name = c("DGP1", "DGP1", "DGP2", "DGP2"),
  .method_name = c("Method"),
  feature_info = lapply(
    1:4,
    FUN = function(i) {
      tibble::tibble(
        # feature names
        feature = c("featureA", "featureB", "featureC"),
        # estimated feature importance scores
        est_importance = c(10, runif(2, min = -2, max = 2))
      )
    }
  )
)

# evaluate feature importances (using all default metrics) for each replicate
eval_results <- eval_feature_importance(
  fit_results,
  nested_data = "feature_info",
  feature_col = "feature",
  imp_col = "est_importance"
)
# summarize feature importances (using all default metric) across replicates
eval_results_summary <- summarize_feature_importance(
  fit_results,
  nested_data = "feature_info",
  feature_col = "feature",
  imp_col = "est_importance"
)

}
\seealso{
Other feature_selection_funs: 
\code{\link{eval_feature_selection_curve_funs}},
\code{\link{eval_feature_selection_err_funs}},
\code{\link{plot_feature_importance}()},
\code{\link{plot_feature_selection_curve}()},
\code{\link{plot_feature_selection_err}()}
}
\concept{feature_selection_funs}
