---
title: "Basics"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{basics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(pcs.sim.pkg)

# create a data-generating process function to pass to create_dgp()
dgp_fun <- function(n, noise_level = 4) {
  X <- matrix(rnorm(n * 2), nrow=n)
  y <- cbind(1, X) %*% c(-8, 3, -1) + rnorm(n, sd = noise_level)
  return(list(X = X, y = y))
}

dgp <- create_dgp(dgp_fun, n = 200, noise_level = 1)

# create a method function to pass to create_method(); this this case, just get
# the p-values of the two predictors in the OLS fit of the data
method_fun <- function(X, y) {
  fit <- lm(y ~ X)
  return(list(
    "X1 p-val" = summary(fit)$coefficients["X1", "Pr(>|t|)"],
    "X2 p-val" = summary(fit)$coefficients["X2", "Pr(>|t|)"]
  ))
}

method <- create_method(method_fun)

eval_summary_fun <- function(results) {
  eval_out <- results %>%
    dplyr::group_by(dgp, method) %>%
    dplyr::summarise_all(~mean(.x < 0.05))
  return(eval_out)
}

eval_fun <- function(results) {
  eval_out <- results %>%
    dplyr::mutate_at(dplyr::vars(-dgp, -method), 
                     ~ifelse(.x < 0.05, "reject", "fail to reject"))
  return(eval_out)
}

summary_evaluator <- create_evaluator(eval_summary_fun)
evaluator <- create_evaluator(eval_fun)

# create the experiment and add the dgp and method
experiment <- create_experiment(n_reps = 1000) %>%
  add_dgp(dgp) %>%
  add_method(method) %>%
  add_evaluator(summary_evaluator) %>%
  add_evaluator(evaluator)

future::plan(future::sequential)

# run sequentually
seq_start <- proc.time()
o1 <- experiment$run()
proc.time() - seq_start

eval_res <- experiment$evaluate(o1)

future::plan(future::multiprocess, workers=2)

# run in parallel with 2 processes
par_start <- proc.time()
o2 <- experiment$run()
proc.time() - par_start

future::plan(future::sequential)
```
