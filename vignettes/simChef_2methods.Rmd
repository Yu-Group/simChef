---
title: "Getting started with simChef"
output:
  bookdown::html_document2:
    base_format: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{simChef Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  # disable R chunk evaluation when using macOS in GH Actions
  # see https://github.com/tidyverse/ggplot2/issues/2252#issuecomment-1006713187
  # and https://github.com/lcolladotor/biocthis/issues/27 and
  # https://github.com/bodkan/slendr/commit/f0f5ae18452cc9df5d151874e41b0b8fd5f29aa2#
  eval = Sys.getenv("RUNNER_OS") != "macOS"
)

library(simChef)

set.seed(12345)

# remove old cached results to start fresh
for (fname in list.files(file.path("results", "Example Experiment"),
                         pattern = ".rds", recursive = T, full.names = T)) {
  file.remove(fname)
}
```

# Overview

Welcome to `simChef`! Our goal is to empower data scientists to focus their attention toward scientific best practices by removing the administrative burdens of simulation design. Using `simChef`, practitioners can seamlessly and efficiently run simulation experiments using an intuitive [tidy
grammar](https://design.tidyverse.org/). The core features of `simChef` include:

1. A tidyverse-inspired grammar of data-driven simulation experiments
2. A growing built-in library of composable building blocks for evaluation metrics and visualization utilities
3. Flexible and seamless integration with distributed computation, caching, and checkpointing
4. Automated generation of an R Markdown document to easily navigate, visualize, and interpret simulation results (example [here](../linear_regression_output.html))

# Example usage

To highlight the ease of running simulation studies using `simChef`, we begin with a basic example usage and defer details to Section \@ref(writing-your-own-simulation-experiment).

> **Simulation Example:** Suppose, for concreteness, that we would like to evaluate the prediction accuracy of two methods (linear regression and random forests) under two different underlying data-generating processes (a linear and non-linear response function) and across different signal-to-noise ratios.

At its core, `simChef` breaks down a simulation experiment into four components:

- `DGP`: the data-generating processes from which to *generate* data
- `Method`: the methods (or models) to *fit* in the experiment
- `Evaluator`: the evaluation metrics used to *evaluate* the methods' performance
- `Visualizer`: the visualization functions used to *visualize* outputs from the method fits or evaluation results (can be tables, plots, or even R Markdown snippets to display)

Using these components, users can easily run a simulation experiment in six simple steps. Below, we summarize these steps and provide code for our running example.

### Step 1. Specify DGP, method, evaluation, and visualization functions of interest. {-}

Recall that in the given simulation example, we would like to study two methods (linear regression and random forests) under two different DGPs (a linear and non-linear response function). We code these DGPs (`linear_dgp_fun` and `nonlinear_dgp_fun`) and methods (`linear_reg_fun` and `rf_fun`) via custom functions below. 

```{r dgp-funs}
#' Linear Data-Generating Process
#' 
#' @description Generate training and test data according to the classical
#'   linear regression model: y = X*beta + noise.
#' 
#' @param n_train Number of training samples.
#' @param n_test Number of training samples.
#' @param p Number of features.
#' @param beta Coefficient vector in linear regression function.
#' @param noise_sd Standard deviation of additive noise term.
linear_dgp_fun <- function(n_train, n_test, p, beta, noise_sd) {
  n <- n_train + n_test
  X <- matrix(rnorm(n * p), nrow = n, ncol = p)
  y <- X %*% beta + rnorm(n, sd = noise_sd)
  data_list <- list(
    X_train = X[1:n_train, , drop = FALSE],
    y_train = y[1:n_train],
    X_test = X[(n_train + 1):n_test, , drop = FALSE],
    y_test = y[(n_train + 1):n_test]
  )
  return(data_list)
}

#' Non-linear Data-Generating Process
#' 
#' @description Generate training and test data according to the following 
#'   non-linear data-generating process: y = 1(X > 0)*beta + noise.
#' 
#' @param n_train Number of training samples.
#' @param n_test Number of training samples.
#' @param p Number of features.
#' @param beta Coefficient vector in linear regression function.
#' @param noise_sd Standard deviation of additive noise term.
nonlinear_dgp_fun <- function(n_train, n_test, p, beta, noise_sd) {
  n <- n_train + n_test
  X <- matrix(rnorm(n * p), nrow = n, ncol = p)
  y <- (X > 0) %*% beta + rnorm(n, sd = noise_sd)
  data_list <- list(
    X_train = X[1:n_train, , drop = FALSE],
    y_train = y[1:n_train],
    X_test = X[(n_train + 1):n_test, , drop = FALSE],
    y_test = y[(n_train + 1):n_test]
  )
  return(data_list)
}
```

```{r method-funs}
#' Linear Regression Method
#' 
#' @param X_train Training data matrix.
#' @param y_train Training response vector.
#' @param X_test Test data matrix.
#' @param y_test Test response vector.
linear_reg_fun <- function(X_train, y_train, X_test, y_test) {
  train_df <- dplyr::bind_cols(data.frame(X_train), y = y_train)
  fit <- lm(y ~ ., data = train_df)
  predictions <- predict(fit, data.frame(X_test))
  return(list(predictions = predictions, y_test = y_test))
}

#' Random Forest Method
#' 
#' @param X_train Training data matrix.
#' @param y_train Training response vector.
#' @param X_test Test data matrix.
#' @param y_test Test response vector.
#' @param ... Additional arguments to pass to `ranger::ranger()`
rf_fun <- function(X_train, y_train, X_test, y_test, ...) {
  train_df <- dplyr::bind_cols(data.frame(X_train), y = y_train)
  fit <- ranger::ranger(y ~ ., data = train_df, ...)
  predictions <- predict(fit, data.frame(X_test))$predictions
  return(list(predictions = predictions, y_test = y_test))
}
```

We can similarly write custom functions to evaluate these methods and visualize results. However, `simChef` also provides a built-in library of helper functions for common evaluation and visualization needs. We leverage this library for convenience here. In particular, for prediction tasks, we will use the functions `simChef::summarize_pred_err()` and `simChef::plot_pred_err()` to evaluate and plot the prediction error between the observed and predicted responses, respectively. For details, see `? simChef::summarize_pred_err` and `? simChef::plot_pred_err`.

*Note*: Most of the user-written code is encapsulated by Step 1. From here, there is minimal coding on the user end as we turn to leverage the `simChef` grammar for experiments.

### Step 2. Convert functions into `DGP`, `Method`, `Evaluator`, and `Visualizer` class objects. {-}

Once we have specified the relevant DGP, method, evaluation, and visualization functions, the next step is to convert these functions into `DGP`, `Method`, `Evaluator`, and `Visualizer` class objects (`R6`) for `simChef`. To do so, we simply wrap the functions in `create_dgp()`, `create_method()`, `create_evaluator()`, or `create_visualizer()`, while specifying an intelligible name for the object and any input parameters to pass to the function.

```{r create-classes}
## DGPs
linear_dgp <- create_dgp(
  .dgp_fun = linear_dgp_fun, .name = "Linear DGP",
  # additional named parameters to pass to .dgp_fun()
  n_train = 200, n_test = 200, p = 2, beta = c(1, 0), noise_sd = 1
)
nonlinear_dgp <- create_dgp(
  .dgp_fun = nonlinear_dgp_fun, .name = "Non-linear DGP",
  # additional named parameters to pass to .dgp_fun()
  n_train = 200, n_test = 200, p = 2, beta = c(1, 0), noise_sd = 1
)

## Methods
linear_reg <- create_method(
  .method_fun = linear_reg_fun, .name = "Linear Regression"
  # additional named parameters to pass to .method_fun()
)
rf <- create_method(
  .method_fun = rf_fun, .name = "Random Forest", 
  # additional named parameters to pass to .method_fun()
  num.threads = 1
)

## Evaluators
pred_err <- create_evaluator(
  .eval_fun = summarize_pred_err, .name = 'Prediction Accuracy',
  # additional named parameters to pass to .eval_fun()
  truth_col = "y_test", estimate_col = "predictions"
) 

## Visualizers
pred_err_plot <- create_visualizer(
  .viz_fun = plot_pred_err, .name = 'Prediction Accuracy Plot',
  # additional named parameters to pass to .viz_fun()
  eval_name = 'Prediction Accuracy'
) 
```

### Step 3. Assemble recipe parts into a complete simulation experiment. {-}

Thus far, we have created the many individual components (i.e., `DGP(s)`, `Method(s)`, `Evaluator(s)`, and `Visualizer(s)`) for our simulation experiment. We next assemble or `add` these components together to create a complete simulation experiment recipe via:

```{r experiment-recipe}
experiment <- create_experiment(name = "Example Experiment") %>%
  add_dgp(linear_dgp) %>%
  add_dgp(nonlinear_dgp) %>%
  add_method(linear_reg) %>%
  add_method(rf) %>%
  add_evaluator(pred_err) %>%
  add_visualizer(pred_err_plot)
```

We can also vary across one or more parameters in the `DGP(s)` and/or `Method(s)` by adding a `vary_across` component to the simulation experiment recipe. In the given simulation example, we would like to vary across the amount of noise (`noise_sd`) in the underlying DGPs, which can be done as follows:

```{r vary-across}
experiment <- experiment %>%
  add_vary_across(.dgp = "Linear DGP", noise_sd = c(0.1, 0.5, 1, 2)) %>%
  add_vary_across(.dgp = "Non-linear DGP", noise_sd = c(0.1, 0.5, 1, 2))
```

*Tip*: To see a high-level summary of the simulation experiment recipe, it can be helpful to print the experiment.

```{r print-experiment}
print(experiment)
```

### Step 4. Document and describe the simulation experiment in text. {-}

A crucial component when running veridical simulations is **documentation**. We highly encourage practitioners to document the purpose or objective of the simulation experiment, what `DGP(s)`, `Method(s)`, `Evaluator(s)`, and `Visualizer(s)` were used, and why these `DGP(s)`, `Method(s)`, `Evaluator(s)`, and `Visualizer(s)` were chosen. This can and should be done before even running the simulation experiment. To facilitate this tedious but important process, we can easily initialize a documentation template to fill out using

```{r init-docs}
init_docs(experiment)
```

```{r cp-docs, echo = FALSE, warning = FALSE, message = FALSE, results = "hide"}
# copy pre-written .md files in vignettes/docs to the experiment's docs dir
file.copy(from = here::here("vignettes/docs"),
          to = file.path(experiment$get_save_dir()),
          recursive = TRUE)
```

### Step 5. Run the experiment. {-}

At this point, we have created and documented the simulation experiment recipe, but we have not generated any results from the experiment. That is, we have only given the simulation experiment instructions on what to do. To run the experiment, say over 100 replicates, we can do so via

```{r run-experiment}
results <- run_experiment(experiment, n_reps = 10, save = TRUE)
```

### Step 6. Visualize results via an automated R Markdown report. {-}

Finally, to visualize and report all results from the simulation experiment, we can render the documentation. This will generate a single html document, including the code, documentation (from Step 4), and simulation results.

```{r render-docs}
render_docs(experiment)
```

The rendered document corresponding to this simulation example can be found [here](../linear_regression_output.html), and voila! Simulation example complete!

In the next section, we will provide additional details necessary for you to create your own simulation experiment.

# Writing your own simulation experiment
